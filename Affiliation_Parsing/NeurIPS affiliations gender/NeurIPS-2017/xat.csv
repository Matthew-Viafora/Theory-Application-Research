379,379,Ethan Elenberg,ASAPP,Amin Karbasi,Yale,Streaming Weak Submodularity: Interpreting Neural Networks on the Fly.
380,380,Alina Ene,University of Warwick,László A. Végh,London School of Economics,Decomposable Submodular Function Minimization: Discrete and Continuous.
381,381,Josip Djolonga,ETH Zurich,Andreas Krause,ETH Zurich,Differentiable Learning of Submodular Functions.
382,382,Robert S Chen,Harvard University,Vasilis Syrgkanis,Microsoft Research,Robust Optimization for Non-Convex Objectives.
383,383,Rong Ge,Duke University,Tengyu Ma,Stanford University,On the Optimization Landscape of Tensor Decompositions.
384,384,Simon Du,Carnegie Mellon University,Barnabas Poczos,Carnegie Mellon University,Gradient Descent Can Take Exponential Time to Escape Saddle Points.
385,385,Qing Qu,Columbia University,John Wright,Columbia University,Convolutional Phase Retrieval.
386,386,Suriya Gunasekar,TTI Chicago,Nati Srebro,TTI-Chicago,Implicit Regularization in Matrix Factorization.
387,387,Jason Altschuler,MIT,Philippe Rigollet,MIT,Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration.
388,388,Jacob D Abernethy,University of Michigan,Jun-Kun Wang,Georgia Institute of Technology,On Frank-Wolfe and Equilibrium Computation.
389,389,Francesco Locatello,MPI Tübingen - ETH Zürich,Martin Jaggi,EPFL,Greedy Algorithms for Cone Constrained Optimization with Convergence Guarantees.
390,390,Mert Gurbuzbalaban,Rutgers University,Denizcan Vanli,Massachusetts Institute of Technology,When Cyclic Coordinate Descent Outperforms Randomized Coordinate Descent.
391,391,Zeyuan Allen-Zhu,Microsoft Research,Yuanzhi Li,Princeton University,Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm Balls.
392,392,Mingrui Liu,The University of Iowa,Tianbao Yang,The University of Iowa,"Adaptive Accelerated Gradient Converging Method under H\""{o}lderian Error Bound Condition."
393,393,Yi Xu,The University of Iowa,Tianbao Yang,The University of Iowa,Adaptive SVRG Methods under Error Bound Conditions with Unknown Growth Parameter.
394,394,Shixiang Chen,The Chinese University of HongKong,Wei Liu,Tencent AI Lab,Geometric Descent Method for Convex Composite Minimization.
395,395,Cong Fang,Peking University,Zhouchen Lin,Peking University,Faster and Non-ergodic O(1/K) Stochastic Alternating Direction Method of Multipliers.
396,396,Tomoya Murata,NTT DATA Mathematical Systems Inc.,Taiji Suzuki,taiji@mist.i.u-tokyo.ac.jp,Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for Regularized Empirical Risk Minimization.
397,397,Yossi Arjevani,The Weizmann Institute,Yossi Arjevani,The Weizmann Institute,Limitations on Variance-Reduction and Acceleration Schemes for Finite Sums Optimization.
398,398,Damien Scieur,INRIA - ENS,Alexandre d'Aspremont,CNRS - Ecole Normale Supérieure,Nonlinear Acceleration of Stochastic Algorithms.
