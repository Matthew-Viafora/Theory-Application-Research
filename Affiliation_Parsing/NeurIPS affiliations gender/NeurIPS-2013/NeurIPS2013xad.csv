59,59,Gunnar Kedenburg,None,Remi Munos,Google DeepMind,Aggregating Optimistic Planning Trees for Solving Markov Decision Processes.
60,60,Mohsen Bayati,Stanford University,Andrea Montanari,Stanford,Estimating LASSO Risk and Noise Level.
61,61,Pablo Sprechmann,Duke University,Guillermo Sapiro,Duke University,Supervised Sparse Analysis and Synthesis Operators.
62,62,Adel Javanmard,Stanford University,Andrea Montanari,Stanford,Model Selection for High-Dimensional Regression under the Generalized Irrepresentability Condition.
63,63,Akshay Krishnamurthy,UMass Amherst,Aarti Singh,CMU,Low-Rank Matrix and Tensor Completion via Adaptive Sampling.
64,64,Andreas Stuhlmüller,Massachusetts Institute of Technology,Noah Goodman,Stanford University,Learning Stochastic Inverses.
65,65,Ziteng Wang,,Liwei Wang,Peking University,Efficient Algorithm for Privately Releasing Smooth Queries.
66,66,Daniel L Yamins,Massachusetts Institute of Technology,James J DiCarlo,Massachusetts Institute of Technology,Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Human Ventral Stream.
67,67,Mijung Park,University of Texas,Jonathan W Pillow,UT Austin,Bayesian inference for low rank spatiotemporal neural receptive fields.
68,68,Sivaraman Balakrishnan,CMU,Larry Wasserman,Carnegie Mellon University,Cluster Trees on Manifolds.
69,69,Il Memming Park,Stony Brook University,Jonathan W Pillow,UT Austin,Spectral methods for neural characterization using generalized quadratic models.
70,70,Wenjie Luo,TTI Chicago,Raquel Urtasun,University of Toronto,Latent Structured Active Learning.
71,71,Ke Hou,CUHK,Zhi-Quan Luo,"University of Minnesota, Twin Cites",On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization.
72,72,Zheng Wen,Stanford University,Benjamin Van Roy,Stanford University,Efficient Exploration and Value Function Generalization in Deterministic Systems.
73,73,Nathaniel J Smith,University of Edinburgh,Michael C Frank,Stanford University,Learning and using language via recursive pragmatic reasoning about other agents.
74,74,Mehrdad Mahdavi,Michigan State University (MSU),Rong Jin,Michigan State University (MSU),Mixed Optimization for Smooth Functions.
75,75,John Duchi,UC Berkeley,Brendan McMahan,Google,"Estimation, Optimization, and Parallelism when Data is Sparse."
76,76,Christophe Schulke,ESPCI ParisTech,Lenka Zdeborová,EPFL,Blind Calibration in Compressed Sensing using Message Passing Algorithms.
77,77,José Bento,Boston College,Jonathan S Yedidia,Disney Research,A message-passing algorithm for multi-agent trajectory planning.
78,78,Mike Hughes,Tufts University,Erik Sudderth,Brown University,Memoized Online Variational Inference for Dirichlet Process Mixture Models.
