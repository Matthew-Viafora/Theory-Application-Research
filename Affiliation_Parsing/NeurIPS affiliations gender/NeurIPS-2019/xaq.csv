319,319,Ruoqi Shen,University of Washington,Yin Tat Lee,UW,The Randomized Midpoint Method for Log-Concave Sampling.
320,320,Marcel Hirt,University College London,Alain Durmus,ENS Paris Saclay,Copula-like Variational Inference.
321,321,Kazuki Osawa,Tokyo Institute of Technology,Rio Yokota,"Tokyo Institute of Technology, AIST- Tokyo Tech Real World Big-Data Computation Open Innovation Laboratory (RWBC- OIL), National Institute of Advanced Industrial Science and Technology (AIST)",Practical Deep Learning with Bayesian Principles.
322,322,Dominik Linzner,Technische Universität Darmstadt,Heinz Koeppl,Technische Universität Darmstadt,Scalable Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data.
323,323,Trevor Campbell,UBC,Xinglong Li,The University of British Columbia,Universal Boosting Variational Inference.
324,324,Yixin Wang,Columbia University,David Blei,Columbia University,Variational Bayes under Model Misspecification.
325,325,Tomasz Kuśmierczyk,University of Helsinki,Arto Klami,University of Helsinki,Variational Bayesian Decision-making for Continuous Utilities.
326,326,Hengyuan Hu,Facebook,Mike Lewis,Facebook AI Research,Hierarchical Decision Making by Generating and Following Natural Language Instructions.
327,327,Xiangyuan Zhang,University of Illinois at Urbana-Champaign,Tamer Basar,University of Illinois at Urbana-Champaign,Non-Cooperative Inverse Reinforcement Learning.
328,328,Jack Umenberger,Uppsala University,Håkan Hjalmarsson,KTH,Robust exploration in linear quadratic reinforcement learning .
329,329,Andrea Zanette,Stanford University,Emma Brunskill,Stanford University,Almost Horizon-Free Structure-Aware Best Policy Identification with a Generative Model.
330,330,Kamil Ciosek,Microsoft,Katja Hofmann,Microsoft Research,Better Exploration with Optimistic Actor Critic.
331,331,Simon Du,Institute for Advanced Study,Hanrui Zhang,Duke University,Provably Efficient Q-learning with Function Approximation via Distribution Shift Error Checking Oracle.
332,332,Liangpeng Zhang,University of Birmingham,Xin Yao,Southern University of Science and Technology,Explicit Planning for Efficient Exploration in Reinforcement Learning.
333,333,Jian QIAN,INRIA Lille - Sequel Team,Alessandro Lazaric,Facebook Artificial Intelligence Research,Exploration Bonus for Regret Minimization in Discrete and Continuous Average Reward MDPs.
334,334,Daniel Russo,Columbia University,Daniel Russo,Columbia University,Worst-Case Regret Bounds for Exploration via Randomized Value Functions.
335,335,Marek Petrik,University of New Hampshire,Reaz Russel,University of New Hampshire,Beyond Confidence Regions: Tight Bayesian Ambiguity Sets for Robust MDPs.
336,336,Bastian Alt,Technische Universität Darmstadt,Heinz Koeppl,Technische Universität Darmstadt,Correlation Priors for Reinforcement Learning.
337,337,Mikael Henaff,Microsoft Research,Mikael Henaff,Microsoft Research,Explicit Explore-Exploit Algorithms in Continuous State Spaces.
338,338,Daniel Freeman,Google Brain,Luke Metz,Google Brain,Learning to Predict Without Looking Ahead: World Models Without Forward Prediction.
