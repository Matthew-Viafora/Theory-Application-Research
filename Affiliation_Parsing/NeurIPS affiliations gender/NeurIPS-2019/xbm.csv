759,759,Greg Yang,Microsoft Research,Greg Yang,Microsoft Research,Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes.
760,760,Andreas Kirsch,University of Oxford,Yarin Gal,University of Oxford,BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning.
761,761,Robert Pinsler,University of Cambridge,Jose Miguel Hern√°ndez-Lobato,University of Cambridge,Bayesian Batch Active Learning as Sparse Subset Approximation.
762,762,Shali Jiang,Washington University in St. Louis,Benjamin Moseley,Carnegie Mellon University,Cost Effective Active Search.
763,763,Fabio Vitale,University of Lille - INRIA Lille (France),Claudio Gentile,Google Research,Flattening a Hierarchical Clustering through Active Learning.
764,764,Weishi Shi,Rochester Institute of Technology,Qi Yu,Rochester Institute of Technology,Integrating Bayesian and Discriminative Sparse Kernel Machines for  Multi-class Active Learning.
765,765,Blake Mason,University of Wisconsin - Madison,Robert Nowak,University of Wisconsion-Madison,Learning Nearest Neighbor Graphs from Noisy Distance Samples.
766,766,Tomi Peltola,Aalto University,Samuel Kaski,Aalto University,Machine Teaching of Active Sequential Learners.
767,767,Songbai Yan,"University of California, San Diego",Tara Javidi,University of California San Diego,The Label Complexity of Active Learning from Observational Data.
768,768,Juncheng Li,Carnegie Mellon University,Florian Metze,Carnegie Mellon University,Adversarial Music: Real world Audio Adversary against Wake-word Detection System.
769,769,Chongli Qin,DeepMind,Pushmeet Kohli,DeepMind,Adversarial Robustness through Local Linearization.
770,770,Jean-Baptiste Alayrac,Deepmind,Pushmeet Kohli,DeepMind,Are Labels Required for Improving Adversarial Robustness?.
771,771,Mislav Balunovic,ETH Zurich,Martin Vechev,"ETH Zurich, Switzerland",Certifying Geometric Robustness of Neural Networks.
772,772,Muhammad Muzammal Naseer,Australian National University (ANU),Fatih Porikli,ANU,Cross-Domain Transferability of Adversarial Perturbations.
773,773,Cassidy Laidlaw,"University of Maryland, College Park",Soheil Feizi,University of Maryland,Functional Adversarial Attacks.
774,774,Shuyu Cheng,Tsinghua University,Jun Zhu,Tsinghua University,Improving Black-box Adversarial Attacks with a Transfer-based Prior.
775,775,Fanny Yang,"Stanford University, ETH Zurich",Christina Heinze-Deml,ETH Zurich,Invariance-inducing regularization using worst-case transformations suffices to boost accuracy and spatial robustness.
776,776,Pranjal Awasthi,Rutgers University/Google,Aravindan Vijayaraghavan,Northwestern University,On Robustness to Adversarial Examples and Polynomial Optimization.
777,777,Arnak Dalalyan,ENSAE ParisTech,Philip Thompson,"University of Cambridge, Statistical Laboratory",Outlier-robust estimation of a sparse linear model using $\ell_1$-penalized Huber's $M$-estimator.
778,778,Matt Jordan,UT Austin,Alex Dimakis,"University of Texas, Austin",Provable Certificates for Adversarial Examples: Fitting a Ball in the Union of Polytopes.
