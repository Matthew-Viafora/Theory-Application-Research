,Unnamed: 0,first-author,first-author-affiliation,last-author,last-author-affiliation,title
119,119,Dinghuai Zhang,Peking University,Bin Dong,Peking University,You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle.
120,120,Wesley J Maddox,New York University,Andrew Gordon Wilson,New York University,A Simple Baseline for Bayesian Uncertainty in Deep Learning.
121,121,Matthias Minderer,Google Research,Honglak Lee,Google Brain,Unsupervised learning of object structure and dynamics from videos.
122,122,Zeyuan Allen-Zhu,Microsoft Research,Yuanzhi Li,Princeton,Can SGD Learn Recurrent Neural Networks with Provable Generalization?.
123,123,Aya Abdelsalam Ismail,University of Maryland,Soheil Feizi,University of Maryland,Input-Cell Attention Reduces Vanishing Saliency of Recurrent Neural Networks.
124,124,Giancarlo Kerg,MILA,Guillaume Lajoie,Université de Montréal / Mila,Non-normal Recurrent Neural Network (nnRNN): learning long time dependencies while improving expressivity with transient dynamics.
125,125,Niru Maheswaranathan,Google Brain,David Sussillo,Google Inc.,Reverse engineering recurrent networks for sentiment classification reveals line attractor dynamics.
126,126,Biao Zhang,University of Edinburgh,Rico Sennrich,University of Edinburgh,Root Mean Square Layer Normalization.
127,127,Sara Hooker,Google Brain,Been Kim,Google,A Benchmark for Interpretability Methods in Deep Neural Networks.
128,128,Wieland Brendel,"AG Bethge, University of Tübingen",Matthias Bethge,University of Tübingen,"Accurate, reliable and fast robustness evaluation."
129,129,Ke Li,UC Berkeley,Jitendra Malik,University of California at Berkley,Approximate Feature Collisions in Neural Nets.
130,130,Matthew Sotoudeh,"University of California, Davis",Aditya V Thakur,"University of California, Davis",Computing Linear Restrictions of Neural Networks.
131,131,Patrick Schwab,ETH Zurich / Roche,Walter Karlen,ETH Zurich,CXPlain: Causal Explanations for Model Interpretation under Uncertainty.
132,132,Pei Wang,UC San Diego,Nuno Nvasconcelos,UC San Diego,Deliberative Explanations: visualizing network insecurities.
133,133,Ann-Kathrin Dombrowski,TU Berlin,Pan Kessel,TU Berlin,Explanations can be manipulated and geometry is to blame.
134,134,Lukas Hoyer,Bosch Center for Artificial Intelligence,Volker Fischer,"Robert Bosch GmbH, Bosch Center for Artificial Intelligence",Grid Saliency for Context Explanations of Semantic Segmentation.
135,135,Alessio Ansuini,International School for Advanced Studies (SISSA),Davide Zoccolan,"Visual Neuroscience Lab, International School for Advanced Studies (SISSA)",Intrinsic dimension of data representations in deep neural networks.
136,136,Ari Morcos,Facebook AI Research,Yuandong Tian,Facebook AI Research,One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers.
137,137,Emily Reif,Google,Been Kim,Google,Visualizing and Measuring the Geometry of BERT.
138,138,Scott Gigante,Yale University,Gal Mishne,UC San Diego,Visualizing the PHATE of Neural Networks.
