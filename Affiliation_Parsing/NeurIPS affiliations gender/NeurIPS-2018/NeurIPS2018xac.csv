,Unnamed: 0,first-author,first-author-affiliation,last-author,last-author-affiliation,title
39,39,Jangho Kim,Seoul National University,Nojun Kwak,Seoul National University,Paraphrasing Complex Network: Network Compression via Factor Transfer.
40,40,Anna Thomas,Stanford,Chris RÃ©,Stanford,Learning Compressed Transforms with Low Displacement Rank.
41,41,xu lan,"Queen Mary, University of London",Shaogang Gong,Queen Mary University of London,Knowledge Distillation by On-the-Fly Native Ensemble.
42,42,Ron Banner,Intel - Artificial Intelligence Products Group (AIPG),Daniel Soudry,Technion,Scalable methods for 8-bit training of neural networks.
43,43,Guocong Song,Playground Global,Wei Chai,Google Inc,Collaborative Learning for Deep Neural Networks.
44,44,Peng Jiang,The Ohio State University,Gagan Agrawal,Ohio State University,A Linear Speedup Analysis of Distributed Deep Learning with Sparse and Quantized Communication.
45,45,Michael Teng,University of Oxford (visiting at University of British Columbia),Frank Wood,University of British Columbia,Bayesian Distributed Stochastic Gradient Descent.
46,46,Etai Littwin,Apple,Lior Wolf,Facebook AI Research,Regularizing by the Variance of the Activations' Sample-Variances.
47,47,Songtao Wang,Tsinghua University,Jianping Wu,Tsinghua University,"BML: A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training."
48,48,Michal Rolinek,Max Planck Institute for Intelligent Systems,Georg Martius,MPI for Intelligent Systems,L4: Practical loss-based stepsize adaptation for deep learning.
49,49,CHEN LIN,SenseTime,Junjie Yan,Sensetime Group Limited,Synaptic Strength For Convolutional Neural Network.
50,50,Hongyang Gao,Texas A&M University,Shuiwang Ji,Texas A&M University,ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions.
51,51,Zhenhua Liu,Peking University,Ruiqin Xiong,Peking University,Frequency-Domain Dynamic Pruning for Convolutional Neural Networks.
52,52,Yu Ji,Tsinghua University,Yuan Xie,UCSB,TETRIS: TilE-matching the TRemendous Irregular Sparsity.
53,53,Joshua Fromm,University of Washington,Matthai Philipose,Microsoft Research,Heterogeneous Bitwidth Binarization in Convolutional Neural Networks.
54,54,Peiqi Wang,Tsinghua University,Yuan Xie,"University of California, Santa Barbara",HitNet: Hybrid Ternary Recurrent Neural Network.
55,55,Joe Marino,California Institute of Technology,Yisong Yue,Caltech,A General Method for Amortizing Variational Filtering.
56,56,Minjia Zhang,Microsoft,Yuxiong He,Microsoft,Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models.
57,57,Xin Zhang,Massachusetts Institute of Technology,Rishabh Singh,Google Brain,"Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections."
58,58,Hae Beom Lee,KAIST,Sung Ju Hwang,"KAIST, AItrics",DropMax: Adaptive Variational Softmax.
