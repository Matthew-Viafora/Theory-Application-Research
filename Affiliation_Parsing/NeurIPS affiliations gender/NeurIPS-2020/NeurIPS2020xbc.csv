,Unnamed: 0,first-author,first-author-affiliation,last-author,last-author-affiliation,title
559,559,Theodore Perkins,Ottawa Hospital Research Institute,Theodore Perkins,Ottawa Hospital Research Institute,Towards Playing Full MOBA Games with Deep Reinforcement Learning.
560,560,Eric K Garcia,University of Washington,Maya R Gupta,University of Washington,Federated Bayesian Optimization via Thompson Sampling.
561,561,Boaz Nadler,Weizmann Institute of Science,Xueyuan Zhou,None,Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games.
562,562,Emanuel Todorov,University of Washington,Emanuel Todorov,University of Washington,Reinforcement Learning with Augmented Data.
563,563,Matthew Wilder,University of Colorado at Boulder,Mike Mozer,Google Research and U. Colorado Boulder,Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning.
564,564,Zhihua Zhang,Shanghai Jiao Tong University,guang dai,zju,Almost Optimal Model-Free Reinforcement Learningvia Reference-Advantage Decomposition.
565,565,Aaron Courville,U. Montreal,Yoshua Bengio,University of Montreal,Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning.
566,566,Jonathan W Pillow,UT Austin,Jonathan W Pillow,UT Austin,Succinct and Robust Multi-Agent Communication With Temporal Message Control.
567,567,Yiming Ying,State University of New York at Albany,Mark A Girolami,University of Glasgow,Scalable Multi-Agent Reinforcement Learning for Networked Systems with Average Reward.
568,568,Feng Zhou,Carnegie Mellon University,Fernando D De la Torre,Carnegie Mellon University,Learning Individually Inferred Communication for Multi-Agent Cooperation.
569,569,Ben Taskar,University of Washington,Ben Taskar,University of Washington,Emergent Reciprocity and Team Formation from Randomized Uncertain Social Preferences.
570,570,Elad Hazan,Princeton University,Satyen Kale,Google,Marginal Utility for Planning in Continuous or Large Discrete Action Spaces.
571,571,Peter Sollich,King's College London,Camille Coti,INRIA Saclay-Île de France,A Novel Automated Curriculum Strategy to Solve Hard Sokoban Planning Instances.
572,572,Guillermo Cecchi,IBM Research,Jean-Baptiste Poline,CEA-INSERM,Softmax Deep Double Deterministic Policy Gradients.
573,573,HongJing Lu,UCLA,Alan L Yuille,UCLA,Non-Crossing Quantile Regression for Distributional Reinforcement Learning.
574,574,Matt Streeter,Duolingo,Andreas Krause,ETH Zurich,Improving Generalization in Reinforcement Learning with Mixture Regularization.
575,575,Nir Ailon,Technion,Claire Monteleoni,University of Colorado Boulder,Choice Bandits.
576,576,Gideon S Mann,Google Inc.,Dan Walker,None,Differentiable Meta-Learning of Bandit Policies.
577,577,Siamac Fazli,TU Berlin,Klaus-Robert Müller,TU Berlin,Latent Bandits Revisited.
578,578,Jake Bouvrie,Massachusetts Institute of Technology,Tomaso Poggio,MIT,Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence Bounds for Optimal Adaptive Allocation with Multiple Plays and Markovian Rewards.
