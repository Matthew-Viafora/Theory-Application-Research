,Unnamed: 0,first-author,first-author-affiliation,last-author,last-author-affiliation,title
579,579,Matthias Seeger,Amazon,Matthias Seeger,Amazon,Sub-sampling for Efficient Non-Parametric Bandit Exploration.
580,580,Ruben Coen-Cagli,Albert Einstein College of Medicine,Odelia Schwartz,Albert Einstein College of Medicine,Online Learning in Contextual Bandits using Gated Linear Networks.
581,581,Antonio Torralba,Massachusetts Institute of Technology,Antonio Torralba,Massachusetts Institute of Technology,High-Dimensional Contextual Policy Search with Unknown Context Rewards using Bayesian Optimization.
582,582,Zenglin Xu,University of Electronic Science & Technology of China,Zhirong Yang,Aalto University,Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement.
583,583,Pari Ram,IBM Research,Alexander Gray,Skytree Inc. and Georgia Tech,RD$^2$: Reward Decomposition with Representation Decomposition.
584,584,Lawrence Cayton,Max Planck Institute for Biological Cybernetics,Lawrence Cayton,Max Planck Institute for Biological Cybernetics,Efficient Exploration of Reward Functions in Inverse Reinforcement Learning via Bayesian Optimization.
585,585,Dilip Krishnan,NYU,Rob Fergus,DeepMind / NYU,Learning Guidance Rewards with Trajectory-space Smoothing.
586,586,Yusuke Fujiwara,ATR,Yukiyasu Kamitani,None,Avoiding Side Effects in Complex Environments.
587,587,Nino Shervashidze,"INRIA, Laboratoire d'Informatique de l'ENS",Karsten Borgwardt,ETH Zurich,Reward-rational (implicit) choice: A unifying formalism for reward learning.
588,588,Kurt T Miller,PDT Partners,Michael Jordan,UC Berkeley,Planning with General Objective Functions: Going Beyond Total Rewards.
589,589,Menachem Fromer,Hebrew University,Amir Globerson,"Tel Aviv University, Google",Preference-based Reinforcement Learning with Finite-Time Guarantees.
590,590,Kurt T Miller,PDT Partners,Michael Jordan,UC Berkeley,Is Long Horizon RL More Difficult Than Short Horizon RL?.
591,591,Amarnag Subramanya,Google Inc.,Jeff A Bilmes,"University of Washington, Seattle",Online Meta-Critic Learning for Off-Policy Actor-Critic Methods.
592,592,Joseph Schlecht,University of Arizona,Kobus Barnard,University of Arizona,POMO: Policy Optimization with Multiple Optima for Reinforcement Learning.
593,593,Kevin G Waugh,University of Alberta,Michael Bowling,DeepMind / University of Alberta,Error Bounds of Imitating Policies and Environments.
594,594,Martin Allen,Connecticut College,Shlomo Zilberstein,Univ of Mass,Model-based Adversarial Meta-Reinforcement Learning.
595,595,Yiming Ying,State University of New York at Albany,Mark A Girolami,University of Glasgow,Offline Imitation Learning with a Misspecified Simulator.
596,596,Hamed Pirsiavash,University of California Irvine,Charless Fowlkes,UC Irvine,Policy Improvement via Imitation of Multiple Oracles.
597,597,Tomer D Ullman,Massachusetts Institute of Technology,Josh Tenenbaum,MIT,Toward the Fundamental Limits of Imitation Learning.
598,598,Wu-Jun Li,Nanjing University,Zhihua Zhang,Shanghai Jiao Tong University,Trajectory-wise Multiple Choice Learning for Dynamics Generalization in Reinforcement Learning.
