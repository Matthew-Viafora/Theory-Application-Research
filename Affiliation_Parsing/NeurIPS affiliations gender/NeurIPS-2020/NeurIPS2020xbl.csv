739,739,Hamed Valizadegan,Michigan State University,Jianchang Mao,Yahoo! Labs,Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign Dropout.
740,740,Kurt T Miller,PDT Partners,Michael Jordan,UC Berkeley,GCN meets GPU: Decoupling “When to Sample” from “How to Sample”.
741,741,Massih R Amini,University Joseph Fourier,Cyril Goutte,National Research Council Canada,Improving model calibration with accuracy versus uncertainty optimization.
742,742,Ingo Steinwart,Los Alamos National Laboratory,Andreas Christmann,University of Bayreuth,Deep Evidential Regression.
743,743,Kai Yu,Baidu,Yihong Gong,None,Practical Quasi-Newton Methods for Training Deep Neural Networks.
744,744,Ofer Dekel,Microsoft Research,Ofer Dekel,Microsoft Research,Ultra-Low Precision 4-bit Training of Deep Neural Networks.
745,745,Jian Peng,TTI Chicago,Jinbo Xu,Toyota Tech Inst at Chicago,Improving Neural Network Training in Low Dimensional Random Bases.
746,746,Boaz Nadler,Weizmann Institute of Science,Xueyuan Zhou,None,Bandit Samplers for Training Graph Neural Networks.
747,747,Samuel J Gershman,Harvard University,Josh Tenenbaum,MIT,ScaleCom: Scalable Sparsified Gradient Compression for Communication-Efficient Distributed Training.
748,748,Shakir Mohamed,DeepMind,Finale P Doshi-Velez,Harvard,Robust Optimal Transport with Applications in Generative Modeling and Domain Adaptation.
749,749,Samuel J Gershman,Harvard University,Josh Tenenbaum,MIT, Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods .
750,750,Jake Bouvrie,Massachusetts Institute of Technology,Tomaso Poggio,MIT,MomentumRNN: Integrating Momentum into Recurrent Neural Networks.
751,751,Rob Fergus,DeepMind / NYU,Antonio Torralba,Massachusetts Institute of Technology,Why are Adaptive Methods Good for Attention Models?.
752,752,Eric K Garcia,University of Washington,Maya R Gupta,University of Washington,MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler.
753,753,Mladen Kolar,University of Chicago,Eric Xing,Petuum Inc. /  Carnegie Mellon University,"Dark Experience for General Continual Learning: a Strong, Simple Baseline."
754,754,Bharath Sriperumbudur,The Pennsylvania State University,Gert Lanckriet,U.C. San Diego,RATT: Recurrent Attention to Transient Tasks for Continual Image Captioning.
755,755,Zhen James Xiang,Princeton University,Peter J Ramadge,Princeton,Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks.
756,756,Vijay Desai,None,Ciamac C Moallemi,Columbia University,Continual Deep Learning by Functional Regularisation of Memorable Past.
757,757,Lei ShiUpdateMe,"University of California, Berkeley",Tom Griffiths,Princeton,Look-ahead Meta Learning for Continual Learning.
758,758,Lin Xiao,Facebook AI Research,Lin Xiao,Facebook AI Research,A Combinatorial Perspective on Transfer Learning .
