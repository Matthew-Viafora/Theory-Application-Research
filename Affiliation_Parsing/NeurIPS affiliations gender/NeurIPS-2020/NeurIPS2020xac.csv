39,39,Robert Legenstein,Graz University of Technology,Wolfgang Maass,Graz University of Technology,Learning Strategic Network Emergence Games.
40,40,Le Song,Carnegie Mellon University,Eric Xing,Petuum Inc. /  Carnegie Mellon University,Fighting Copycat Agents in Behavioral Cloning from Observation Histories.
41,41,Zhihua Zhang,Shanghai Jiao Tong University,guang dai,zju,Attention-Gated Brain Propagation: How the brain can implement reward-based error backpropagation.
42,42,Shuheng Zhou,ETH Zurich,Shuheng Zhou,ETH Zurich,Can the Brain Do Backpropagation? --- Exact Implementation of Backpropagation in Predictive Coding Networks.
43,43,Wolf Vanpaemel,KULeuven,Wolf Vanpaemel,KULeuven,Demixed shared component analysis of neural population data from multiple brain areas.
44,44,Charles Kemp,Carnegie Mellon University,Charles Kemp,Carnegie Mellon University,Neural encoding with visual attention.
45,45,Andrew Guillory,University of Washington,Jeff A Bilmes,"University of Washington, Seattle",On Numerosity of Deep Neural Networks.
46,46,Sahand N Negahban,"University of California, Berkeley",Bin Yu,None,Compact task representations as a normative model for higher-order brain activity.
47,47,Wu-Jun Li,Nanjing University,Zhihua Zhang,Shanghai Jiao Tong University,Using noise to probe recurrent neural network structure and prune synapses.
48,48,Peter Sollich,King's College London,Camille Coti,INRIA Saclay-ÃŽle de France,An Imitation from Observation Approach to Transfer Learning with Dynamics Mismatch.
49,49,Mladen Kolar,University of Chicago,Eric Xing,Petuum Inc. /  Carnegie Mellon University,Language Models are Few-Shot Learners.
50,50,Xiao-Ming Wu,Columbia University,Shuo-Yen Robert Li,None,Incorporating BERT into Parallel Sequence Decoding with Adapters.
51,51,Novi Quadrianto,University of Sussex and HSE,Dale Schuurmans,Google Brain & University of Alberta,CogLTX: Applying BERT to Long Texts.
52,52,Andrew McCallum,UMass Amherst,Sameer Singh,"University of California, Irvine",MPNet: Masked and Permuted Pre-training for Language Understanding.
53,53,Joseph Schlecht,University of Arizona,Kobus Barnard,University of Arizona,MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers.
54,54,Bharath Sriperumbudur,The Pennsylvania State University,Gert Lanckriet,U.C. San Diego,Towards Neural Programming Interfaces.
55,55,Boaz Nadler,Weizmann Institute of Science,Xueyuan Zhou,None,Language Through a Prism: A Spectral Approach for Multiscale Language Representations.
56,56,Shobha Venkataraman,AT&T Labs -- Research,Oliver Spatscheck,None,ColdGANs: Taming Language GANs with Cautious Sampling Strategies.
57,57,Chunxiao Zhou,NIH (National Institutes of Health),Yongmei Michelle Wang,None,ConvBERT: Improving BERT with Span-based Dynamic Convolution.
58,58,Roger Luo,Snap Inc.,Vittorio Ferrari,University of Edinburgh,Investigating Gender Bias in Language Models Using Causal Mediation Analysis.
