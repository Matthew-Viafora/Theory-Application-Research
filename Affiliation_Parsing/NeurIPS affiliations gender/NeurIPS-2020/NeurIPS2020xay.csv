,Unnamed: 0,first-author,first-author-affiliation,last-author,last-author-affiliation,title
479,479,Yusuke Watanabe,The Institute of Statistical Mathematics,Kenji Fukumizu,Institute of Statistical Mathematics / Preferred Networks / RIKEN AIP,Neural Sparse Voxel Fields.
480,480,Brian Kulis,UC Berkeley,Trevor Darrell,UC Berkeley,RepPoints v2: Verification Meets Regression for Object Detection.
481,481,Chun-Nan Hsu,USC,Yuh-Jye Lee,National Taiwan University of Science and Technology,Efficient Contextual Bandits with Continuous Actions.
482,482,Brian Kulis,UC Berkeley,Trevor Darrell,UC Berkeley,Collapsing Bandits and Their Application to Public Health Intervention.
483,483,Manqi Zhao,Boston Univesity,Venkatesh Saligrama,Boston University,Learning to Play Sequential Games versus Unknown Opponents.
484,484,Stephen Gould,ANU,Daphne Koller,insitro,Interferobot: aligning an optical interferometer by a reinforcement learning agent.
485,485,Tao Hu,"JFRC, HHMI",Dmitri B Chklovskii,HHMI,Reinforcement Learning in Factored MDPs: Oracle-Efficient Algorithms and Tighter Regret Bounds for the Non-Episodic Setting.
486,486,Katherine Heller,Duke,Nick Chater,None,Reinforcement Learning with Feedback Graphs.
487,487,Alexandre Bouchard-Côté,UBC,Dan Klein,UC Berkeley,A Unifying View of Optimism in Episodic Reinforcement Learning.
488,488,Ben Taskar,University of Washington,Ben Taskar,University of Washington,Provably Efficient Reward-Agnostic Navigation with Linear Value Iteration.
489,489,Edward Vul,Massachusetts Institute of Technology,Josh Tenenbaum,MIT,On Reward-Free Reinforcement Learning with Linear Function Approximation.
490,490,Hamid R Maei,Stanford University,Rich Sutton,"DeepMind, U Alberta",On Efficiency in Hierarchical Reinforcement Learning.
491,491,Marek Petrik,IBM,Shlomo Zilberstein,Univ of Mass,Towards Minimax Optimal Reinforcement Learning in Factored Markov Decision Processes.
492,492,Odalric-Ambrym Maillard,INRIA,Remi Munos,Google DeepMind,Efficient Model-Based Reinforcement Learning through Optimistic Policy Search and Planning.
493,493,Matthias Hein,University of Tübingen,Matthias Hein,University of Tübingen,Belief-Dependent Macro-Action Discovery in POMDPs using the Value of Information.
494,494,Jonathan Huang,google.com,Carlos Guestrin,University of Washington,High-Throughput Synchronous Deep RL.
495,495,Jaakko Luttinen,Aalto University,Alexander Ilin,Helsinki University of Technology,AttendLight: Universal Attention-Based Reinforcement Learning Model for Traffic Signal Control.
496,496,Amarnag Subramanya,Google Inc.,Jeff A Bilmes,"University of Washington, Seattle",Dynamic Submodular Maximization.
497,497,Hamid R Maei,Stanford University,Rich Sutton,"DeepMind, U Alberta",Adaptive Shrinkage Estimation for Streaming Graphs.
498,498,Zhihua Zhang,Shanghai Jiao Tong University,guang dai,zju,Near-Optimal Comparison Based Clustering.
