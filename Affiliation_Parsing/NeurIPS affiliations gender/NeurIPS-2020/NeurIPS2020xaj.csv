,Unnamed: 0,first-author,first-author-affiliation,last-author,last-author-affiliation,title
179,179,Shuheng Zhou,ETH Zurich,Shuheng Zhou,ETH Zurich,Cascaded Text Generation with Markov Transformers.
180,180,Samuel Rota Bulò,Università Ca' Foscari,Marcello Pelillo,Università Ca' Foscari di Venezia,All Word Embeddings from One Embedding.
181,181,Arthur Choi,UCLA,Adnan Darwiche,UCLA,Data Diversification: A Simple Strategy For Neural Machine Translation.
182,182,Jonathan Huang,google.com,Carlos Guestrin,University of Washington,Learning Sparse Prototypes for Text Generation.
183,183,Siamac Fazli,TU Berlin,Klaus-Robert Müller,TU Berlin,A Discrete Variational Recurrent Topic Model without the Reparametrization Trick.
184,184,Menachem Fromer,Hebrew University,Amir Globerson,"Tel Aviv University, Google",AViD Dataset: Anonymized Videos from Diverse Countries.
185,185,Alekh Agarwal,UC Berkeley,Martin J Wainwright,UC Berkeley,Convolutional Tensor-Train LSTM for Spatio-Temporal Learning.
186,186,Garvesh Raskutti,SAMSI,Bin Yu,None,End-to-End Learning and Intervention in Games.
187,187,Paris Smaragdis,University of Illinois Urbana-Champaign,Bhiksha Raj,Carnegie Mellon University,Cross-validation Confidence Intervals for Test Error.
188,188,Lin Xiao,Facebook AI Research,Lin Xiao,Facebook AI Research,Learning Robust Decision Policies from Observational Data.
189,189,Emanuel Todorov,University of Washington,Emanuel Todorov,University of Washington,Improved Sample Complexity for Incremental Autonomous Exploration in MDPs.
190,190,Allie Fletcher,UCLA,Sundeep Rangan,Qualcomm,Self-Imitation Learning via Generalized Lower Bound Q-learning.
191,191,Martin A Zinkevich,Yahoo! Inc.,John Langford,None,An Improved Analysis of  (Variance-Reduced) Policy Gradient and Natural Policy Gradient Methods.
192,192,Volkan Cevher,EPFL,Volkan Cevher,EPFL,One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL.
193,193,Kamalika Chaudhuri,UCSD,Daniel Hsu,Columbia University,An operator view of policy gradient methods.
194,194,Mladen Kolar,University of Chicago,Eric Xing,Petuum Inc. /  Carnegie Mellon University,Robust Reinforcement Learning via Adversarial training with Langevin Dynamics.
195,195,Peter Orbanz,Columbia University,Peter Orbanz,Columbia University,Improving Sample Complexity Bounds for (Natural) Actor-Critic Algorithms.
196,196,Novi Quadrianto,University of Sussex and HSE,Dale Schuurmans,Google Brain & University of Alberta,How to Learn a Useful Critic? Model-based Action-Gradient-Estimator Policy Optimization.
197,197,Liefeng Bo,Intel Labs,Cristian Sminchisescu,Lund University/Google,The Value Equivalence Principle for Model-Based Reinforcement Learning.
198,198,Tetsuro Morimura,IBM,Kenji Doya,Okinawa Institute of Science and Technology Graduate University,Doubly Robust Off-Policy Value and Gradient Estimation for Deterministic Policies.
