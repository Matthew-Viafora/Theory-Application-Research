379,Yi Xu,The University of Iowa,Tianbao Yang,The University of Iowa,Stochastic Optimization for DC Functions and Non-smooth Non-convex Regularizers with Non-asymptotic Convergence
380,Qiuwei Li,Colorado School of Mines,Gongguo Tang,Colorado School of Mines,Alternating Minimizations Converge to Second-Order Optimal Solutions
381,Wen Sun,Carnegie Mellon University,Drew Bagnell,Carnegie Mellon University,Provably Efficient Imitation Learning from Observation Alone
382,Mehdi Fatemi,Microsoft Research,Samira Ebrahimi Kahou,Microsoft Research,Dead-ends and Secure Exploration in Reinforcement Learning
383,Mark Rowland,DeepMind,Will Dabney,DeepMind,Statistics and Samples in Distributional Reinforcement Learning
384,Zebang Shen,Zhejiang University,Chao Mi,Zhejiang University,Hessian Aided Policy Gradient
385,Elad Hazan,Princeton University,Abby Van Soest,Princeton University,Provably Efficient Maximum Entropy Exploration
386,Omer Gottesman,Harvard University,Finale Doshi-Velez,Harvard University,Combining parametric and nonparametric models for off-policy evaluation
387,Lin Yang,Princeton,Mengdi Wang,Princeton University,Sample-Optimal Parametric Q-Learning Using Linearly Additive Features
388,Andrea Tirinzoni,Politecnico di Milano,Marcello Restelli,Politecnico di Milano,Transfer of Samples in Policy Search via Multiple Importance Sampling
389,Chen Tessler,Technion,Shie Mannor,Technion,Action Robust Reinforcement Learning and Applications in Continuous Control
390,Shiau Hong Lim,IBM Research,Arnaud Autef,Ecole Polytechnique,Kernel-Based Reinforcement Learning in Robust Markov Decision Processes
391,Shiyin Lu,Nanjing University,Lijun Zhang,Nanjing University,Optimal Algorithms for Lipschitz Bandits with Heavy-tailed Rewards
392,Margaux Brégère,"CNRS Université Paris-Sud, Inria Paris, EDF R&D",Gilles Stoltz,Université paris Sud,Target Tracking for Contextual Bandits: Application to Demand Side Management
393,Vinay Praneeth Boda,LinkedIn Corp.,Prashanth L.A.,IIT Madras,Correlated bandits or: How to minimize mean-squared error online
394,Ping-Chun Hsieh,Texas A&M University,P R Kumar,Texas A & M University,Stay With Me: Lifetime Maximization Through Heteroscedastic Linear Bandits With Reneging
395,Branislav Kveton,Google Research,Mohammad Ghavamzadeh,Facebook AI Research,"Garbage In, Reward Out: Bootstrapping Exploration in Multi-Armed Bandits"
396,Julian Zimmert,University of Copenhagen,Chen-Yu Wei,University of Southern California,Beating Stochastic and Adversarial Semi-bandits Optimally and Simultaneously
397,Kwang-Sung Jun,Boston University,Robert Nowak,University of Wisconsion-Madison,Bilinear Bandits with Low-rank Structure 
398,Shuai Li,The Chinese University of Hong Kong,Csaba Szepesvari,DeepMind/University of Alberta,Online Learning to Rank with Features
