319,Jingkai Mao,Man AHL,Shimon Whiteson,University of Oxford,A Baseline for Any Order Gradient Estimation in Stochastic Computation Graphs
320,Guido Novati,ETH Zurich,Petros Koumoutsakos,ETH Zurich,Remember and Forget for Experience Replay
321,Fritz Obermeyer,Uber AI Labs,Noah Goodman,Uber AI Labs,Tensor Variable Elimination for Plated Factor Graphs
322,zenna Tavares,MIT,Rajesh Ranganath,New York University,Predicate Exchange: Inference with Declarative Knowledge
323,Andrew Miller,Columbia University,Sendhil Mullainathan,University of Chicago,Discriminative Regularization for Latent Variable Models with Applications to Electrocardiography
324,Ping Liang Tan,University of Cambridge,Robert Peharz,University of Cambridge,Hierarchical Decompositional Mixtures of Variational Autoencoders
325,Ya-Ping Hsieh,EPFL,Volkan Cevher,EPFL,Finding Mixed Nash Equilibria of Generative Adversarial Networks
326,Thomas Kipf,University of Amsterdam,Peter Battaglia,DeepMind,CompILE: Compositional Imitation Learning and Execution
327,Luigi Antelmi,"UCA, Inria",Marco Lorenzi,"Inria UCA,",Sparse Multi-Channel Variational Autoencoder for the Joint Analysis of Heterogeneous Data
328,Yuan Gao,Xi'an Jiaotong University,Shunkang Zhang,HKUST,Deep Generative Learning via Variational Gradient Flow
329,Jonathan Ho,UC Berkeley,Pieter Abbeel,OpenAI / UC Berkeley,Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design
330,Halley R Young,University of Pennsylvania,Mayur Naik,University of Pennsylvania,Learning Neurosymbolic Generative Models via Program Synthesis
331,Hongyang Zhang,CMU & TTIC,Michael Jordan,UC Berkeley,Theoretically Principled Trade-off between Robustness and Accuracy
332,Kevin Roth,ETH Zurich,Thomas Hofmann,ETH Zurich,The Odds are Odd: A Statistical Test for Detecting Adversarial Examples
333,Yuzhe Yang,MIT,Dina Katabi,MIT,ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation
334,Jeremy Cohen,Carnegie Mellon University,Zico Kolter,Carnegie Mellon University / Bosch Center for AI,Certified Adversarial Robustness via Randomized Smoothing
335,Yao Qin,"University of California, San Diego",Colin Raffel,Google,"Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition"
336,Seungyong Moon,Seoul National University,Hyun Oh Song,Seoul National University,Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial Optimization
337,Eric Wong,Carnegie Mellon University,Zico Kolter,Carnegie Mellon University / Bosch Center for AI,Wasserstein Adversarial Examples via Projected Sinkhorn Iterations
338,Chen Zhu,University of Maryland,Tom Goldstein,University of Maryland,Transferable Clean-Label Poisoning Attacks on Deep Neural Nets
