99,Zaiyi Chen,Cainiao AI,Tianbao Yang,The University of Iowa,Katalyst: Boosting Convex Katayusha for  Non-Convex Problems with a  Large Condition Number
100,Romain Laroche,Microsoft Research,Remi Tachet des Combes,Microsoft Research Montreal,Safe Policy Improvement with Baseline Bootstrapping
101,Borislav Mavrin,University of Alberta,Yaoliang Yu,University of Waterloo,Distributional Reinforcement Learning for Efficient Exploration
102,Matteo Papini,Politecnico di Milano,Marcello Restelli,Politecnico di Milano,Optimistic Policy Optimization via Multiple Importance Sampling
103,zhengyao jiang,University of Liverpool,Shan Luo,University of Liverpool,Neural Logic Reinforcement Learning
104,Goran Radanovic,Harvard University,Adish Singla,Max Planck Institute (MPI-SWS),Learning to Collaborate in Markov Decision Processes
105,Ching-An Cheng,Georgia Tech,Byron Boots,Georgia Tech,Predictor-Corrector Policy Optimization
106,Kelvin Xu,"University of California, Berkeley",Chelsea Finn,"Stanford, Google, UC Berkeley",Learning a Prior over Intent via Meta-Inverse Reinforcement Learning
107,Carles Gelada,Google Brain,Marc Bellemare,Google Brain,DeepMDP: Learning Continuous Latent Space Models for Representation Learning
108,Josiah Hanna,UT Austin,Peter Stone,University of Texas at Austin,Importance Sampling Policy Evaluation with an Estimated Behavior Policy
109,alexis jacq,EPFL,Olivier Pietquin,GOOGLE BRAIN,Learning from a Learner
110,Joshua Romoff,McGill University,Emma Brunskill,Stanford University,Separable value functions across time-scales
111,Yash Chandak,University of Massachusetts Amherst,Philip Thomas,University of Massachusetts Amherst,Learning Action Representations for Reinforcement Learning
112,Ben London,Amazon,Ted Sandler,Amazon.com,Bayesian Counterfactual Risk Minimization
113,Anna Harutyunyan,DeepMind,Doina Precup,DeepMind,Per-Decision Option Discounting
114,Andrea Zanette,Stanford University,Emma Brunskill,Stanford University,Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds
115,Matthieu Geist,Google,Olivier Pietquin,GOOGLE BRAIN,A Theory of Regularized Markov Decision Processes
116,Yuu Jinnai,Brown University,George Konidaris,Brown,Discovering Options for Exploration by Minimizing Cover Time
117,Christoph Dann,Carnegie Mellon University,Emma Brunskill,Stanford University,Policy Certificates: Towards Accountable Reinforcement Learning
118,Robert Dadashi,Google AI Residency Program,Dale Schuurmans,Google / University of Alberta,The Value Function Polytope in Reinforcement Learning
