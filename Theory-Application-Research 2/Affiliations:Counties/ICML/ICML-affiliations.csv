,Unnamed: 0,Unnamed: 0.1,first-author-affiliation,last-author-affiliation,title
0,0,0.0,"IBM T. J. Watson Research Center, Yorktown Heights, NY","IBM T. J. Watson Research Center, Yorktown Heights, NY",the role of machine learning in business optimization.
1,1,1.0," University of Oxford, Oxford, UK"," University of Oxford, Oxford, UK",fab-map: appearance-based place recognition and mapping using a learned visual vocabulary model.
2,2,2.0, University of Chicago, UC Irvine,discriminative latent variable models for object detection.
3,3,3.0," Microsoft Research Ltd., Cambridge, UK"," Microsoft Research Ltd., Cambridge, UK",web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft's bing search engine.
4,4,4.0," School of Informatics and Computing, Indiana University, Bloomington"," School of Informatics and Computing, Indiana University, Bloomington",music plus one and machine learning.
5,5,5.0," MIT Computer Science & Artificial Intelligence Lab, Cambridge, MA"," MIT Computer Science & Artificial Intelligence Lab, Cambridge, MA",climbing the tower of babel: unsupervised multilingual learning.
6,6,6.0," EECS Department, UC Berkeley"," EECS and Statistics Department, UC Berkeley",detecting large-scale system problems by mining console logs.
7,7,7.0," LAL/LRI, University of Paris-Sud, CNRS, Orsay, France"," LAL/LRI, University of Paris-Sud, CNRS, Orsay, France",surrogating the surrogate: accelerating gaussian-process-based global optimization with a mixture cross-entropy algorithm.
8,8,8.0," Department of CSA, Indian Institute of Science, INDIA"," Faculty of Industrial Engg. and Management, Technion, Haifa, ISRAEL",robust formulations for handling uncertainty in kernel matrices.
9,9,9.0," Department of Computer Science, University of Maryland, College Park, MD"," Department of Computer Science, University of Maryland, College Park, MD",active learning for networked data.
10,10,10.0," Department of Computer Science, Princeton University, Princeton, NJ"," Department of Operations Research and Information Engineering , Cornell University, Ithaca, NY",distance dependent chinese restaurant processes.
11,11,11.0," Machine Learning Group, Computer Science Department, Faculty of Sciences, ULB, Université Libre de Bruxelles, Brussels, Belgium"," Machine Learning Group, Computer Science Department, Faculty of Sciences, ULB, Université Libre de Bruxelles, Brussels, Belgium",causal filter selection in microarray data.
12,12,12.0,"LIP6, Université Paris 6. 104, Paris, France"," Google., New York, NY",label ranking under ambiguous supervision for learning semantic correspondences.
13,13,13.0,"INRIA - WILLOW Project (INRIA/ENS/CNRS UMR 8548), Paris, France and Courant Institute of Mathematical Sciences New York University, NY"," Courant Institute of Mathematical Sciences New York University, NY",a theoretical analysis of feature pooling in visual recognition.
14,14,14.0," LIPADE, Universite Paris Descartes, Paris, FRANCE"," LIPADE, Universite Paris Descartes, Paris, FRANCE",multi-agent learning experiments on repeated matrix games.
15,15,15.0," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA"," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA",learning tree conditional random fields.
16,16,16.0," Department of Computer Science, Technion, Haifa, Israel"," Google, Mountain View, CA",finding planted partitions in nearly linear time using arrested spectral clustering.
17,17,17.0," LAL/LRI, University of Paris-Sud, CNRS, Orsay, France Research Group on Artificial Intelligence of the Hungarian Academy of Sciences and University of Szeged, Szeged, Hungary"," LAL/LRI, University of Paris-Sud, CNRS, Orsay, France",fast boosting using adversarial bandits.
18,18,18.0," Computer Science Division, University of California, Berkeley, CA"," Department of Psychology, University of California, Berkeley, CA",modeling transfer learning in human categorization with the hierarchical dirichlet process.
19,19,19.0," Electrical Engineering and Computer Science, School of Engineering, University of California, Merced"," Electrical Engineering and Computer Science, School of Engineering, University of California, Merced",the elastic embedding algorithm for dimensionality reduction.
20,20,20.0," DSI, Università di Milano, Italy"," DSI, Università di Milano, Italy",random spanning trees and the prediction of weighted graphs.
21,21,21.0," Department of Computer Science, University of Texas, Austin, Texas"," Department of Computer Science, University of Texas, Austin, Texas","convergence, targeted optimality, and safety in multiagent learning."
22,22,22.0," Department of Computer Science, University of California, Irvine, CA"," Department of Computer Science, University of California, Irvine, CA",dynamical products of experts for modeling financial time series.
23,23,23.0," Mathematics and Computer Science, Marburg University, Marburg, Germany"," Mathematics and Computer Science, Marburg University, Marburg, Germany",label ranking methods based on the plackett-luce model.
24,24,24.0," Mathematics and Computer Science, Marburg University, Marburg, Germany"," Mathematics and Computer Science, Marburg University, Marburg, Germany",graded multilabel classification: the ordinal case.
25,25,0.0," University of Wisconsin-Madison, Madison, WI"," University of Wisconsin-Madison, Madison, WI",comparing clusterings in space.
26,26,1.0," Google Research, New York, NY"," Courant Institute of Mathematical Sciences, New York, NY",two-stage learning kernel algorithms.
27,27,2.0," Dept. of Computer Science, K.U. Leuven, Heverlee, Belgium"," Dept. of Computer Science, K.U.Leuven, Heverlee, Belgium",fast neighborhood subgraph pairwise distance kernel.
28,28,3.0," Human Language Technology Research Institute, University of Texas at Dallas, Richardson, TX"," Human Language Technology Research Institute, University of Texas at Dallas, Richardson, TX",mining clustering dimensions.
29,29,4.0," Department of Computer Science & Engineering, University of Washington, Seattle, WA"," Department of Computer Science & Engineering, University of Washington, Seattle, WA",bottom-up learning of markov network structure.
30,30,5.0," Mathematics and Computer Science, Marburg University, Marburg, Germany and Institute of Computing Science, Poznań University of Technology, Poznań, Poland"," Mathematics and Computer Science, Marburg University, Marburg, Germany",bayes optimal multilabel classification via probabilistic classifier chains.
31,31,6.0," Computer Vision Laboratory, ETH Zurich, Zurich, Switzerland"," Computer Vision Laboratory, ETH Zurich, Zurich, Switzerland",a conditional random field for multiple-instance learning.
32,32,7.0," College of Computing, Georgia Institute of Technology, Atlanta, Georgia"," College of Computing, Georgia Institute of Technology, Atlanta, Georgia",asymptotic analysis of generative semi-supervised learning.
33,33,8.0," Biomathematics and Statistics Scotland, JCMB, Edinburgh, UK and Institute for Adaptive and Neural Computation, School of Informatics, University of Edinburgh"," Biomathematics and Statistics Scotland, JCMB, Edinburgh, UK",heterogeneous continuous dynamic bayesian networks with flexible structure and inter-time segment information sharing.
34,34,9.0," Victoria University of Wellington, Wellington, New Zealand"," Statistical Machine Learning Group & AI Group, NICTA & ANU, Canberra, Australia",temporal difference bayesian model averaging: a bayesian perspective on adapting lambda.
35,35,10.0," University of Massachusetts Amherst, Amherst, MA"," University of Massachusetts Amherst, Amherst, MA",high-performance semi-supervised learning using discriminatively constrained generative models.
36,36,11.0," Computer Science Division, University of California, Berkeley, CA"," Computer Science Division and Department of Statistics, University of California, Berkeley, CA",on the consistency of ranking algorithms.
37,37,12.0," Computer Science & Engineering and Applied Mathematics, University of Washington, Seattle"," Computer Science & Engineering and Applied Mathematics, University of Washington, Seattle",inverse optimal control with linearly-solvable mdps.
38,38,13.0," School of Computer Science and Engineering, Hebrew University, Jerusalem, Israel"," Institute of Mathematics, Hebrew University, Jerusalem, Israel",continuous-time belief propagation.
39,39,14.0," School of Engineering, Bar-Ilan University, Ramat-Gan, Israel"," School of Engineering, Bar-Ilan University, Ramat-Gan, Israel",a nonparametric information theoretic clustering algorithm.
40,40,15.0,"LRI, CNRS UMR 8623 & INRIA-Saclay, Orsay, FRANCE","LRI, CNRS UMR 8623 & INRIA-Saclay, Orsay, FRANCE",feature selection as a one-player game.
41,41,16.0," Department of Computer Science, Princeton University, Princeton, NJ"," Department of Computer Science, Princeton University, Princeton, NJ",a language-based approach to measuring scholarly impact.
42,42,17.0," Faculty of IE&M, Technion - Israel Institute of Technology, Haifa, Israel","MSIS Department and RUTCOR, Rutgers University, 640 Bartholomew Road, Piscataway NJ",boosting classifiers with tightened l0-relaxation penalties.
43,43,18.0," Courant Institute, New York University, New York, NY"," Courant Institute, New York University, New York, NY",learning fast approximations of sparse coding.
44,44,19.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",boosted backpropagation learning for training deep modular networks.
45,45,20.0," University of Washington, Seattle, WA"," University of Washington, Seattle, WA",interactive submodular set cover.
46,46,21.0," Department of Computer Science and Engineering, Indian Institute of Technology, Delhi, India"," Microsoft Research India, Bangalore, India",large scale max-margin multi-label classification with priors.
47,47,22.0," Carnegie Mellon Univeresity, Pittsburgh, PA"," Carnegie Mellon Univeresity, Pittsburgh, PA",active learning for multi-task adaptive filtering.
48,48,23.0," Stony Brook University, Stony Brook, NY"," Stony Brook University, Stony Brook, NY",multi-task learning of gaussian graphical models.
49,49,24.0,"Mines ParisTech, Centre for Computational Biology, Fontainebleau, France and Institut Curie, Paris, France and INSERM, U900, Paris, France","Mines ParisTech, Centre for Computational Biology, Fontainebleau, France and Institut Curie, Paris, France and INSERM, U900, Paris, France",on learning with kernels for unordered pairs.
50,50,0.0," Institute of Theoretical Computer Science, ETH Zurich, Zurich, Switzerland"," Institute of Theoretical Computer Science, ETH Zurich, Zurich, Switzerland",a simple algorithm for nuclear norm regularized problems.
51,51,1.0," Max Planck Institute for Biological Cybernetics, Tübingen, Germany"," Max Planck Institute for Biological Cybernetics, Tübingen, Germany",telling cause from effect based on high-dimensional observations.
52,52,2.0,"INRIA - WILLOW Project, Laboratoire d'Informatique de l'Ecole Normale Supérieure (INRIA/ENS/CNRS UMR 8548) Paris. France","INRIA - WILLOW Project, Laboratoire d'Informatique de l'Ecole Normale Supérieure (INRIA/ENS/CNRS UMR 8548) Paris. France",proximal methods for sparse hierarchical dictionary learning.
53,53,3.0," Arizona State University, Tempe, AZ"," NEC Laboratories America, Inc., Cupertino, CA",3d convolutional neural networks for human action recognition.
54,54,4.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",accelerated dual decomposition for map inference.
55,55,5.0," Department of Computer Science, The University of Texas at Austin, Austin Texas"," Department of Computer Science, The University of Texas at Austin, Austin Texas",efficient selection of multiple bandit arms: theory and practice.
56,56,6.0," Dept. of Computer Science, University of Texas, Austin, TX"," Dept. of Computer Science, University of Texas, Austin, TX",a scalable trust-region algorithm with application to mixed-norm regression.
57,57,7.0," Robotics Institute, Carnegie Mellon University, PA"," Robotics Institute, Carnegie Mellon University, PA",local minima embedding.
58,58,8.0," Robotics Institute, Carnegie Mellon University, PA"," Robotics Institute, Carnegie Mellon University, PA",gaussian processes multiple instance learning.
59,59,9.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",tree-guided group lasso for multi-task regression with structured sparsity.
60,60,10.0," Department of Computer Science & Engineering, University of Washington, Seattle, WA"," Department of Computer Science & Engineering, University of Washington, Seattle, WA",learning markov logic networks using structural motifs.
61,61,11.0," California Institute of Technology, Computer Science Department"," Ecole Polytechnique Federale de Lausanne, STI-IEL-LIONS & Idiap Research Institute",submodular dictionary selection for sparse representation.
62,62,12.0," TU Berlin, Machine Learning and Robotics Group, Berlin, Germany"," TU Berlin, Machine Learning and Robotics Group, Berlin, Germany",probabilistic backward and forward reasoning in stochastic relational worlds.
63,63,13.0," Department of Scientific Computing, Florida State University, Tallahassee, Florida"," Department of Statistics, Florida State University, Tallahassee, Florida",supervised aggregation of classifiers using artificial prediction markets.
64,64,14.0," INRIA Lille - Nord Europe, Team SequeL, Villeneuve d'Ascq, France"," INRIA Lille - Nord Europe, Team SequeL, Villeneuve d'Ascq, France",bayesian multi-task reinforcement learning.
65,65,15.0," INRIA Lille - Nord Europe, Team SequeL, Villeneuve d'Ascq, France"," INRIA Lille - Nord Europe, Team SequeL, Villeneuve d'Ascq, France",finite-sample analysis of lstd.
66,66,16.0," Microsoft Research, Cambridge, UK"," Microsoft Research, Cambridge, UK",a fast natural newton method.
67,67,17.0," Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"," Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China and MOE-MS Key Lab. for Intel. Comp. and Intel. Sys., Shanghai Jiao Tong University, Shanghai, China",making large-scale nyström approximation possible.
68,68,18.0," Computer Science Division, University of California, Berkeley, CA"," Toyota Technological Institute at Chicago, Chicago, IL",on the interaction between norm and dimensionality: multiple regimes in learning.
69,69,19.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",power iteration clustering.
70,70,20.0," Shanghai Jiao Tong University, Shanghai, China"," Shanghai Jiao Tong University, Shanghai, China",robust subspace segmentation by low-rank representation.
71,71,21.0," Department of Electrical and Computer Engineering, National University of Singapore, Singapore"," Department of Electrical and Computer Engineering, National University of Singapore, Singapore",robust graph mode seeking by graph shift.
72,72,22.0," Department of Electrical Engineering, Columbia University, New York, NY"," Department of Electrical Engineering, Columbia University, New York, NY",large graph construction for scalable semi-supervised learning.
73,73,23.0," IBM T.J. Watson Research Center, Yorktown Heights, NY"," Harvard Medical School, Harvard University, Boston, MA",learning temporal causal graphs for relational time-series analysis.
74,74,24.0," University of Michigan, Ann Arbor, MI"," University of Michigan, Ann Arbor, MI",efficient reinforcement learning with multiple reward functions for randomized controlled trial analysis.
75,75,25.0," Google, Mountain View, CA"," Computer Science Department, Columbia University, New York",restricted boltzmann machines are hard to approximately evaluate or simulate.
76,76,0.0," Computer Science Division, University of California, Berkeley, CA"," Computer Science Division and Department of Statistics, University of California, Berkeley, CA",mixed membership matrix factorization.
77,77,1.0," Department of Computing Science, University of Alberta, Edmonton, Canada"," Department of Computing Science, University of Alberta, Edmonton, Canada",toward off-policy learning control with function approximation.
78,78,2.0," School of Computer Science, The Australian National University, Canberra, Australia"," School of Computer Science, The Australian National University, Canberra, Australia",constructing states for reinforcement learning.
79,79,3.0," University of Toronto, Ontario, Canada"," University of Toronto, Ontario, Canada",deep learning via hessian-free optimization.
80,80,4.0," University of Toronto, Ontario, Canada"," University of Toronto, Ontario, Canada",learning the linear dynamical system with asos.
81,81,5.0," Department of Electrical and Computer Engineering, Northeastern University, Boston, MA"," Department of Electrical and Computer Engineering, Northeastern University, Boston, MA",from transformation-based dimensionality reduction to feature selection.
82,82,6.0," Statistical Visual Computing Laboratory, University of California, San Diego, La Jolla, CA"," Statistical Visual Computing Laboratory, University of California, San Diego, La Jolla, CA","risk minimization, probability elicitation, and cost-sensitive svms."
83,83,7.0," NICTA and Australian National University, Canberra, Australia"," NICTA and Australian National University, Canberra, Australia",exploiting data-independence for fast belief-propagation.
84,84,8.0," Department of Computer Science and Engineering, University of California, San Diego, CA"," Department of Electrical and Computer Engineering, University of California, San Diego, CA",metric learning to rank.
85,85,9.0,,,learning efficiently with approximate inference via dual losses.
86,86,10.0," Dep. of Computer Science, University of Toronto, Toronto ON, CANADA"," Dep. of Med. Research, University of Toronto, Toronto ON, CANADA",deep supervised t-distributed embedding.
87,87,11.0," IBM Research - Tokyo, Kanagawa, Japan"," Kyoto University, Kyoto-shi, Kyoto, Japan",nonparametric return distribution approximation for reinforcement learning.
88,88,12.0," Department of Computer Science, University of Toronto, Toronto, ON, Canada"," Department of Computer Science, University of Toronto, Toronto, ON, Canada",rectified linear units improve restricted boltzmann machines.
89,89,13.0," ECE Department, Northeastern University, Boston, MA"," EECS and Statistics Departments, University of California, Berkeley, CA",multiple non-redundant spectral clustering views.
90,90,14.0," Artificial Intelligence Research Institute (IIIA-CSIC), Bellaterra, (Spain)"," Artificial Intelligence Research Institute (IIIA-CSIC), Bellaterra, (Spain)",multiagent inductive learning: an argumentation-based approach.
91,91,15.0," Department of ECE, Duke University, Durham, NC"," Department of ECE, Duke University, Durham, NC",a stick-breaking construction of the beta process.
92,92,16.0," The University of Texas at Austin, Austin, TX"," The University of Texas at Austin, Austin, TX",boosting for regression transfer.
93,93,17.0," Department of Computer Science, University of Massachusetts, Amherst, MA"," Department of Computer Science, University of Massachusetts, Amherst, MA",feature selection using regularization in approximate linear programs for markov decision processes.
94,94,18.0," Department of Computing Science, University of Alberta, AB, Canada"," Department of Computing Science, University of Alberta, AB, Canada",budgeted distribution learning of belief net parameters.
95,95,19.0," McGill University, School of Computer Science, Montreal, QC, CANADA"," McGill University, School of Computer Science, Montreal, QC, CANADA",approximate predictive representations of partially observable systems.
96,96,20.0," Department of Computer Science, University of Texas, Austin, TX"," Department of Computer Science, University of Texas, Austin, TX",spherical topic models.
97,97,21.0," INRIA Lille, Villeneuve d'Ascq, France"," INRIA Lille, Villeneuve d'Ascq, France",clustering processes.
98,98,22.0," University of Cambridge, Cambridge, United Kingdom"," University of Cambridge, UK & Max Planck Institute for Biological Cybernetics, Tubingen, Germany",gaussian process change point models.
99,99,23.0," University of Tsukuba, Tsukuba, Ibaraki, Japan and Japan Science and Technology Agency, Kawaguchi, Saitama, Japan"," University of Tsukuba, Tsukuba, Ibaraki, Japan",online prediction with privacy.
100,100,24.0," Brain and Cognitive Sciences and CSAIL, MIT, Cambridge, MA"," Brain and Cognitive Sciences and CSAIL, MIT, Cambridge, MA",learning deep boltzmann machines using adaptive mcmc.
101,101,0.0," University of Potsdam, Department of Computer Science, Potsdam, Germany"," University of Potsdam, Department of Computer Science, Potsdam, Germany",active risk estimation.
102,102,1.0," LORIA - INRIA Lorraine - Campus Scientifique - Vandœuvre-lès-Nancy, FRANCE"," LORIA - INRIA Lorraine - Campus Scientifique - Vandœuvre-lès-Nancy, FRANCE",should one compute the temporal difference fix point or minimize the bellman residual? the unified oblique projection view.
103,103,2.0," Massachusetts Institute of Technology, Cambridge, Massachusetts"," Massachusetts Institute of Technology, Cambridge, Massachusetts",application of machine learning to epileptic seizure detection.
104,104,3.0," Microsoft Research, Mountain View CA"," Microsoft Research, Mountain View CA",learning optimally diverse rankings over large document collections.
105,105,4.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," Yahoo! Research, Santa Clara, CA",hilbert space embeddings of hidden markov models.
106,106,5.0," Berlin Institute of Technology, Berlin, Germany and Friedrich Miescher Laboratory, Tübingen, Germany"," Czech Technical University in Prague, Praha, Czech Republic",coffin: a computational framework for linear svms.
107,107,6.0," Computer Science & Engineering, University of Michigan, Ann Arbor, MI"," Department of Psychology, University of Michigan, Ann Arbor, MI",internal rewards mitigate agent boundedness.
108,108,7.0," California Institute of Technology, Pasadena, CA"," Saarland University, Saarbrücken, Germany",gaussian process optimization in the bandit setting: no regret and experimental design.
109,109,8.0," University of Alberta, Edmonton, Canada"," University of Alberta, Edmonton, Canada",model-based reinforcement learning with nearly tight exploration complexity bounds.
110,110,9.0," School of Computer Engineering, Nanyang Technological University, Singapore"," School of Computer Engineering, Nanyang Technological University, Singapore",learning sparse svm for feature selection on very high dimensional datasets.
111,111,10.0," Centre for Theoretical Neuroscience, University of Waterloo, Waterloo ON, CANADA"," Centre for Theoretical Neuroscience, University of Waterloo, Waterloo ON, CANADA",deep networks for robust visual recognition.
112,112,11.0," Laboratory of Mathematics LMI, INSA de Rouen, Saint-Etienne-du-Rouvray, FRANCE"," Laboratory of Theoretical and Applied Computer Science, UFR MIM, Metz University, Metz, FRANCE",a dc programming approach for sparse eigenvalue problem.
113,113,12.0, LORIA - INRIA Lorraine - Vandœuvre-lès-Nancy - FRANCE, LORIA - INRIA Lorraine - Vandœuvre-lès-Nancy - FRANCE,least-squares a policy iteration: bias-variance trade-off in control problems.
114,114,13.0," Department of Statistics, University of California, Berkeley, CA"," Department of EECS and Department of Statistics, University of California, Berkeley, CA",an analysis of the convergence of graph laplacians.
115,115,14.0," Department of Mathematical Informatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan"," Department of Mathematical Informatics, The University of Tokyo, Bunkyo-ku, Tokyo, Japan",a fast augmented lagrangian algorithm for learning low-rank matrices.
116,116,15.0," Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan"," Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan",one-sided support vector regression for multiclass cost-sensitive classification.
117,117,16.0," Computer Science Department, University of Basel, Basel, Switzerland"," Computer Science Department, University of Basel, Basel, Switzerland",the translation-invariant wishart-dirichlet process for clustering distance data.
118,118,17.0," Rutgers University, Piscataway, NJ"," Princeton University, Princeton, NJ",generalizing apprenticeship learning across hypothesis classes.
119,119,18.0," National Key Laboratory for Novel Software Technology, Nanjing University, China"," National Key Laboratory for Novel Software Technology, Nanjing University, China",a new analysis of co-training.
120,120,19.0," Department of Computer and Information Sciences, Temple University, Philadelphia, PA"," Department of Computer and Information Sciences, Temple University, Philadelphia, PA",multi-class pegasos on a budget.
121,121,20.0," Department of Engineering, University of Cambridge, Cambridge, UK"," Department of Computer Science, Princeton University, Princeton, NJ",the ibp compound dirichlet process and its application to focused topic modeling.
122,122,21.0," Department of Computer Science, Hefei University of Technology, Hefei, Anhui, China and Department of Computer Science, University of Vermont, Burlington, VT"," Department of Computer Science, University of Massachusetts Boston, Boston, MA",online streaming feature selection.
123,123,22.0," RL Laboratory, Department of Computer Science, Rutgers University, Piscataway, NJ"," RL Laboratory, Department of Computer Science, Rutgers University, Piscataway, NJ",classes of multiagent q-learning dynamics with ε-greedy exploration.
124,124,23.0," Cluster of Excellence MMCI, Saarland University and MPI Informatics, Saarbruecken, Germany"," Department of Computer Science & Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong",simple and efficient multiple kernel learning by group lasso.
125,125,0.0," Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong"," Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong",online learning for group lasso.
126,126,1.0," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI"," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI",learning from noisy side information by generalized maximum entropy model.
127,127,2.0," Department of Computer Science, University of Helsinki, Finland"," Department of Computer Science, University of Helsinki, Finland",convergence of least squares temporal difference methods under general conditions.
128,128,3.0," NEC Laboratories America, Cupertino, CA"," Rutgers University, Piscataway, NJ",improved local coordinate coding using local tangents.
129,129,4.0," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA"," The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",projection penalties: dimension reduction without loss.
130,130,5.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",conditional topic random fields.
131,131,6.0," Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI"," Department of Educational Psychology, University of Wisconsin-Madison, Madison, WI",cognitive models of test-item effects in human category learning.
132,132,7.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",modeling interaction via the principle of maximum causal entropy.
133,133,0.0," Department of Electrical Engineering, Columbia University, New York, NY"," Department of Electrical Engineering, Columbia University, New York, NY",hashing with graphs.
134,134,1.0," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong"," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong",efficient sparse modeling with automatic feature grouping.
135,135,2.0," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong"," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong",multi-label classification on tree- and dag-structured hierarchies.
136,136,3.0, IBM T.J. Watson Research Center, IBM T.J. Watson Research Center,a graph-based framework for multi-task multi-view learning.
137,137,4.0," Centre for Quantum Computation & Intelligent Systems, FEIT, University of Technology, Sydney, NSW, Australia"," Centre for Quantum Computation & Intelligent Systems, FEIT, University of Technology, Sydney, NSW, Australia",godec: randomized low-rank & sparse matrix decomposition in noisy case.
138,138,5.0," Ecole Normale Supérieure, HEC Paris, CNRS, France"," Department of Electrical Engineering, Technion, Haifa, Israel",unimodal bandits.
139,139,6.0," Max Planck Institute for Intelligent Systems, Tübingen, Germany"," Department of Information Engineering, University of Padova, Padova, Italy",learning output kernels with block coordinate descent.
140,140,7.0," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan"," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan",on information-maximization clustering: tuning parameter selection and analytic solution.
141,141,8.0," CEREGMIA — Univ. Antilles-Guyane, Schoelcher, Martinique, France"," Sony Computer Science Laboratories, Inc., Shinagawa-Ku, Tokyo, Japan","on tracking portfolios with certainty equivalents on a generalization of markowitz model: the fool, the wise and the adaptive."
142,142,9.0," University of California, San Diego, CA"," University of California, San Diego, CA",multiple instance learning with manifold bags.
143,143,10.0," School of Information Technology and Engineering, University of Ottawa, Canada"," School of Information Technology and Engineering, University of Ottawa, Canada and Institute for Computer Science, Polish Academy of Sciences, Warsaw, Poland",large scale text classification using semi-supervised multinomial naive bayes.
144,144,11.0," Department of Mathematics, Stanford University, Stanford, CA"," Computer Science Division, UC Berkeley, Berkeley, CA",implementing regularization implicitly via approximate eigenvector computation.
145,145,12.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",parsing natural scenes and natural language with recursive neural networks.
146,146,13.0," Department of Computer Science, University of Massachusetts, Amherst, MA"," Department of Computer Science, University of Massachusetts, Amherst, MA",conjugate markov decision processes.
147,147,14.0," Department of Computer Science, University of Toronto"," Department of Computer Science, University of Toronto",learning mallows models with pairwise preferences.
148,148,15.0," Dept. of Electrical Engineering and Computer Science, and of Statistics, University of Michigan, Ann Arbor, MI"," Dept. of Electrical Engineering and Computer Science, and of Statistics, University of Michigan, Ann Arbor, MI",surrogate losses and regret bounds for cost-sensitive classification with example-dependent costs.
149,149,16.0," Dept. of CSE, IIT-Bombay, Mumbai, INDIA"," Dept. of CSE, IIT-Bombay, Mumbai, INDIA",efficient rule ensemble learning using hierarchical kernels.
150,150,17.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA and Instituto de Telecomunicações, Instituto Superior Técnico, Lisboa, Portugal"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",an augmented lagrangian approach to constrained map inference.
151,151,18.0," Computer Science Department, Carnegie Mellon University, Pittsburgh, PA"," Computer Science Department, Carnegie Mellon University, Pittsburgh, PA",time series clustering: complex is simpler!.
152,152,19.0," Department of Computer Science, Royal Holloway University of London, Egham, United Kingdom"," Department of Computer Science, Royal Holloway University of London, Egham, United Kingdom",inference of inversion transduction grammars.
153,153,20.0," Department of Mathematics, Yunnan Normal University, Kunming, Yunnan, China"," Department of Computer Science & Engineering, Nanjing University of Aeronautics & Astronautics, China",bcdnpkl: scalable non-parametric kernel learning using block coordinate descent.
154,154,21.0," School of Computer Engineering, Nanyang Technological University, Singapore"," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI",online auc maximization.
155,155,0.0," H. John Heinz III College, Carnegie Mellon University, Pittsburgh, PA"," Department of Computer Science, Cornell University, Ithaca, NY",beat the mean bandit.
156,156,1.0," DSI, Università degli Studi di Milano, Milano, Italy"," Idiap Research Institute, Centre du Parc, Martigny, Switzerland and École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland",ultra-fast optimization algorithm for sparse multi kernel learning.
157,157,2.0," University of Kansas, Lawrence, KS"," University of Kansas, Lawrence, KS",estimating the bayes point using linear knapsack problems.
158,158,3.0," Computer Science Department, UC Santa Cruz", Google,on the necessity of irrelevant variables.
159,159,4.0," Modelling of Cognitive Processes, Bernstein Center for Computational Neuroscience and TU Berlin. Franklinstr. Berlin, Germany"," ENSAE-CREST, Malakoff, France",abc-ep: expectation propagation for likelihood-free bayesian computation.
160,160,5.0," Departement d'informatique et de genie logiciel, Universite Laval, Quebec, Canada"," Departement d'informatique et de genie logiciel, Universite Laval, Quebec, Canada",a pac-bayes sample compression approach to kernel methods.
161,161,6.0," Department of Electrical Engineering, The Technion - Israel Institute of Technology, Haifa, Israel"," Department of Electrical Engineering, The Technion - Israel Institute of Technology, Haifa, Israel",integrating partial model knowledge in model free rl algorithms.
162,162,7.0," Universidad Autónoma de Madrid and Instituto de Ingeniería del Conocimiento, Madrid, Spain"," MPI for Intelligent Systems, Tubingen, Germany",fast newton-type methods for total variation regularization.
163,163,8.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",parallel coordinate descent for l1-regularized loss minimization.
164,164,9.0," Duke University, Durham, NC"," Duke University, Durham, NC",approximate dynamic programming for storage problems.
165,165,10.0," Max Planck Institute for Intelligent Systems, Tübingen, Germany"," University of Washington, Seattle, WA",online submodular minimization for combinatorial structures.
166,166,11.0," University of Washington, Seattle, WA"," University of Washington, Seattle, WA",simultaneous learning and covering with adversarial noise.
167,167,12.0," Computer Science Department, Purdue University, West Lafayette, IN"," Computer Science Department, Purdue University, West Lafayette, IN",relational active learning for joint collective classification models.
168,168,13.0," Department of Computer Science, University of Maryland, College Park, MD"," Department of Computer Science, University of Maryland, College Park, MD",a co-training approach for multi-view spectral clustering.
169,169,14.0," Department of Electrical Engineering, Technion, Haifa, Israel"," Department of Electrical Engineering, Technion, Haifa, Israel",learning from multiple outlooks.
170,170,15.0, Carnegie Mellon University, Carnegie Mellon University,adaptive kernel approximation for large-scale non-linear svm prediction.
171,171,16.0," Research School of Computer Science, Australian National University and NICTA, Canberra, Australia"," Dpto. Teoría de la Señal y Comunicaciones, Universidad Carlos III de Madrid, Leganís, Spain",risk-based generalizations of f-divergences.
172,172,17.0," SML NICTA & RSISE ANU, Canberra ACT, Australia"," IST Austria (Institute of Science and Technology Austria), Klosterneuburg, Austria",learning multi-view neighborhood preserving projections.
173,173,18.0," DSI, Università degli Studi di Milano, Italy"," DSI, Università degli Studi di Milano, Italy",better algorithms for selective sampling.
174,174,19.0,"LTCI UMR Telecom ParisTech/CNRS No. 5141, Paris, France","LTCI UMR Telecom ParisTech/CNRS No. 5141, Paris, France",minimax learning rates for bipartite ranking and plug-in rules.
175,175,20.0," Machine Learning and Robotics Lab, FU Berlin, Berlin, Germany"," Machine Learning and Robotics Lab, FU Berlin, Berlin, Germany",task space retrieval using inverse feedback control.
176,176,21.0," Department of Computer Science & Engineering, University of Washington"," Department of Engineering, University of Cambridge, UK",pilco: a model-based and data-efficient approach to policy search.
177,177,0.0," IDSIA, USI & SUPSI, Switzerland"," IDSIA, USI & SUPSI, Switzerland",incremental basis construction from temporal difference error.
178,178,1.0," Department of Computer Science, Princeton University, Princeton, NJ"," Department of Computer Science, Princeton University, Princeton, NJ",predicting legislative roll calls from text.
179,179,2.0," Nikon Corporation, Tokyo, Japan"," Beckman Institute, University of Illinois, Urbana-Champaign",on bayesian pca: automatic dimensionality selection and analytic solution.
180,180,3.0," Dept. IRO, Université de Montréal. Montréal (QC), Canada"," Dept. IRO, Université de Montréal. Montréal (QC), Canada",domain adaptation for large-scale sentiment classification: a deep learning approach.
181,181,4.0," Department of Computer Science, U. of Southern California, Los Angeles, CA"," Department of Computer Science, U. of Southern California, Los Angeles, CA",learning with whom to share in multi-task feature learning.
182,182,5.0," Jožef Stefan Institute, Ljubljana, Slovenia"," Jožef Stefan Institute, Ljubljana, Slovenia",speeding up hoeffding-based regression trees with options.
183,183,6.0," Department of EECS, University of Liège, Liège, Belgium"," Department of EECS, University of Liège, Liège, Belgium",linear regression under fixed-rank constraints: a riemannian approach.
184,184,7.0, MPI for Intelligent Systems and Stanford University, MPI for Intelligent Systems,uncovering the temporal dynamics of diffusion networks.
185,185,8.0," Electrical Engineering Department, Stanford, CA"," Computer Science Department, Stanford, CA",multiclass boosting with hinge loss based on output coding.
186,186,9.0,"IBISC, EA 4526, Université d'Évry Val d'Essonne, Évry, France","ENSIIE, Évry, France and IBISC, EA 4526, Université d'Evry Val d'Essonne, Évry, France",semi-supervised penalized output kernel regression for link prediction.
187,187,10.0," Steklov Mathematical Institute, St. Petersburg, Russia and St. Petersburg Academic University, St. Petersburg, Russia"," St. Petersburg Institute for Informatics and Automation RAS, St. Petersburg, Russia and St. Petersburg Academic University, St. Petersburg, Russia",a new bayesian rating system for team competitions.
188,188,11.0," Stanford University, Stanford, CA"," École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland",optiml: an implicitly parallel domain-specific language for machine learning.
189,189,12.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",infinite svm: a dirichlet process mixture of large-margin kernel machines.
190,190,13.0," Department of Electrical and Computer Engineering, Duke University, Durham, NC"," Department of Electrical and Computer Engineering, Duke University, Durham, NC",on the integration of topic modeling and dictionary learning.
191,191,14.0," David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, CANADA"," School of Computer Science and Engineering, The Hebrew University of Jerusalem, ISRAEL",access to unlabeled data can speed up prediction time.
192,192,15.0," Departement d'informatique et de genie logiciel, Universite Laval, Quebec, Canada"," Departement d'informatique et de genie logiciel, Universite Laval, Quebec, Canada",from pac-bayes bounds to quadratic programs for majority votes.
193,193,16.0," Intelligent Systems Laboratory, University of Bristol, UK"," Departament de Sistemes Informatics i Computacio, Universitat Politecnica de València, Spain",a coherent interpretation of auc as a measure of aggregated classification performance.
194,194,17.0," Czech Technical University in Prague, Praha, Czech Republic"," Max Planck Institute for Intelligent Systems, Tubingen, Germany",support vector machines as probabilistic models.
195,195,18.0, Microsoft Research New England and Weizmann Institute of Science, Microsoft Research New England,adaptively learning the crowd kernel.
196,196,19.0," D. Bren School of Information and Computer Science, University of California, Irvine, CA"," Gatsby Computational Neuroscience Unit, UCL, London, UK",bayesian learning via stochastic gradient langevin dynamics.
197,197,20.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",multimodal deep learning.
198,198,21.0," Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI"," Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI",on the robustness of kernel density m-estimators.
199,199,22.0," School of Computing, University of Utah, Salt Lake City, UT"," Department of Computer Science, University of Maryland, College Park, MD",beam search based map estimates for the indian buffet process.
200,200,23.0, Microsoft Research, Microsoft Research,optimal distributed online prediction.
201,201,0.0," TTI Chicago, Chicago"," TTI Chicago, Chicago",convex max-product algorithms for continuous mrfs with applications to protein folding.
202,202,1.0," Department of Computer Science, University of Texas, Austin, Texas"," Department of Computer Science, University of Texas, Austin, Texas",structure learning in ergodic factored mdps without knowledge of the transition function's in-degree.
203,203,2.0," Department of Statistics & FAS Center for Systems Biology, Harvard University, Cambridge, MA"," Department of Statistics & FAS Center for Systems Biology, Harvard University, Cambridge, MA",tree preserving embedding.
204,204,3.0," University of Washington, Seattle, WA"," University of Washington, Seattle, WA",clustering by left-stochastic matrix factorization.
205,205,4.0," Duke University, Durham, NC"," Duke University, Durham, NC",the infinite regionalized policy representation.
206,206,5.0, University of Massachusetts, University of Massachusetts,samplerank: training factor graphs with atomic gradients.
207,207,6.0," UC San Diego, La Jolla, CA"," Yahoo! Research, Sunnyvale, CA",preserving personalized pagerank in subgraphs.
208,208,7.0," Microsoft Research, Redmond, WA"," Microsoft Research, Redmond, WA",hierarchical classification via orthogonal transfer.
209,209,8.0," Ludwig-Maximilians-Universität, Munich, Germany"," Ludwig-Maximilians-Universität, Munich, Germany",a three-way model for collective learning on multi-relational data.
210,210,9.0," Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria"," Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria",variational inference for policy search in changing situations.
211,211,10.0," Department of Communications Engineering, Universidad de Cantabria, Spain"," School of Computer Science, University of Manchester, UK",variational heteroscedastic gaussian process regression.
212,212,11.0," Department of Statistics, Pennsylvania State University, University Park, PA"," Department of Computer Science, University of California, Irvine, CA",dynamic egocentric models for citation networks.
213,213,12.0," ICHRPS, Tufts Medical Center, Boston, MA"," ICHRPS, Tufts Medical Center, Boston, MA",the constrained weight space svm: learning with ranked features.
214,214,13.0," Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX"," Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX",robust matrix completion and corrupted columns.
215,215,14.0," Massachusetts Institute of Technology, Cambridge, MA"," Massachusetts Institute of Technology, Cambridge, MA",online discovery of feature dependencies.
216,216,15.0," Department of Computer Science, Princeton University, Princeton, NJ"," Department of Computer Science, Princeton University, Princeton, NJ",variational inference for stick-breaking beta process priors.
217,217,16.0," Redwood Center for Theoretical Neuroscience, Wills Neuroscience Institute, University of California, Berkeley and Biophysics Graduate Group, Wills Neuroscience Institute, University of California, Berkeley"," Redwood Center for Theoretical Neuroscience, Wills Neuroscience Institute, University of California, Berkeley and Physics Department, Wills Neuroscience Institute, University of California, Berkeley and Helen, Wills Neuroscience Institute, University of California, Berkeley",minimum probability flow learning.
218,218,17.0," Massachusetts Institute of Technology, Cambridge, MA"," Massachusetts Institute of Technology, Cambridge, MA",infinite dynamic bayesian networks.
219,219,18.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",the importance of encoding versus training with sparse coding and vector quantization.
220,220,19.0," Graduate School of Informatics, Kyoto University"," Graduate School of Informatics, Kyoto University",fast global alignment kernels.
221,221,20.0," University of British Columbia, Canada"," University of British Columbia, Canada",learning attentional policies for tracking and recognition in video with deep networks.
222,222,21.0," Washington University in Saint Louis, Saint Louis, MO"," Washington University in Saint Louis, Saint Louis, MO",automatic feature decomposition for single view co-training.
223,223,0.0," Graduate School of Applied Informatics, Hyogo University, Kobe"," Gakushuin University, Tokyo",mapping kernels for trees.
224,224,1.0," LIF, LSIS, CNRS, Aix-Marseille Université"," LSIS, CNRS, Université du Sud-Toulon-Var",stochastic low-rank kernel learning for regression.
225,225,2.0," Collaborative Research Center for Innovative Mathematical Modelling, Institute of Industrial Science, University of Tokyo, Japan"," Institute of Industrial Science, University of Tokyo, Japan",size-constrained submodular minimization through minimum norm base.
226,226,3.0," University of Oxford, Department of Engineering Science, Oxford, UK"," Oxford Brookes University, Oxford, UK",locally linear support vector machines.
227,227,4.0," SequeL Project, INRIA Lille - Nord Europe, Villeneuve d'Ascq, France"," LITIS, UFR de Sciences, Université de Rouen, St Etienne du Rouvray, France",functional regularized least squares classification with operator-valued kernels.
228,228,5.0," UT Austin, Austin, TX"," National University of Singapore , Singapore, SINGAPORE",clustering partially observed graphs via convex optimization.
229,229,6.0," University of Toronto, Toronto, ON, Canada"," University of Toronto, Toronto, ON, Canada",generating text with recurrent neural networks.
230,230,7.0," Dept of Computer Science & Engg, University of Minnesota, Twin Cities"," School of Statistics, Univeristy of Minnesota, Twin Cities",probabilistic matrix addition.
231,231,8.0," University of Toronto, Canada"," University of Toronto, Canada",learning recurrent neural networks with hessian-free optimization.
232,232,9.0," Department of Computer Science, University of Southern California"," Department of Computer Science, University of Southern California","submodular meets spectral: greedy algorithms for subset selection, sparse approximation and dictionary selection."
233,233,10.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",a spectral algorithm for latent tree graphical models.
234,234,11.0," ECE Department, Northeastern University, Boston, MA"," EECS and Statistics Departments, University of California, Berkeley, CA",a unified probabilistic model for global and local unsupervised feature selection.
235,235,12.0," National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China"," National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",towards making unlabeled data never hurt.
236,236,13.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",on random weights and unsupervised feature learning.
237,237,14.0," Yahoo! Research, New York, NY"," Yahoo! Research, Santa Clara, CA",doubly robust policy evaluation and learning.
238,238,15.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",learning deep energy models.
239,239,16.0," Centrum Wiskunde & Informatica, Amsterdam, The Netherlands"," Mathematics and Computer Science, Marburg University, Marburg, Germany",bipartite ranking through minimization of univariate loss.
240,240,17.0," Department of EECS, University of California, Berkeley, CA"," Departments of Statistics and EECS, University of California, Berkeley, CA",noisy matrix decomposition via convex relaxation: optimal rates in high dimensions.
241,241,18.0," DIRO, Université de Montréal, Montréal, Québec, Canada"," DIRO, Université de Montréal, Montréal, Québec, Canada",unsupervised models of images by spike-and-slab rbms.
242,242,19.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",approximating correlated equilibria using relaxations on the marginal polytope.
243,243,20.0," ECE Department, Northeastern University, Boston, MA"," ECE Department, Northeastern University, Boston, MA",active learning from crowds.
244,244,21.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",computational rationalization: the inverse equilibrium problem.
245,245,22.0," INRIA Lille - Nord Europe, Team SequeL, France"," Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",finite-sample analysis of lasso-td.
246,246,23.0," Department of Computer Science, Duke University, Durham, NC"," Department of Computer Science, Duke University, Durham, NC",generalized value functions for large action sets.
247,247,24.0," University of Pennsylvania, Department of Computer and Information Science, Philadelphia, PA"," University of Pennsylvania, Department of Computer and Information Science, Philadelphia, PA",k-dpps: fixed-size determinantal point processes.
248,248,0.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",generalized boosting algorithms for convex optimization.
249,249,0.0," Microsoft Research, Redmond"," Microsoft Research Asia, Beijing, P.R.C.",conversational speech transcription using context-dependent deep neural networks.
250,250,1.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",data-driven web design.
251,251,2.0," United States Naval Academy, Annapolis, MD"," Stanford University, Stanford, CA",learning the central events and participants in unlabeled text.
252,252,3.0, Massachusetts Institute of Technology, Carnegie Mellon University,"exemplar-svms for visual object detection, label transfer and image retrieval."
253,253,4.0," Department of Statistics, Harvard University, Cambridge, MA"," Department of Statistics, Harvard University, Cambridge, MA",summarizing topical content with word frequency and exclusivity.
254,254,5.0," Tencent Inc, Beijing, P. R. China"," Microsoft Research, Redmond, WA",truelabel + confusions: a spectrum of probabilistic models in analyzing multiple ratings.
255,255,6.0," University of Southern California, Institute for Robotics and Intelligent Systems, Los Angeles, CA"," University of Southern California, Institute for Robotics and Intelligent Systems, Los Angeles, CA",robust multiple manifolds structure learning.
256,256,7.0," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA"," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA",two-manifold problems with applications to nonlinear system identification.
257,257,8.0," Department of Electrical Engineering, Columbia University, New York, NY"," Department of Electrical Engineering, Columbia University, New York, NY",on the difficulty of nearest neighbor search.
258,258,9.0," CLMC Lab, University of Southern California, Los Angeles, CA"," CLMC Lab, University of Southern California, Los Angeles, CA and Max-Planck-Institute for Intelligent Systems, Tübingen, Germany",learning force control policies for compliant robotic manipulation.
259,259,10.0," CMLA, UMR, CNRS, ENS Cachan, France"," CMLA, UMR, CNRS, ENS Cachan, France",estimation of simultaneously sparse and low rank matrices.
260,260,11.0," Department of Computer Science, Cornell University, Ithaca, NY"," Department of Computer Science, Cornell University, Ithaca, NY",online structured prediction via coactive learning.
261,261,12.0," Computer & Information Science, University of Pennsylvania, Philadelphia, PA"," Computer & Information Science, University of Pennsylvania, Philadelphia, PA",two step cca: a new spectral method for estimating vector models of words.
262,262,13.0," Helsinki Institute for Information Technology, Department of Information and Computer Science, Aalto University School of Science"," Helsinki Institute for Information Technology, Department of Information and Computer Science, Aalto University School of Science",bayesian efficient multiple kernel learning.
263,263,14.0," Department of Computer and Information Science, IUPUI, Indianapolis, IN"," Biindley Bioscience Center, Purdue University, W. Lafayette, IN",bayesian nonexhaustive learning for online discovery and modeling of emerging classes.
264,264,15.0," University of Rome Tor Vergata, Rome, Italy"," University of Rome Tor Vergata, Rome, Italy",distributed tree kernels.
265,265,16.0," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI"," Yahoo Labs!, Santa Clara, CA",multiple kernel learning from noisy labels by stochastic programming.
266,266,17.0," Siemens Corporate Research and Technology, Princeton, NJ"," Siemens Corporate Research and Technology, Princeton, NJ",inductive kernel low-rank decomposition with priors: a generalized nyström method.
267,267,18.0," Department of Computer Science, University of Toronto, Toronto, ON"," Department of Computer Science, University of Toronto, Toronto, ON",active learning for matching problems.
268,268,19.0," Duke University, Durham, NC"," Duke University, Durham, NC",ensemble methods for convex regression with applications to geometric programming based circuit design.
269,269,20.0," Department of Mechanical Engineering, National University of Singapore, Singapore"," Department of Mechanical Engineering, National University of Singapore, Singapore",stability of matrix factorization for collaborative filtering.
270,270,21.0," Department of Electrical Engineering, Technion, Haifa, Israel"," The Gonda Brain Research Center, Bar Ilan University and Google research",adaptive regularization for weight matrices.
271,271,22.0," INRIA, Talence, ENSTA-ParisTech, Paris, France"," RLAI Laboratory, Department of Computing Science, University of Alberta, Edmonton, Canada",off-policy actor-critic.
272,272,23.0," Center for Visual Computing, École Centrale Paris, France and Équipe Galen, INRIA Saclay, Île-de-France, France and Université Paris-Est, LIGM (UMR CNRS), École des Ponts ParisTech, France"," Stanford University, Stanford, CA",modeling latent variable uncertainty for loss-based learning.
273,273,24.0," University of Washington, Department of Electrical Engineering, Seattle, WA"," University of Washington, Department of Electrical Engineering, Seattle, WA",dimensionality reduction by local discriminative gaussians.
274,274,25.0," Department of Computer Science, University of Toronto"," Department of Computer Science, University of Toronto",learning to label aerial images from noisy data.
275,275,0.0," Faculty of Engineering, Tel Aviv University, Ramat Aviv, Israel"," University of Minnesota, Department of Electrical and Computer Engineering, Minneapolis",learning efficient structured sparse models.
276,276,1.0," Yahoo! Labs Bangalore, Bengaluru, Karnataka, India"," Department of Computer Science, The University of Texas at Austin, Austin, Texas",pac subset selection in stochastic multi-armed bandits.
277,277,2.0," Department of Psychology, Princeton University, Princeton, NJ"," Department of Computer Science, Princeton University, Princeton, NJ",nonparametric variational inference.
278,278,3.0," Research School of Computer Science, The Australian National University and NICTA, Canberra, Australia"," Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, China",the convexity and design of composite multiclass losses.
279,279,4.0," Selim and Rachel Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem"," Selim and Rachel Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem",learning the experts for online sequence prediction.
280,280,5.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",efficient active algorithms for hierarchical clustering.
281,281,6.0," Department of Mathematics and Computer Science, University of Basel, Basel, Switzerland"," Department of Mathematics and Computer Science, University of Basel, Basel, Switzerland",copula mixture model for dependency-seeking clustering.
282,282,7.0," College of Computing, Georgia Institute of Technology, Atlanta, Georgia"," College of Computing, Georgia Institute of Technology, Atlanta, Georgia",the landmark selection method for multiple output prediction.
283,283,8.0," Department of Computer Science, Technische Universität Dortmund, Germany"," Department of Computer Science, Technische Universität Dortmund, Germany",subgraph matching kernels for attributed graphs.
284,284,9.0," LITIS, Université de Rouen-INSA de Rouen, Avenue de l'Université, St-Etienne-du-Rouvray, France"," LITIS, Université de Rouen-INSA de Rouen, Avenue de l'Université, St-Etienne-du-Rouvray, France",adaptive canonical correlation analysis based on matrix manifolds.
285,285,10.0," Department of EECS, Oregon State University, Corvallis, OR"," Department of Computer Science, Williams College, Williamstown, MA",batch active learning via coordinated matching.
286,286,11.0," Oregon State University, Corvallis, OR"," Oregon State University, Corvallis, OR",hybrid batch bayesian optimization.
287,287,12.0," IBM T.J. Watson Research Center, Yorktown Heights, NY"," IBM T.J. Watson Research Center, Yorktown Heights, NY",efficient and practical stochastic subgradient descent for nuclear norm regularization.
288,288,13.0," Dept. of Computer Science and Engineering, University of Minnesota, Twin Cities"," Max Planck Institute for Biogeochemistry, Jena, Germany",gap filling in the plant kingdom: trait prediction using hierarchical probabilistic matrix factorization.
289,289,14.0," Supélec, IMS Research Group, Metz, France"," INRIA Lille, France",a dantzig selector approach to temporal difference learning.
290,290,15.0, Pacific Northwest National Laboratory, Pacific Northwest National Laboratory,scaling up coordinate descent algorithms for large l1 regularization problems.
291,291,16.0," Duke University, Durham, NC"," Duke University, Durham, NC",cross-domain multitask learning with latent probit models.
292,292,17.0," HCI, IWR, University of Heidelberg, Heidelberg, Germany"," HCI, IWR, University of Heidelberg, Heidelberg, Germany",structured learning from partial annotations.
293,293,18.0," Machine Learning Department, Carnegie Mellon University"," The Robotics Institute, Carnegie Mellon University",maximum margin output coding.
294,294,19.0," Carnegie Mellon University, Pittsburgh, PA"," University of Chicago, Chicago, IL",sequential nonparametric regression.
295,295,20.0," Computing Science Department, University of Alberta, Edmonton, Alberta, Canada"," Yahoo! Research, Santa Clara, CA",on local regret.
296,296,21.0," Department of Computer Science, University of New Mexico, Albuquerque, NM"," Department of Computer Science, University of New Mexico, Albuquerque, NM",smoothness and structure learning by proxy.
297,297,22.0, University College London, University College London,a fast and simple algorithm for training neural probabilistic language models.
298,298,23.0," Institute of Computer Science, FORTH, Greece, and Computer Science Department, University of Crete, Greece"," Institute of Computer Science, FORTH, Greece, and Computer Science Department, University of Crete, Greece",incorporating causal prior knowledge as path-constraints in bayesian networks and maximal ancestral graphs.
299,299,24.0," Google, New York, NY"," Google, New York, NY",latent collaborative retrieval.
300,300,0.0," Department of Electrical Engineering, Technion, Israel"," Department of Mechanical Engineering, National University of Singapore, Singapore",lightning does not strike twice: robust mdps with coupled uncertainty.
301,301,1.0," Max Planck Institute for Intelligent Systems, Tübingen, Germany"," Institute for Computing and Information Sciences, Radboud University, Nijmegen, The Netherlands",on causal and anticausal learning.
302,302,2.0," Columbia University, New York, NY"," Columbia University, New York, NY",compact hyperplane hashing with bilinear functions.
303,303,3.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",continuous inverse optimal control with locally optimal examples.
304,304,4.0," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong"," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong",convex multitask learning with flexible task clusters.
305,305,5.0," Dept. of Bioengineering, University of Pennsylvania, Philadelphia, PA"," Depts. of Neurology and Bioengineering, University of Pennsylvania, Philadelphia, PA",a hierarchical dirichlet process model with multiple levels of clustering for human eeg seizure modeling.
306,306,6.0,,,building high-level features using large scale unsupervised learning.
307,307,7.0," Dept. of Computer Science & Sheffield Institute for Translational Neuroscience, University of Sheffield, UK"," Dept. of Computer Science & Sheffield Institute for Translational Neuroscience, University of Sheffield, UK",manifold relevance determination.
308,308,8.0," Sheffield Institute for Translational Neuroscience and Department of Computer Science, University of Sheffield"," Sheffield Institute for Translational Neuroscience and Department of Computer Science, University of Sheffield",residual component analysis: generalising pca for more flexible inference in linear-gaussian models.
309,309,9.0," School of Computer Science and Engineering, South China University of Technology, Guangzhou, China"," School of Computer Science and Engineering, South China University of Technology, Guangzhou, China",clustering to maximize the ratio of split to diameter.
310,310,10.0," School of Computer Engineering, Nanyang Technological University, Singapore"," School of Computer Engineering, Nanyang Technological University, Singapore",on-line portfolio selection with moving average reversion.
311,311,11.0," Microsoft Research Cambridge, United Kingdom"," Microsoft Research Cambridge, United Kingdom",improved information gain estimates for decision tree induction.
312,312,12.0," IDSIA, USI & SUPSI, Switzerland"," IDSIA, USI & SUPSI, Switzerland",on the size of the online kernel sparsification dictionary.
313,313,13.0," Graduate School of Information Science and Technology, The University of Tokyo, Hongo, Tokyo, Japan"," Graduate School of Information Science and Technology, The University of Tokyo, Hongo, Tokyo, Japan",fast computation of subpath kernel for trees.
314,314,14.0," The Key Laboratory of Machine Perception, Peking University, Beijing, China"," The Key Laboratory of Machine Perception, Peking University, Beijing, China",total variation and euler's elastica for supervised learning.
315,315,15.0," University of Texas at Austin, Austin, TX"," University of Texas at Austin, Austin, TX",learning the dependence graph of time series with latent factors.
316,316,16.0," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA"," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA",estimating sparse precision matrices from data with missing values.
317,317,17.0," Australian Centre for Visual Technologies, The University of Adelaide"," Australian Centre for Visual Technologies, The University of Adelaide",is margin preserved after random projection?.
318,318,18.0," Department of Biomedical Engineering, Dalian University of Technology, Dalian, P.R.China"," Department of Statistical Science, Centre for Computational Statistics and Machine Learning, University College London, London, UK",a bayesian approach to approximate joint diagonalization of square matrices.
319,319,19.0," University of California, San Diego, La Jolla, CA"," University of California, San Diego, La Jolla, CA",predicting accurate probabilities with a ranking loss.
320,320,20.0," School of Computer Engineering, Nanyang Technological University, Singapore"," School of Computer Engineering, Nanyang Technological University, Singapore",learning with augmented features for heterogeneous domain adaptation.
321,321,21.0," Computer Science Department, KAIST, Daejeon, Korea"," Computer Science Department, KAIST, Daejeon, Korea",dirichlet process with mixed random measures: a nonparametric topic model for labeled data.
322,322,22.0," Department of Computer Science, University of British Columbia"," Department of Engineering, University of Cambridge",bayesian and l1 approaches for sparse unsupervised learning.
323,323,0.0," Ming Hsieh Dept. of Electrical Engineering, University of Southern California, Los Angeles, CA"," Ming Hsieh Dept. of Electrical Engineering, University of Southern California, Los Angeles, CA and Department of Computer Science, University of Southern California, Los Angeles, CA",collaborative topic regression with social matrix factorization for recommendation systems.
324,324,1.0," Department of Computer Science, ETH Zurich, Switzerland"," Department of Computer Science, ETH Zurich, Switzerland",lpqp for map: putting lp solvers to better use.
325,325,2.0," Department of Information and Computer Science, Aalto University, Finland"," Department of Information and Computer Science, Aalto University, Finl",clustering by low-rank doubly stochastic matrix decomposition.
326,326,3.0," Research School of Computer Science, The Australian National University, Canberra, ACT, Australia and National ICT, Canberra, ACT, Australia"," National ICT, Canberra, ACT, Australia and Research School of Computer Science, The Australian National University, Canberra, ACT, Australia",dependent hierarchical normalized random measures for dynamic topic modeling.
327,327,4.0," Aalto University, Dept. of Biomedical Engineering and Computational Science, Espoo, Finland"," Aalto University, Dept. of Biomedical Engineering and Computational Science, Espoo, Finland",state-space inference for non-linear latent force models with application to satellite orbit prediction.
328,328,5.0," Toyota Technological Institute at Chicago, Chicago, IL"," Toyota Technological Institute at Chicago, Chicago, IL",the kernelized stochastic batch perceptron.
329,329,6.0," LAL, LRI, University of Paris-Sud, CNRS, Orsay, France"," Research Group on Artificial Intelligence of the Hungarian Academy of Sciences and University of Szeged, Aradi Szeged, Hungary",fast classification using sparse decision dags.
330,330,7.0, The University of Tokyo, The University of Tokyo,rethinking collapsed variational bayes inference for lda.
331,331,8.0," Signal Processing and Speech Communication Laboratory, Graz University of Technology, Austria"," Signal Processing and Speech Communication Laboratory, Graz University of Technology, Austria",exact maximum margin structure learning of bayesian networks.
332,332,9.0," Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, China"," Tsinghua National Laboratory for Information Science and Technology(TNList), Department of Automation, Tsinghua University, Beijing, China",aoso-logitboost: adaptive one-vs-one logitboost for multi-class problem.
333,333,10.0," CSML, University College London"," The Institute of Statistical Mathematics, Tokyo",hypothesis testing using pairwise distances and associated kernels.
334,334,11.0," Department of Computer Science, National University of Singapore, Singapore, Singapore"," Department of Computer Science, National University of Singapore, Singapore, Singapore",monte carlo bayesian reinforcement learning.
335,335,12.0," School of Informatics, University of Edinburgh"," School of Informatics, University of Edinburgh",a topic model for melodic sequences.
336,336,13.0," School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR"," School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR",output space search for structured prediction.
337,337,14.0," Microsoft Research, Cambridge, UK"," Microsoft Research, Cambridge, UK",how to grade a test without knowing the answers: a bayesian graphical model for adaptive crowdsourcing and aptitude testing.
338,338,15.0," Carnegie Mellon University, Pittsburgh, PA"," Uppsala Universitet, Uppsala, Sweden",bayesian optimal active search and surveying.
339,339,16.0," Dept. of Computer Sciences, University of Wisconsin Madison"," Dept. of Biostatistics & Med. Informatics, University of Wisconsin Madison and Dept. of Computer Sciences",incorporating domain knowledge in matching problems via harmonic analysis.
340,340,17.0," Duke University, Durham, NC"," Duke University, Durham, NC",lognormal and gamma mixed negative binomial regression.
341,341,18.0," Duke University, Durham, NC"," Duke University, Durham, NC",greedy algorithms for sparse reinforcement learning.
342,342,19.0," Institute of Industrial Science, the University of Tokyo, Tokyo, Japan"," Honda Research Institute Japan Co., Ltd., Wako-shi, Saitama, Japan",apprenticeship learning for model parameters of partially observable environments.
343,343,20.0," Department of Computer Science, University of Maryland, College Park, MD"," iSchool and UMIACS, University of Maryland, College Park, MD",modeling images using transformed indian buffet processes.
344,344,21.0," Department of Computer Science, Cornell University, Ithaca, NY"," Department of Computer Science, Cornell University, Ithaca, NY",learning object arrangements in 3d scenes using human context.
345,345,22.0," Department of Computer and Information Sciences, Temple University, Philadelphia, PA"," Department of Computer and Information Sciences, Temple University, Philadelphia, PA",cross language text classification via subspace co-regularized multi-view learning.
346,346,23.0," Computer Learning Research Centre, Royal Holloway, University of London, Egham, Surrey, UK"," Computer Learning Research Centre, Royal Holloway, University of London, Egham, Surrey, UK",plug-in martingales for testing exchangeability on-line.
347,347,0.0," Dept. of CSE, The University of Texas at Arlington, Arlington, TX"," Dept. of CSE, The University of Texas at Arlington, Arlington, TX",an iterative locally linear embedding algorithm.
348,348,1.0," Aston University, Birmingham, UK"," Aston University, Birmingham, UK",direct gaussian process quantile regression using expectation propagation.
349,349,2.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",latent multi-group membership graph model.
350,350,3.0," Department of Computer Science, University of British Columbia, Vancouver, BC, Canada"," Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",exponential regret bounds for gaussian process bandits with deterministic observations.
351,351,4.0,,,estimating the hessian by back-propagating curvature.
352,352,5.0,," Williams College, Williamstown, MA",feature selection via probabilistic outputs.
353,353,6.0," iLab, H. John Heinz III College, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",hierarchical exploration for accelerating contextual bandits.
354,354,7.0," Electrical Engineering and Computer Science, School of Engineering, University of California, Merced"," Electrical Engineering and Computer Science, School of Engineering, University of California, Merced",partial-hessian strategies for fast learning of nonlinear embeddings.
355,355,8.0," Department of Statistics University of Washington Seattle, WA"," Microsoft Research, Redmond, WA",fast prediction of new feature utility.
356,356,9.0," Purdue University, West Lafayette, IN"," Google, Los Angeles, CA",robust classification with adiabatic quantum optimization.
357,357,10.0," Department of Computer Science and Engineering, UCSD, La Jolla, CA"," Department of Computer Science and Engineering, UCSD, La Jolla, CA",agglomerative bregman clustering.
358,358,11.0," School of Informatics,University of Edinburgh"," School of Informatics,University of Edinburgh",isoelastic agents and wealth updates in machine learning markets.
359,359,12.0," Max Planck Institute for Intelligent Systems, Tübingen, Germany"," Max Planck Institute for Intelligent Systems, Tübingen, Germany",quasi-newton methods: a new direction.
360,360,13.0," University of Alberta, Edmonton, Alberta, Canada"," University of Alberta, Edmonton, Alberta, Canada",no-regret learning in extensive-form games with imperfect recall.
361,361,14.0," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan"," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan",information-theoretic semi-supervised metric learning via entropy regularization.
362,362,15.0," Dept. of Computer Science, Rensselaer Polytechnic Institute, Troy, NY"," IBM Almaden Research Center, San Jose, CA",fast approximation of matrix coherence and statistical leverage.
363,363,16.0," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan"," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan",artist agent: a reinforcement learning approach to automatic stroke generation in oriental ink painting.
364,364,17.0," University of Frankfurt, Frankfurt, Germany"," University of Frankfurt, Frankfurt, Germany",on multi-view feature learning.
365,365,18.0," School of Computer Engineering, Nanyang Technological University, Singapore"," School of Computer Engineering, Nanyang Technological University, Singapore",fast bounded online gradient descent algorithms for scalable kernel-based online learning.
366,366,19.0," Friedrich-Schiller-University Jena, Germany"," Friedrich-Schiller-University Jena, Germany",a hybrid algorithm for convex semidefinite optimization.
367,367,20.0," Computer Science Department, University of Basel, Switzerland"," Computer Science Department, University of Basel, Switzerland","a complete analysis of the l1,p group-lasso."
368,368,21.0," Stony Brook University, Stony Brook, NY"," Stony Brook University, Stony Brook, NY",convergence rates of biased stochastic optimization for learning sparse ising models.
369,369,22.0," University of Potsdam, Department of Computer Science, Potsdam, Germany"," University of Potsdam, Department of Computer Science, Potsdam, Germany",learning to identify regular expressions that describe email campaigns.
370,370,23.0," Department of Computer Science, University of Toronto, Toronto, Ontario, Canada"," Department of Computer Science, University of Toronto, Toronto, Ontario, Canada",deep mixtures of factor analysers.
371,371,24.0," Department of CSE, Ohio State University, Columbus, OH"," Departments of EECS and Statistics, University of California, Berkeley, CA",revisiting k-means: new algorithms via bayesian nonparametrics.
372,372,25.0," Department of Engineering, University of Cambridge, Cambridge, UK"," Department of Engineering, University of Cambridge, Cambridge, UK",gaussian process regression networks.
373,373,26.0," Research School of Computer Science, Australian National University and NICTA, Canberra, Australia"," NICTA, Canberra, Australia",tighter variational representations of f-divergences via restriction to probability measures.
374,374,0.0," State Key Lab of Intelligent Tech & Sys, Tsinghua National TNList Lab, Department of Computer Science and Technology, Tsinghua University, Beijing, China"," State Key Lab of Intelligent Tech & Sys, Tsinghua National TNList Lab, Department of Computer Science and Technology, Tsinghua University, Beijing, China",max-margin nonparametric latent feature models for link prediction.
375,375,1.0," NICTA & Australian National University, Canberra, ACT, Australia"," NICTA & Australian National University, Locked Bag, Canberra, ACT, Australia",discriminative probabilistic prototype learning.
376,376,2.0," Computer Science Department, University of Southern California, Los Angeles, CA"," IBM T.J. Watson Research Center, Yorktown Heights, NY",sparse-gev: sparse latent space model for multivariate extreme value time series modeling.
377,377,3.0," Aix-Marseille Univ., QARMA, LIF, CNRS, UMR, Marseille, France"," Aix-Marseille Univ., QARMA, LIF, CNRS, UMR, Marseille, France",pac-bayesian generalization bound on confusion matrix for multi-class classification.
378,378,4.0," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan"," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan",semi-supervised learning of class balance under class-prior change by distribution matching.
379,379,5.0," Department of Computer Science, U.S. Naval Academy, Annapolis, MD"," Navy Center for Applied Research in Artificial Intelligence, Naval Research Laboratory; Washington, DC",semi-supervised collective classification via hybrid label regularization.
380,380,6.0," Max Planck Institute for Intelligent Systems, Tübingen, Germany"," Max Planck Institute for Intelligent Systems, Tübingen, Germany and Department of Computer Science, University of Hamburg, Germany",shortest path distance in random k-nearest neighbor graphs.
381,381,7.0," School of Computer Engineering, Nanyang Technological University, Singapore"," Department of Computing, Macquarie University, Australia",a split-merge framework for comparing clusterings.
382,382,8.0," Department of Computer Science, CSML, University College London, London"," Department of Computer Science, CSML, University College London, London",compositional planning using optimal option models.
383,383,9.0," U. of Southern California, Los Angeles, CA"," U. of Southern California, Los Angeles, CA",information-theoretical learning of discriminative clusters for unsupervised domain adaptation.
384,384,10.0," Computer Science Department, University of Massachusetts, Amherst, MA"," Computer Science Department, University of Maryland, College Park, MD",flexible modeling of latent task structures in multitask learning.
385,385,11.0," Washington University, St. Louis, MO"," Université de Technologie de Compiègne, CNRS, UMR, Compiègne, France",an efficient approach to sparse linear discriminant analysis.
386,386,12.0," Washington University, St. Louis, MO"," Criteo, Palo Alto, CA",the greedy miser: learning under test-time budgets.
387,387,13.0," Dept. ML, Berlin Institute of Technology"," Institute AIFB, Karlsruhe Institute of Technology",canonical trends: detecting trend setters in web data.
388,388,14.0," INRIA, Ecole Normale Supéarieure"," INRIA, Ecole Normale Supéarieure",a convex relaxation for weakly supervised classifiers.
389,389,15.0," KU Leuven, Heverlee, Belgium"," University of Wisconsin, Madison, WI",demand-driven clustering in relational domains for predicting adverse drug events.
390,390,16.0," Department of Computer Science, University of Maryland, College Park, MD"," Department of Computer Science, University of Maryland, College Park, MD",a binary classification framework for two-stage multiple kernel learning.
391,391,17.0," Institute of Computing Science, Poznan University of Technology, Poznan, Poland"," Mathematics and Computer Science, Marburg University, Marburg, Germany",consistent multilabel ranking through univariate loss minimization.
392,392,18.0," INRIA, Département d'Informatique de l'Ecole Normale Supérieure, Paris, France"," INRIA, Département d'Informatique de l'Ecole Normale Supérieure, Paris, France",on the equivalence between herding and conditional gradient algorithms.
393,393,0.0," Brown University, Department of Computer Science, Providence, RI"," Brown University, Department of Computer Science, Providence, RI",the nonparametric metadata dependent relational model.
394,394,1.0," Department of Computer Science, University of Toronto, Toronto, Ontario, Canada"," Department of Computer Science, University of Toronto, Toronto, Ontario, Canada",deep lambertian networks.
395,395,2.0," Department of Computer Science, University of Rochester, Rochester, NY"," Department of Computer Science, University of Rochester, Rochester, NY",convergence of the em algorithm for gaussian mixtures with unbalanced mixing coefficients.
396,396,3.0," Computer Science and Engineering, University of Washington, Seattle, WA"," Computer Science and Engineering, University of Washington, Seattle, WA",a joint model of language and perception for grounded attribute learning.
397,397,4.0," Autonomous Learning Laboratory, Computer Science Dept., University of Massachusetts Amherst"," Autonomous Learning Laboratory, Computer Science Dept., University of Massachusetts Amherst",learning parameterized skills.
398,398,5.0," University of California at Berkeley, CA"," University of California at Berkeley, CA",safe exploration in markov decision processes.
399,399,6.0," School of Computer Science, McGill University, Montreal, Canada"," School of Computer Science, McGill University, Montreal, Canada",improved estimation in time varying models.
400,400,7.0," Department of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy"," Wilhelm Schickard Institute for Computer Science, University of Tübingen, Tübingen, Germany",poisoning attacks against support vector machines.
401,401,8.0," Department of Computing Science, University of Alberta, Edmonton, AB, Canada"," Department of Computing Science, University of Alberta, Edmonton, AB, Canada",regularizers versus losses for nonlinear dimensionality reduction.
402,402,9.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",utilizing static analysis and code generation to accelerate neural networks.
403,403,10.0," Laboratoire Hubert Curien, Université Jean Monnet, Saint-Etienne, France"," Laboratoire Hubert Curien, Université Jean Monnet, Saint-Etienne, France",similarity learning for provably accurate sparse linear classification.
404,404,11.0," Advanced Technology Labs, Adobe Systems Inc., San Francisco, CA"," Gatsby Computational Neuroscience Unit, University College London, UK",variational inference in non-negative factorial hidden markov models for efficient audio source separation.
405,405,12.0," Department of ECE, Duke University, Durham, NC"," Department of ECE, Duke University, Durham, NC",communications inspired linear discriminant analysis.
406,406,13.0," Princeton U., Dept. of Computer Science, Princeton, NJ"," Princeton U., Dept. of Computer Science, Princeton, NJ",sparse stochastic inference for latent dirichlet allocation.
407,407,14.0," College of Computing, Georgia Institute of Technology"," College of Computing, Georgia Institute of Technology",stochastic smoothing for nonsmooth minimizations: accelerating sgd by exploiting structure.
408,408,15.0," Dept. of CSE, IIT Bombay, Mumbai, India"," Dept. of CSE, IIT Bombay, Mumbai, India",a convex feature learning formulation for latent task structure discovery.
409,409,16.0,,,efficient decomposed learning for structured prediction.
410,410,17.0," Cognitive Robotics, École Nationale Supérieure de Techniques Avancées, Paris and INRIA Bordeaux Sud-Ouest, Talence, France"," Institut des Systèmes Intelligents et de Robotique, Université Pierre Marie Curie, CNRS, UMR, Paris",path integral policy improvement with covariance matrix adaptation.
411,411,18.0," Department of Computer Science, National University of Singapore, Singapore"," DSO National Laboratories, Singapore",optimizing f-measures: a tale of two approaches.
412,412,19.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",efficient euclidean projections onto the intersection of norm balls.
413,413,20.0, University of Pennsylvania, University of Pennsylvania,making gradient descent optimal for strongly convex stochastic optimization.
414,414,21.0," University of Texas at Austin, Austin, TX"," Toyota Technological Institute at Chicago, Chicago, IL",clustering using max-norm constrained optimization.
415,415,22.0, MPI for Intelligent Systems and Stanford University, MPI for Intelligent Systems,submodular inference of diffusion networks from multiple trees.
416,416,23.0," IBM T.J. Watson Research Center, Yorktown, NY"," IBM T.J. Watson Research Center, Yorktown, NY",approximate dynamic programming by minimizing distributionally robust bounds.
417,417,24.0, CSML," CSML, University College London, UK and MPI for Intelligent Systems",modelling transition dynamics in mdps with rkhs embeddings.
418,418,25.0," University of Massachusetts Amherst, Amherst, MA"," University of Massachusetts Amherst, Amherst, MA",approximate principal direction trees.
419,419,26.0," University of Wisconsin-Madison, Madison, WI"," University of Wisconsin-Madison, Madison, WI",unachievable region in precision-recall space and its effect on empirical evaluation.
420,420,27.0," Washington University, St. Louis, MO"," U. of Southern California, Los Angeles, CA",marginalized denoising autoencoders for domain adaptation.
421,421,28.0," Carnegie Mellon University, School of Computer Science, Pittsburgh, PA"," Carnegie Mellon University, School of Computer Science, Pittsburgh, PA",copula-based kernel dependency measures.
422,422,29.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",group sparse additive models.
423,423,0.0," Department of Electrical Engineering, The Technion-Israel Institute of Technology, Haifa, Israel"," Department of Electrical Engineering, The Technion-Israel Institute of Technology, Haifa, Israel",policy gradients with variance related risk criteria.
424,424,1.0," Computer Science Department, ETH Zurich, Zurich, Switzerland"," Toyota Technological Institute at Chicago, Chicago, IL",efficient structured prediction with latent variables for general graphical models.
425,425,2.0,,,on the partition function and random maximum a-posteriori perturbations.
426,426,3.0," Department of Computer Science, Purdue University, West Lafayette, IN"," Departments of Computer Science and Statistics, Purdue University, West Lafayette, IN",infinite tucker decomposition: nonparametric bayesian models for multiway data analysis.
427,427,4.0," Department of Electrical & Computer Engineering, Duke University, Durham, NC"," Department of Electrical & Computer Engineering, Duke University, Durham, NC",inferring latent structure from mixed real and categorical relational data.
428,428,5.0," Centre for Computational Statistics and Machine Learning, University College London, London"," Centre for Computational Statistics and Machine Learning, University College London, London",bayesian conditional cointegration.
429,429,6.0," Dept of Computer Science & Engg, University of Minnesota, Twin Cities"," Dept of Computer Science & Engg, University of Minnesota, Twin Cities",online alternating direction method.
430,430,7.0," Department of Biophysics, Radboud University Nijmegen, Nijmegen, The Netherlands"," Department of Biophysics, Radboud University Nijmegen, Nijmegen, The Netherlands",on the sample complexity of reinforcement learning with a generative model.
431,431,8.0," University of California, San Diego, La Jolla, CA"," Microsoft Research, New England, Cambridge, MA",convergence rates for differentially private statistical estimation.
432,432,9.0," Department of Computer Science, University of Maryland, College Park, MD"," Department of Computer Science, University of Maryland, College Park, MD",learning task grouping and overlap in multi-task learning.
433,433,10.0," Johns Hopkins University, Baltimore, MD"," Carnegie Mellon University, Pittsburgh, PA",the nonparanormal skeptic.
434,434,11.0," Centre for Computational Intelligence (Ci), Nanyang Technological University , Singapore"," Centre for Computational Intelligence (Ci), Nanyang Technological University , Singapore",discovering support and affiliated features from very high dimensions.
435,435,12.0," Toyota Technological Institute at Chicago, Chicago, IL"," Department of Computer Science, University of Texas, Austin, Texas",online bandit learning against an adaptive adversary: from regret to policy regret.
436,436,13.0," Department of Computing Science, University of Alberta, Edmonton, AB, Canada"," Department of Computing Science, University of Alberta, Edmonton, AB, Canada",statistical linear estimation with penalized estimators: an application to reinforcement learning.
437,437,14.0," School of Computer and Communication Sciences, Ecole Polytechnique Fédérale de Lausanne, Switzerland"," School of Computer and Communication Sciences, Ecole Polytechnique Fédérale de Lausanne, Switzerland",large scale variational bayesian inference for structured scale mixture models.
438,438,15.0," Dept. of Computer Science, UC Irvine, Irvine, CA"," Dept. of Computer Science, UC Irvine, Irvine, CA",bayesian posterior sampling via stochastic gradient fisher scoring.
439,439,16.0," Department of Computing Science, University of Alberta, AB, Canada"," Department of Computing Science, University of Alberta, AB, Canada",an adaptive algorithm for finite stochastic partial monitoring.
440,440,17.0," Computer Science Division, University of California, Berkeley, CA"," Computer Science Division and Department of Statistics, University of California, Berkeley, CA",the big data bootstrap.
441,441,18.0," Microsoft Research, Mountain View, CA"," Carnegie Mellon University, Pittsburgh, PA",predicting preference flips in commerce search.
442,442,19.0," CSML and University College London, UK"," CSML and University College London, UK",conditional mean embeddings as regressors.
443,443,20.0," Dept. IRO, Université de Montréal, Montréal, QC, Canada"," Dept. IRO, Université de Montréal, Montréal, QC, Canada",a generative process for sampling contractive auto-encoders.
444,444,21.0," Universitat Politècnica de Catalunya, Barcelona"," Universitat Politècnica de Catalunya, Barcelona",local loss optimization in operator models: a new insight into spectral learning.
445,445,22.0," Department of Electrical and Computer Engineering, National University of Singapore, Singapore"," Department of Electrical and Computer Engineering, National University of Singapore, Singapore",robust pca in high-dimension: a deterministic approach.
446,446,23.0," Department of Statistics, University of California, Berkeley"," Department of Statistics, University of California, Berkeley",complexity analysis of the lasso regularization path.
447,447,24.0, Technion-Israel Inst. of Tech., IBM T.J. Watson Research Center,projection-free online learning.
448,448,25.0," Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA"," Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA",machine learning that matters.
449,449,26.0," Courant Institute of Mathematical Sciences, New York University, New York, NY and Université Paris-Est, Noisy-le-Grand, France"," Courant Institute of Mathematical Sciences, New York University, New York, NY","scene parsing with multiscale feature learning, purity trees, and optimal covers."
450,450,27.0," Technion-Israel Institute of Technology, Technion City, Haifa, Israel"," Technion-Israel Institute of Technology, Technion City, Haifa, Israel",linear regression with limited observation.
451,451,28.0," Institute of Information Science, Academia Sinica, Taipei, Taiwan"," Institute of Information Science, Academia Sinica, Taipei, Taiwan",an online boosting algorithm with theoretical justifications.
452,452,29.0," Dept. IRO, Université de Montréal, Montréal, QC, Canada"," Dept. IRO, Université de Montréal, Montréal, QC, Canada",modeling temporal dependencies in high-dimensional sequences: application to polyphonic music generation and transcription.
453,453,0.0," INRIA Nancy, France"," Suplec, IMS Research Group, Metz, France",approximate modified policy iteration.
454,454,1.0," Department of EECS, University of California, Berkeley"," Department of EECS, University of California, Berkeley and Department of Statistics",nonparametric link prediction in dynamic networks.
455,455,2.0," Robotics Institute, Carnegie Mellon University, PA"," Robotics Institute, Carnegie Mellon University, PA",agnostic system identification for model-based reinforcement learning.
456,456,0.0," Ecole Polytechnique Federale de Lausanne, Switzerland"," Ecole Polytechnique Federale de Lausanne, Switzerland",an optimal policy for target localization with application to electron microscopy.
457,457,1.0," Max Planck Institute for Intelligent Systems, Tübingen, Germany"," Max Planck Institute for Intelligent Systems, Tübingen, Germany",domain generalization via invariant feature representation.
458,458,2.0," Department of Computer Science and Engineering, University of Washington, Seattle, WA"," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA",a spectral learning approach to range-only slam.
459,459,3.0," Google, Mountain View, CA"," Department of Computer Science and Engineering, UC San Diego, La Jolla, CA",near-optimal bounds for cross-validation via loss stability.
460,460,4.0," College of Computing, Georgia Institute of Technology, Atlanta, GA"," College of Computing, Georgia Institute of Technology, Atlanta, GA",sparsity-based generalization bounds for predictive sparse coding.
461,461,5.0," Department of Mathematics, National University of Singapore, Singapore"," Department of Mathematics, National University of Singapore, Singapore",sparse uncorrelated linear discriminant analysis.
462,462,6.0," INRIA, École Normale Supérieure, Paris, France"," Machine Learning Laboratory, ETH Zurich, Switzerland",block-coordinate frank-wolfe optimization for structural svms.
463,463,7.0," Max Planck Institute for Intelligent Systems, Dpt. of Empirical Inference, Tübingen, Germany"," Max Planck Institute for Intelligent Systems, Dpt. of Empirical Inference, Tübingen, Germany",fast probabilistic optimization from noisy gradients.
464,464,8.0," Microsoft Research, Redmond, WA"," Department of Statistics, Rutgers University, Piscataway, NJ",stochastic gradient descent for non-smooth optimization: convergence results and optimal averaging schemes.
465,465,9.0," School of Computational Science and Engineering, Georgia Tech"," School of Computational Science and Engineering, Georgia Tech",stochastic alternating direction method of multipliers.
466,466,10.0," Department of Mechanical Engineering, National University of Singapore, Singapore"," Department of Mechanical Engineering, National University of Singapore, Singapore",noisy sparse subspace clustering.
467,467,11.0," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA"," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA",parallel markov chain monte carlo for nonparametric mixture models.
468,468,12.0," Département d'informatique et de génie logiciel, Université Laval, Québec, QC, Canada"," Département d'informatique et de génie logiciel, Université Laval, Québec, QC, Canada",risk bounds and learning algorithms for the regression approach to structured output prediction.
469,469,13.0," Rowland Institute at Harvard, Cambridge, MA"," Rowland Institute at Harvard, Cambridge, MA",making a science of model search: hyperparameter optimization in hundreds of dimensions for vision architectures.
470,470,14.0," Dept. of Comp. Sci & Tech, TNLIST Lab, State Key Lab of Intell. Tech & Sys., Beijing, China"," Dept. of Comp. Sci & Tech, TNLIST Lab, State Key Lab of Intell. Tech & Sys., Beijing, China",gibbs max-margin topic models with fast sampling algorithm.
471,471,15.0," Washington University, St. Louis, MO"," Washington University, St. Louis, MO",cost-sensitive tree of classifiers.
472,472,16.0," Australian Centre for Visual Technologies and School of Computer Science, The University of Adelaide, Australia"," Australian Centre for Visual Technologies and School of Computer Science, The University of Adelaide, Australia",learning hash functions using column generation.
473,473,17.0," Microsoft Research Asia, Beijing, China"," Computer Science Department, Cornell University, Ithaca, NY","combinatorial multi-armed bandit: general framework, results and applications."
474,474,18.0," ETH Zurich, Zürich, Switzerland"," ETH Zurich, Zürich, Switzerland",near-optimal batch mode active learning and adaptive submodular optimization.
475,475,19.0," Computer Science Department, University of Geneva, Switzerland"," Business Informatics, University of Applied Sciences Western Switzerland",convex formulations of radius-margin based support vector machines.
476,476,20.0," Reasoning and Learning Laboratory, School of Computer Science, McGill University, Montreal, QC, Canada"," Reasoning and Learning Laboratory, School of Computer Science, McGill University, Montreal, QC, Canada",modelling sparse dynamical systems with compressed predictive state representations.
477,477,21.0," University of California, San Diego, La Jolla, CA"," Microsoft Research, Cambridge, MA",a machine learning framework for programming by example.
478,478,22.0," University of California, Berkeley, Berkeley, CA"," University of California, Berkeley, Berkeley, CA",discriminatively activated sparselets.
479,479,23.0," University of Pennsylvania, Department of Computer and Information Science, Philadelphia, PA"," The Hebrew University of Jerusalem, School of Computer Science, Jerusalem, Israel",the pairwise piecewise-linear embedding for efficient non-linear classification.
480,480,24.0," Lab of Neuro Imaging and Department of Computer Science, UCLA"," Lab of Neuro Imaging and Department of Computer Science, UCLA and Microsoft Research Asia",fixed-point model for structured labeling.
481,481,25.0," Department of Computer Science, University of Southern California, Los Angeles, CA"," Department of Computer Science, University of Southern California, Los Angeles, CA",connecting the dots with landmarks: discriminatively learning domain-invariant features for unsupervised domain adaptation.
482,482,26.0," Dept. of Computer Science, University of Maryland, College Park, MD"," IBM T.J. Watson Research Center, Yorktown Heights, NY",fast conical hull algorithms for near-separable non-negative matrix factorization.
483,483,27.0," Johns Hopkins University, Baltimore, MD"," Princeton University, Princeton, NJ",principal component analysis on non-gaussian dependent data.
484,484,28.0," Department of EECS, University of California, Irvine"," Microsoft Research, New England",learning linear bayesian networks with latent variables.
485,485,29.0," Department of Operations Research and Financial Engineering, Princeton University"," Department of Computer Science, Princeton University",multiple identifications in multi-armed bandits.
486,486,30.0," Toyota Technological Institute at Chicago, Chicago, IL"," Toyota Technological Institute at Chicago, Chicago, IL",learning optimally sparse support vector machines.
487,487,31.0," University of Cambridge, Dept. of Engineering, Cambridge, UK"," University of Cambridge, Dept. of Engineering, Cambridge, UK",dynamic probabilistic models for latent feature propagation in social networks.
488,488,32.0," Computer Science and Engineering, Arizona State University, Tempe, AZ and Center for Evolutionary Medicine and Informatics, Arizona State University, Tempe, AZ"," Computer Science and Engineering, Arizona State University, Tempe, AZ and Center for Evolutionary Medicine and Informatics, Arizona State University, Tempe, AZ",efficient sparse group feature selection via nonconvex optimization.
489,489,33.0," Department of Computer and Information Sciences, Temple University, Philadelphia, PA"," Department of Computer and Information Sciences, Temple University, Philadelphia, PA",domain adaptation for sequence labeling tasks with a probabilistic language adaptation model.
490,490,34.0," Washington University, St. Louis, MO"," Washington University, St. Louis, MO",maximum variance correction with application to a* search.
491,491,35.0," Scientific Computing and Imaging Institute, Salt Lake City, UT"," Scientific Computing and Imaging Institute, Salt Lake City, UT",adaptive sparsity in gaussian graphical models.
492,492,36.0," School of Computer Science, McGill University, Canada"," School of Computer Science, McGill University, Canada",average reward optimization objective in partially observable domains.
493,493,37.0," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA"," Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ",feature selection in high-dimensional classification.
494,494,38.0," Department of Computer Science, The University of Texas, Austin, TX"," Department of Computer Science, The University of Texas, Austin, TX",human boosting.
495,495,39.0, IBM T.J. Watson Research Center, University of Toronto,efficient dimensionality reduction for canonical correlation analysis.
496,496,40.0," Dept. of Bioengineering, University of Pennsylvania, Philadelphia, PA"," Depts. of Neurology and Bioengineering, University of Pennsylvania, Philadelphia, PA",parsing epileptic events using a markov switching process for correlated time series.
497,497,41.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",optimal rates for first-order stochastic convex optimization under tsybakov noise condition.
498,498,42.0," Department of Computing Science, University of Alberta, Edmonton, AB, Canada"," Department of Computing Science, University of Alberta, Edmonton, AB, Canada",a randomized mirror descent algorithm for large scale multiple kernel learning.
499,499,43.0," Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX"," Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX",noisy and missing data regression: distribution-oblivious support recovery.
500,500,44.0," Department of Mathematical Informatics, The University of Tokyo, Tokyo, Japan"," Department of Mathematical Informatics, The University of Tokyo, Tokyo, Japan",dual averaging and proximal gradient descent for online alternating direction multiplier method.
501,501,45.0," University of Hyogo, Kobe, Japan"," University of Hyogo, Kobe, Japan",a new frontier of kernel design for structured data.
502,502,46.0," Delft University of Technology, Delft, The Netherlands"," Washington University, St. Louis, MO",learning with marginalized corrupted features.
503,503,47.0," Department of Computer Science, University of Copenhagen, Copenhagen, Denmark"," Department of Computer Science, University of Copenhagen, Copenhagen, Denmark",approximation properties of dbns with binary hidden units and real-valued visible units.
504,504,48.0," CMAP, École Polytechnique, Palaiseau, France"," CMAP, École Polytechnique, Palaiseau, France",revisiting frank-wolfe: projection-free sparse convex optimization.
505,505,49.0," Shanghai Jiao Tong University, China"," Shanghai Jiao Tong University, China",general functional matrix factorization using gradient boosting.
506,506,50.0," Information Processing Group, Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland"," Algorithms Laboratory, Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland",iterative learning and denoising in convolutional neural associative memories.
507,507,51.0," Washington University, St. Louis"," Washington University, St. Louis",scaling multidimensional gaussian processes using projected additive approximations.
508,508,52.0," ETH Zurich, Zurich, Switzerland"," ETH Zurich, Zurich, Switzerland",active learning for multi-objective optimization.
509,509,53.0," Université d'Aix-Marseille, QARMA, CNRS, France"," Université de Lille, LIFL, CNRS, INRIA, France",a generalized kernel approach to structured output learning.
510,510,54.0," Benin School of CSE, The Hebrew University"," Benin School of CSE, The Hebrew University",efficient active learning of halfspaces: an aggressive approach.
511,511,55.0," Department of Mathematics, University of California, Los Angeles"," Department of Mathematics, University of California, Los Angeles",enhanced statistical rankings via targeted data collection.
512,512,56.0," School of Computing, National University of Singapore, Singapore"," School of Computing, National University of Singapore, Singapore",online feature selection for model-based reinforcement learning.
513,513,57.0," Bryn Mawr College, Computer Science Department, Bryn Mawr, PA"," Bryn Mawr College, Computer Science Department, Bryn Mawr, PA",ella: an efficient lifelong learning algorithm.
514,514,58.0," Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India"," Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India",a structural svm based approach for optimizing partial auc.
515,515,59.0," INRIA, Département d'Informatique de l'Ecole Normale Supérieure, Paris, France"," INRIA, Département d'Informatique de l'Ecole Normale Supérieure, Paris, France",convex relaxations for learning bounded-treewidth decomposable graphs.
516,516,60.0," University of California, Los Angeles"," Microsoft Research, New York City and University of California, Los Angeles",adaptive task assignment for crowdsourced classification.
517,517,61.0," The Technion, Faculty of Electrical Engineering, Haifa, Israel"," INRIA Lille-Nord Europe, Villeneuve d'Ascq, France",optimal regret bounds for selecting the state representation in reinforcement learning.
518,518,62.0," Dept. IRO, Université de Montréal, Montréal, QC, Canada"," Dept. IRO, Université de Montréal, Montréal, QC, Canada",better mixing via deep representations.
519,519,63.0," Department of Computer Science, University of Maryland, College Park, MD"," iSchool and UMIACS, University of Maryland, College Park, MD",online latent dirichlet allocation with infinite vocabulary.
520,520,64.0," Dept. of Computing Science, University of Alberta, Edmonton, AB, Canada"," Dept. of Computing Science, University of Alberta, Edmonton, AB, Canada",characterizing the representer theorem.
521,521,65.0," Duke University, Department of Electrical and Computer Engineering, Durham, NC"," Duke University, Department of Electrical and Computer Engineering, Durham, NC",dynamical models and tracking regret in online convex programming.
522,522,66.0," Computer and Information Science, University of Pennsylvania"," Computer and Information Science, University of Pennsylvania",large-scale bandit problems and kwik learning.
523,523,67.0," Interdiscplinary Center for Neural Computation Edmond and Lily Safra Center for Brain Sciences, The Hebrew University of Jerusalem Givat Ram, Jerusalem, Israel"," Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem Givat, Ram, Jerusalem, Israel",vanishing component analysis.
524,524,68.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",learning an internal dynamics model from control demonstration.
525,525,69.0," Department of Electrical and Computer Engineering, University of California, San Diego, CA"," Department of Electrical and Computer Engineering, University of California, San Diego, CA",robust structural metric learning.
526,526,70.0," Saarland University, Saarbrücken, Germany"," Saarland University, Saarbrücken, Germany",constrained fractional set programs and their application in local clustering and community detection.
527,527,71.0," School of Computer Science, College of Computing, Georgia Institute of Technology, Atlanta, GA"," School of Computer Science, College of Computing, Georgia Institute of Technology, Atlanta, GA",efficient semi-supervised and active learning of disjunctions.
528,528,72.0," Department of Computer and Information Science, University of Oregon"," Department of Computer and Information Science, University of Oregon",convex adversarial collective classification.
529,529,73.0," LIPN, CNRS, UMR, Université Paris Nord, Villetaneuse, France"," INSERM, Université Pierre et Marie Curie, Paris, France",rounding methods for discrete linear classification.
530,530,0.0," Twitter Inc., San Francisco, CA"," College of Computing, Georgia Tech, Atlanta, GA",mixture of mutually exciting processes for viral diffusion.
531,531,1.0, Max Planck Institute for Intelligent Systems, University of Cambridge,gaussian process vine copulas for multivariate dependence.
532,532,2.0," INRIA Lille-Nord Europe, Villeneuve d'Ascq, France"," INRIA Lille-Nord Europe, Villeneuve d'Ascq, France",stochastic simultaneous optimistic optimization.
533,533,3.0," Statistical Laboratory, Center for Mathematical Sciences, Cambridge, United Kingdom"," INRIA Lille-Nord Europe, Villeneuve d'Ascq, France",toward optimal stratification for stratified monte-carlo integration.
534,534,4.0," State Key Laboratory on Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, China"," Computer Science and Engineering, Arizona State University, Tempe, AZ",a general iterative shrinkage and thresholding algorithm for non-convex regularized optimization problems.
535,535,5.0," Center for Pattern Recognition and Data Analytics, Deakin University, Australia and Institute for Multi-sensor Processing & Content Analysis, Curtin University, Australia"," Center for Pattern Recognition and Data Analytics, Deakin University, Australia",thurstonian boltzmann machines: learning from multiple inequalities.
536,536,6.0," Department of Computer Science and Engineering, University of California, San Diego"," Department of Computer Science and Engineering, University of California, San Diego",a variational approximation for topic modeling of hierarchical corpora.
537,537,7.0," Carnegie Mellon University, Department of Statistics, Pittsburgh, PA"," Carnegie Mellon University, Department of Statistics, Pittsburgh, PA",forecastable component analysis.
538,538,8.0," Department of Computer Science, ETH Zurich, Switzerland"," Department of Computer Science, ETH Zurich, Switzerland",ellipsoidal multiple instance learning.
539,539,9.0," Georgia Institute of Technology, Atlanta, GA"," Google Research, Mountain View, CA",local low-rank matrix approximation.
540,540,10.0," Orange-Labs, Lannion, France"," Orange-Labs, Lannion, France",generic exploration and k-armed voting bandits.
541,541,11.0," Istituto Italiano di Tecnologia, Genova, Italy"," Istituto Italiano di Tecnologia, Genova, Italy",a unifying framework for vector-valued manifold regularization and multi-view learning.
542,542,12.0," Massachusetts Institute of Technology, Cambridge, MA"," Massachusetts Institute of Technology, Cambridge, MA",learning connections in financial time series.
543,543,13.0," Department of Computer Science, Stanford University, Stanford, CA"," Department of Computer Science, Stanford University, Stanford, CA",fast dropout training.
544,544,14.0," Department of Information and Computer Science, Aalto University, Finland"," Department of Information and Computer Science, Aalto University, Finland and Helsinki Institute for Information Technology, Aalto University and University of Helsinki",scalable optimization of neighbor embedding for visualization.
545,545,15.0," LIPADE, University Paris Descartes, Paris, France"," LIPADE, University Paris Descartes, Paris, France",precision-recall space to correct external indices for biclustering.
546,546,16.0," Department of Computer Science, ETH Zurich, Switzerland"," D.R.C. School of Computer Science, University of Waterloo, Canada, ON",monochromatic bi-clustering.
547,547,17.0," Institut des Systèmes Intelligents et de Robotique, Université Pierre et Marie Curie, Paris, France"," Institut des Systèmes Intelligents et de Robotique, Université Pierre et Marie Curie, Paris, France",gated autoencoders with tied input weights.
548,548,18.0," VTT Technical Research Centre of Finland, Finland"," VTT Technical Research Centre of Finland, Finland",strict monotonicity of sum of squares error and normalized cut in the lattice of clusterings.
549,549,19.0," Johns Hopkins University, Baltimore, MD"," Princeton University, Princeton, NJ",transition matrix estimation in high dimensional time series.
550,550,20.0," Google Inc., New York, NY"," Google Inc., San Bruno, CA",label partitioning for sublinear ranking.
551,551,21.0," Computer Science Department, Stanford University, Palo Alto, CA"," Computer Science Department, Stanford University, Palo Alto, CA",subproblem-tree calibration: a unified approach to max-product message passing.
552,552,22.0," Dept. of Statistics, University of Oxford, Oxford, UK and Linear Accelerator Laboratory, CNRS, University of Paris Sud, Orsay, France and Computer Science Laboratory, CNRS, University of Paris Sud, Orsay, France"," Computer Science Laboratory, CNRS, University of Paris Sud, Orsay, France",collaborative hyperparameter tuning.
553,553,23.0," Faculty of Computer Science, Guangdong University of Technology and State Key Laboratory for Novel Software Technology, Nanjing University, P.R. China"," Faculty of Computer Science, Guangdong University of Technology, P.R. China",sada: a general framework to support robust causation discovery.
554,554,24.0," Dept. of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI"," Dept. of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI",learning and selecting features jointly with point-wise gated boltzmann machines.
555,555,25.0," Electrical Engineering Department, Stanford University, Stanford, CA"," Technicolor Research Center, Palo Alto, CA",sequential bayesian search.
556,556,26.0,,,sparse projections onto the simplex.
557,557,27.0," ICNC-ELSC & Computer Science Department, The Hebrew University of Jerusalem, Jerusalem, Israel"," The Gonda Brain Research Center, Bar Ilan University, Ramat-Gan, Israel",modeling musical influence with topic models.
558,558,28.0," Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India and IBM Research, India"," Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India",subtle topic models and discovering subtly manifested software concerns automatically.
559,559,29.0," Department of Electrical & Computer Engineering, Duke University, Durham, NC"," Department of Electrical & Computer Engineering, Duke University, Durham, NC",exploring the mind: integrating questionnaires and fmri.
560,560,30.0," LIONS, École Polytechnique Fédérale de Lausanne, Switzerland"," LIONS, École Polytechnique Fédérale de Lausanne, Switzerland",a proximal newton framework for composite minimization: graph learning without cholesky decompositions and matrix inversions.
561,561,31.0,,,a practical algorithm for topic modeling with provable guarantees.
562,562,32.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",distributed training of large-scale logistic models.
563,563,33.0," Princeton University, Princeton, NJ"," Carnegie Mellon University, Pittsburgh, PA",an adaptive learning rate for stochastic variational inference.
564,564,34.0," Department of Computer Science and Engineering, UCSD, La Jolla, CA"," Department of Computer Science and Engineering, UCSD, La Jolla, CA","margins, shrinkage and boosting."
565,565,35.0," Dalla Lana School of Public Health, University of Toronto, Canada"," Shanghai Key Lab of Intelligent Information Processing & School of Computer Science, Fudan University, China",canonical correlation analysis based on hilbert-schmidt independence criterion and centered kernel target alignment.
566,566,36.0," Google, Inc., Pittsburgh, PA and Seattle, WA"," Google, Inc., Pittsburgh, PA and Seattle, WA",large-scale learning with less ram via randomization.
567,567,37.0," Dept. of Computer Science, Cornell University, Ithaca, NY"," Dept. of Computer Science, Cornell University, Ithaca, NY",taming the curse of dimensionality: discrete integration by hashing and optimization.
568,568,38.0,," Department of Computer Science and UCL Interactive Centre, University College London, London, UK",sparse coding for multitask and transfer learning.
569,569,39.0," Department of Information Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong"," Department of Information Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong",direct modeling of complex invariances for visual object features.
570,570,40.0," Columbia University, New York, NY"," Columbia University, New York, NY",hierarchically-coupled hidden markov models for learning kinetic rates from single-molecule data.
571,571,41.0," Machine Learning Department, Carnegie Mellon University",,activized learning with uniform classification noise.
572,572,0.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",guided policy search.
573,573,1.0," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan"," Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan",squared-loss mutual information regularization: a novel information-theoretic approach to semi-supervised learning.
574,574,2.0," INRIA Lille-Nord Europe, Villeneuve d'Ascq, France and Hungarian Acad. Sci. and Univ. of Szeged, Szeged, Hungary"," Linear Accelerator Laboratory, Computer Science Laboratory, CNRS, University of Paris Sud, Orsay, France",gossip-based distributed stochastic bandit algorithms.
575,575,3.0, Australian National University, Australian National University,the sample-complexity of general reinforcement learning.
576,576,4.0," School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel"," School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel",hierarchical regularization cascade for joint learning.
577,577,5.0," Google Research, New York, NY"," Google Research, New York, NY",multi-class classification with maximum margin multiple kernel.
578,578,6.0," University of Potsdam, Department of Computer Science, Potsdam, Germany"," University of Potsdam, Department of Computer Science, Potsdam, Germany",bayesian games for adversarial regression problems.
579,579,7.0," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA"," Microsoft Research, Redmond, WA",optimistic knowledge gradient policy for optimal budget allocation in crowdsourcing.
580,580,8.0," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA"," Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA",markov network estimation from multi-attribute data.
581,581,9.0," Facebook Incorporation, Menlo Park, CA"," IBM T.J. Watson Research Center, Yorktown Heights, NY",mileage: multiple instance learning with global embedding.
582,582,10.0," Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI"," Department of Computer Science and Engineering, Arizona State University, Tempe, AZ",guaranteed sparse recovery under linear transformation.
583,583,11.0, University of Montreal," University of California, Berkeley",learning invariant features by harnessing the aperture problem.
584,584,12.0," Computer Science Division, University of California, Berkeley, CA"," Microsoft Research, Redmond, WA",efficient ranking from pairwise comparisons.
585,585,13.0," Microsoft Research Labs, Bangalore, India", Stanford University and Microsoft Research,differentially private learning with kernels.
586,586,14.0," Microsoft Research, New York, NY"," Microsoft Research, New York, NY",selective sampling algorithms for cost-sensitive multiclass prediction.
587,587,15.0,"I3A, Universidad de Zaragoza, Spain"," Inria Bordeaux Sud-Ouest, France",learning multiple behaviors from unlabeled demonstrations in a latent controller space.
588,588,16.0," Institute of Science and Technology, Austria"," Institute of Science and Technology, Austria",inference algorithms for pattern-based crfs on sequence data.
589,589,17.0," IIT Bombay, Mumbai, India"," Microsoft Research India, Bangalore, India",one-bit compressed sensing: provable support and vector recovery.
590,590,18.0," Department of Computer Science, University of Toronto. Toronto, Ontario, Canada"," Department of Computer Science, University of Toronto. Toronto, Ontario, Canada",tensor analyzers.
591,591,19.0," INRA, CNRS, Université d’Evry Val d'Essonne, Evry, France"," Mines ParisTech, CBIO, INSERM, Institut Curie, Paris, France",learning sparse penalties for change-point detection using max margin interval regression.
592,592,20.0," Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI"," Department of Psychology, University of Wisconsin-Madison, Madison, WI",learning from human-generated lists.
593,593,21.0," Computer Science Department, Stanford University, Palo Alto, CA"," Computer Science Department, Stanford University, Palo Alto, CA",a fast and exact energy minimization algorithm for cycle mrfs.
594,594,22.0, Microsoft Research Cambridge, University of Toronto,stochastic k-neighborhood selection for supervised and unsupervised learning.
595,595,23.0," Center for Computer Research in Music and Acoustics, Stanford University", Adobe Research,an efficient posterior regularized latent variable model for interactive sound source separation.
596,596,24.0," UC Berkeley, Dept. Statistics, Berkeley, CA"," UC Berkeley, Dept. Statistics, Berkeley, CA",estimating unknown sparsity in compressed sensing.
597,597,25.0," UC Berkeley, Statistics Department"," UC Berkeley, Statistics Department and EECS Department",mad-bayes: map-based asymptotic derivations from bayes.
598,598,26.0," Signal Processing and Speech Communication Laboratory, Graz University of Technology"," Signal Processing and Speech Communication Laboratory, Graz University of Technology",the most generative maximum margin bayesian networks.
599,599,27.0," Google Knowledge, Mountain View, CA"," Google Knowledge, Mountain View, CA",fastfood: approximating kernel expansions in loglinear time.
600,600,28.0," Arizona State University, Tempe, AZ"," Arizona State University, Tempe, AZ",joint transfer and batch-mode active learning.
601,601,29.0," Departments of Computer Science and Statistics, Purdue University, West Lafayette, IN"," School of Electrical and Computer Engineering, Purdue University West Lafayette, IN",message passing with l1 penalized kl minimization.
602,602,30.0," Graduate School of Informatics, Kyoto University"," CNRS, Ecole Polytechnique",mean reversion with a variance threshold.
603,603,31.0," CSML, University College London"," Department of Statistics, University of Oxford",top-down particle filtering for bayesian decision trees.
604,604,32.0," College of Computing, Georgia Institute of Technology"," College of Computing, Georgia Institute of Technology",smooth sparse coding via marginal regression for learning sparse representations.
605,605,33.0," Department of Electronics and Information Engineering, Huazhong University of Science and Technology"," Microsoft Research Asia and Lab of Neuro Imaging and Department of Computer Science, University of California, Los Angeles",max-margin multiple-instance dictionary learning.
606,606,34.0," Dept. Elect., Inf. and Bioeng., Politecnico di Milano, Milan, Italy"," Dept. Elect., Inf. and Bioeng., Politecnico di Milano, Milan, Italy",safe policy iteration.
607,607,35.0," ELEC, Vrije Universiteit Brussel, Brussels, Belgium"," College of Computing, Georgia Institute of Technology, Atlanta, GA",unfolding latent tree structures using 4th order tensors.
608,608,36.0," University of Toronto, Toronto, ON, Canada"," Microsoft Research, Mountain View, CA",learning fair representations.
609,609,37.0," College of Computing, Georgia Institute of Technology, Atlanta, GA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",hierarchical tensor decomposition of latent tree graphical models.
610,610,38.0," Courant Institute of Mathematical Sciences, New York University, New York, NY"," Courant Institute of Mathematical Sciences, New York University, New York, NY",no more pesky learning rates.
611,611,39.0," Colorado School of Mines, Golden, Colorado"," The University of Texas at Arlington, Arlington, Texas",multi-view clustering and feature learning via structured sparsity.
612,612,40.0," Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada"," Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada",efficient planning in mdps by small backups.
613,613,41.0," Karlsruhe Institute of Technology, Karlsruhe, Germany"," Karlsruhe Institute of Technology, Karlsruhe, Germany",solving continuous pomdps: value iteration with incremental learning of an efficient space representation.
614,614,42.0," ENSAE, CREST, GENES"," Institut Mines-Télécom, Télécom ParisTech, CNRS, LTCI",learning heteroscedastic models by convex programming under group sparsity.
615,615,43.0," NEC Laboratories America, Inc., Princeton, NJ"," Department of Electrical and Computer Engineering, Rutgers, The State University of New Jersey, NJ",covariate shift in hilbert space: a solution via surrogate kernels.
616,616,44.0," MIT, CSAIL, Cambridge, MA"," Google Research, New York, NY",a local algorithm for finding well-connected clusters.
617,617,45.0," Department of Computer Science and Engineering, Hong Kong University of Science and Technology"," Department of Computer Science and Engineering, Hong Kong University of Science and Technology",efficient multi-label classification with many labels.
618,618,46.0," Department of Electrical Engineering, Stanford University, Stanford, CA"," Electrical and Computer Engineering, The Ohio State University, Columbus, OH",spectral compressed sensing via structured matrix completion.
619,619,47.0," Department of Information Science and Electronic Engineering, Zhejiang University, China"," Department of Information Science and Electronic Engineering, Zhejiang University, China",multi-task learning with gaussian matrix generalized inverse gaussian model.
620,620,48.0," Department of Information and Computer Science, Aalto University School of Science, Finland"," Department of Information and Computer Science, Aalto University School of Science, Finland",simple sparsification improves sparse denoising autoencoders in denoising highly noisy images.
621,621,49.0," Department of Computer Science and Engineering, Indian Institute of Technology, Kanpur, UP, India"," Department of Computer Science and Engineering, Indian Institute of Technology, Kanpur, UP, India",on the generalization ability of online learning algorithms for pairwise loss functions.
622,622,50.0," University of Queensland, School of ITEE, QLD, Australia and NICTA, Canberra, ACT, Australia"," NICTA, Canberra, ACT, Australia",non-linear stationary subspace analysis with application to video classification.
623,623,51.0," CSAIL, MIT, Cambridge, MA"," CSAIL, MIT, Cambridge, MA",two-sided exponential concentration bounds for bayes error rate and shannon entropy.
624,624,52.0," University of California, San Diego, La Jolla, CA"," University of California, San Diego, La Jolla, CA",that was fast! speeding up nn search of high dimensional distributions.
625,625,53.0," Electrical Engineering and Computer Science, School of Engineering, University of California, Merced"," Electrical Engineering and Computer Science, School of Engineering, University of California, Merced",entropic affinities: properties and efficient numerical computation.
626,626,54.0," Indian Institute of Technology Delhi, New Delhi, India"," Microsoft Research India, Bangalore, India",local deep kernel learning for efficient non-linear svm prediction.
627,627,55.0," Department of Electrical Engineering, The Technion-Israel Institute of Technology, Haifa, Israel"," Department of Electrical Engineering, The Technion-Israel Institute of Technology, Haifa, Israel",temporal difference methods for the variance of the reward to go.
628,628,56.0," Columbia University, New York, NY"," Columbia University, New York, NY",∞svm for learning with label proportions.
629,629,57.0," Computer Science Department, Stanford University, Stanford, CA"," Computer Science Department, Stanford University, Stanford, CA",parameter learning and convergent inference for dense random fields.
630,630,58.0," Microsoft Cloud and Information Services Laboratory, Redmond, WA"," Microsoft Cloud and Information Services Laboratory, Redmond, WA",loss-proportional subsampling for subsequent erm.
631,631,59.0," LinkedIn Corporation, Mountain View, CA"," LinkedIn Corporation, Mountain View, CA",scalable simple random sampling and stratified sampling.
632,632,60.0," Bioinformatics Institute, A*STAR, Singapore and School of Computing, National University of Singapore, Singapore"," Bioinformatics Institute, A*STAR, Singapore and School of Computing, National University of Singapore, Singapore",riemannian similarity learning.
633,633,61.0," UC Berkeley EECS, Berkeley, CA"," UC Berkeley EECS, Berkeley, CA",on compact codes for spatially pooled features.
634,634,62.0," University of Cambridge, Department of Engineering, Cambridge, UK"," University of Cambridge, Department of Engineering, Cambridge, UK",dynamic covariance models for multivariate financial time series.
635,635,63.0," Dept. of Applied and Computational Math, CalTech, Pasadena, CA"," Dept. of Mathematics, Stanford University, Stanford, CA",revisiting the nyström method for improved large-scale machine learning.
636,636,64.0," National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan"," National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan",infinite positive semidefinite tensor factorization for source separation of mixture signals.
637,637,65.0," Department of Mechanical Engineering, National University of Singapore, Singapore"," Department of Mechanical Engineering, National University of Singapore, Singapore",a unified robust regression model for lasso-like algorithms.
638,638,66.0," Caltech, Pasadena, CA"," Caltech, Pasadena, CA",quickly boosting decision trees: pruning underachieving features early.
639,639,67.0," University of California, San Diego, La Jolla, CA"," University of Sydney and NICTA, Sydney, Australia",on the statistical consistency of algorithms for binary classification under class imbalance.
640,640,68.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",topic model diagnostics: assessing domain relevance via topical alignment.
641,641,69.0," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI"," State Key Laboratory of CAD&CG, College of Computer Science, Zhejiang University, Hangzhou, China",online kernel learning with a near optimal sparsity bound.
642,642,70.0," Machine Learning Department, Carnegie Mellon University"," Robotics Institute, Carnegie Mellon University",spectral learning of hidden markov models from dynamic and static data.
643,643,71.0," Department of Computer Science, University of Texas, Austin, TX"," Department of Computer Science, University of Southern California, Los Angeles, CA",analogy-preserving semantic embedding for visual object categorization.
644,644,72.0," UC Riverside, Riverside, CA"," UC Riverside, Riverside, CA","algebraic classifiers: a generic approach to fast cross-validation, online training and parallel training."
645,645,73.0," Center for Pattern Recognition and Data Analytics, Deakin University, VIC, Australia"," Center for Pattern Recognition and Data Analytics, Deakin University, VIC, Australia",factorial multi-task learning: a bayesian nonparametric approach.
646,646,74.0, MPI for Intelligent Systems and Stanford University, MPI for Intelligent Systems,modeling information propagation with survival theory.
647,647,75.0," Microsoft Research, Redmond, WA"," Technion-Israel Inst. of Tech., Haifa, Israel",better rates for any adversarial deterministic mdp.
648,648,76.0," EPFL, Lausanne, Switzerland"," University of Ioannina, Greece",abc reinforcement learning.
649,649,77.0," School of Computer Science, University of Birmingham, Edgbaston, UK"," School of Computer Science, University of Birmingham, Edgbaston, UK",sharp generalization error bounds for randomly-projected classifiers.
650,650,78.0," Department of Computer Science, Ben-Gurion University, Beer Sheva, Israel"," Department of Computer Science, Ben-Gurion University, Beer Sheva, Israel",on learning parametric-output hmms.
651,651,79.0," School of Computer Science and Engineering and the Center for Neural Computation, The Hebrew University of Jerusalem, Jerusalem, Israel"," School of Computer Science and Engineering and the Center for Neural Computation, The Hebrew University of Jerusalem, Jerusalem, Israel",lda topic model with soft assignment of descriptors to words.
652,652,80.0," Goethe Universität Frankfurt, Frankfurt, Germany"," University of Montreal, Montreal, Canada",on autoencoder scoring.
653,653,81.0," Department of Electrical Engineering, Computer Engineering and Informatics, Cyprus University of Technology"," Department of Electrical Engineering, Computer Engineering and Informatics, Cyprus University of Technology",infinite markov-switching maximum entropy discrimination machines.
654,654,82.0," Département d'informatique et de génie logiciel, Université Laval, Québec, Canada"," Aix-Marseille Univ., LIF-QARMA, CNRS, UMR, Marseille, France",a pac-bayesian approach for domain adaptation with specialization to linear classifiers.
655,655,83.0," Department of Electrical and Computer Engineering, University of Texas at Austin, TX", Stochastic Technologies,sparse pca through low-rank approximations.
656,656,84.0," Department of Statistics, University of Chicago, Chicago, IL"," Department of Statistics and Department of Computer Science, University of Chicago, Chicago, IL",computation-risk tradeoffs for covariance-thresholded regression.
657,657,85.0," Business Analytics and Mathematical Sciences, IBM Thomas J. Watson Research Center, Yorktown Heights, NY"," Business Analytics and Mathematical Sciences, IBM Thomas J. Watson Research Center, Yorktown Heights, NY",exact rule learning via boolean compressed sensing.
658,658,86.0," Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX"," Department of Electrical Engineering, Technion, Haifa, Israel",robust sparse regression under adversarial corruption.
659,659,87.0," INRIA, Grenoble, France"," INRIA, Grenoble, France",optimization with first-order surrogate functions.
660,660,88.0," Computer Science Department, Cornell University, Ithaca, NY"," Computer Science Department, Cornell University, Ithaca, NY",learning spatio-temporal structure from rgb-d videos for human activity detection and anticipation.
661,661,89.0," Microsoft, Sunnyvale, CA"," Department of Computer Science, Columbia University, New York, NY",consistency versus realizable h-consistency for multiclass classification.
662,662,90.0," Microsoft Research New England, Cambridge, MA"," Microsoft Research New England, Cambridge, MA",feature multi-selection among subjective features.
663,663,91.0," Max Plank Institute for Intelligent Systems, Tübingen, Germany"," Max Plank Institute for Intelligent Systems, Tübingen, Germany",domain adaptation under target and conditional shift.
664,664,92.0," University of Maryland, College Park, MD"," University of Maryland, College Park, MD",collective stability in structured prediction: generalization from one example.
665,665,93.0," Department of Computer Science, Cornell University, Ithaca, NY"," Fachbereich Informatik, Universitaet Stuttgart, Stuttgart, Germany",stable coactive learning via perturbation.
666,666,94.0," Department of Electronics and Information Engineering, Huazhong University of Science and Technology"," Microsoft Research Asia and Lab of Neuro Imaging and Department of Computer Science, University of California, Los Angeles",max-margin multiple-instance dictionary learning.
667,667,95.0," University of Washington, Seattle, WA"," University of Washington, Seattle, WA",fast semidifferential-based submodular function optimization.
668,668,96.0," Helsinki Institute for Information Technology and Department of Information and Computer Science, Aalto University"," Helsinki Institute for Information Technology and Department of Information and Computer Science, Aalto University and Department of Computer Science, University of Helsinki",kernelized bayesian matrix factorization.
669,669,97.0," Department of Computer Science & Engineering, University of Washington, Seattle, WA"," Department of Computer Science & Engineering, University of Washington, Seattle, WA",learning the structure of sum-product networks.
670,670,98.0," ICME, Stanford University, Stanford, CA"," Dept. of Mathematics, Stanford University, Stanford, CA",quantile regression for large-scale applications.
671,671,99.0," LinkedIn Corporation, Mountain View, CA"," Department of Mathematics, Stanford University, Stanford, CA",robust regression on mapreduce.
672,672,100.0," Nagoya Institute of Technology, Nagoya, Japan"," Tokyo Institute of Technology, Tokyo, Japan",infinitesimal annealing for training semi-supervised support vector machines.
673,673,101.0," National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China"," National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",one-pass auc optimization.
674,674,102.0," Microsoft Research Cambridge, Cambridge, United Kingdom"," Microsoft Research Cambridge, Cambridge, United Kingdom",learning convex qp relaxations for structured prediction.
675,675,103.0," Department of Computer Science, CSML, University College London, London"," Causata Ltd., London",concurrent reinforcement learning from customer interactions.
676,676,104.0," Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, China"," Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, China",saving evaluation time for the decision function in boosting: representation and reordering base learner.
677,677,105.0," Idiap Research Institute, Switzerland and École Polytechnique Fédérale de Lausanne, Switzerland", Toyota Technological Institute at Chicago,stability and hypothesis transfer learning.
678,678,106.0," School of Computer and Communication Sciences, Ecole Polytechnique Fédérale de Lausanne, Switzerland"," School of Computer and Communication Sciences, Ecole Polytechnique Fédérale de Lausanne, Switzerland",fast dual variational inference for non-conjugate latent gaussian models.
679,679,107.0," Technical University of Denmark, DTU Compute, Lyngby, Denmark"," Technical University of Denmark, DTU Compute, Lyngby, Denmark",modeling temporal evolution and multiscale structure in networks.
680,680,108.0," RSISE, Australian National University, Australia and National ICT, Canberra, Australia"," Dept. Statistics, University of Oxford, UK",dependent normalized random measures.
681,681,109.0," Dept. of Comp. Sci. & Tech., LITS Lab, TNList Lab, Tsinghua University, Beijing, China"," Dept. of Comp. Sci. & Tech., LITS Lab, TNList Lab, Tsinghua University, Beijing, China",fast max-margin matrix factorization with data augmentation.
682,682,110.0," University of Lousiana at Lafayette, Lafayette, LA"," University of Lousiana at Lafayette, Lafayette, LA",natural image bases to represent neuroimaging data.
683,683,111.0," Department of Computer Science, Technion Israel Institute of Technology"," Department of Mechanical Engineering, National University of Singapore",breaking the small cluster barrier of graph clustering.
684,684,112.0," University of Massachusetts, Amherst, MA"," Oregon State University, Corvallis, OR",approximate inference in collective graphical models.
685,685,113.0," Engineering Department, Cambridge University, Cambridge, UK"," Engineering Department, Cambridge University, Cambridge, UK",scaling the indian buffet process via submodular maximization.
686,686,114.0," University of Edinburgh, JCMB, Edinburgh, UK"," Toyota Technological Institute at Chicago, Chicago, Illinois",mini-batch primal and dual methods for svms.
687,687,115.0," Department of Statistics, Colorado State University, Fort Collins, CO"," Department of Statistics, Indiana University, Bloomington, IN","the lasso, persistence and cross-validation."
688,688,116.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",spectral experts for estimating mixtures of linear regressions.
689,689,117.0," Machine Learning Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," Machine Learning Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",distribution to distribution regression.
690,690,118.0," Dept. of Computer Science, Courant Institute of Mathematical Science, New York University"," Dept. of Computer Science, Courant Institute of Mathematical Science, New York University",regularization of neural networks using dropconnect.
691,691,119.0," Department of Engineering, University of Cambridge, Cambridge, UK"," School of Engineering and Applied Sciences, Harvard University, Cambridge",gaussian process kernels for pattern discovery and extrapolation.
692,692,120.0," Washington University, St. Louis, MO"," Washington University, St. Louis, MO",anytime representation learning.
693,693,121.0," QUT, Brisbane, QLD, Australia"," NICTA & ANU, Canberra, ACT, Australia",algorithms for direct 0-1 loss optimization in binary classification.
694,694,122.0," Mathematics and Computer Science, University of Marburg, Marburg, Germany and Research Group on Artificial Intelligence, Hungarian Academy of Sciences and University of Szeged, Hungary"," Mathematics and Computer Science, University of Marburg, Marburg, Germany",top-k selection based on adaptive sampling of noisy preferences.
695,695,123.0," Computer Science Department, Stanford University"," EECS Department, University of California, Berkeley",the extended parameter filter.
696,696,124.0," School of Computer Science, Georgia Institute of Technology, Atlanta, GA"," Blavatnik School of Computer Science, Tel Aviv University, Tel Aviv, Israel",exploiting ontology structures and unlabeled data for learning.
697,697,125.0," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI"," State Key Laboratory of CAD&CG, College of Computer Science, Zhejiang University, Hangzhou, China",o(log t) projections for stochastic optimization of smooth and strongly convex functions.
698,698,126.0," Institute of Computing Science, Poznan University of Technology, Poznan, Poland"," Mathematics and Computer Science, Marburg University, Marburg, Germany",optimizing the f-measure in multi-label classification: plug-in rule approach versus structured loss minimization.
699,699,127.0,,,on the importance of initialization and momentum in deep learning.
700,700,128.0," VMware Bulgaria EOOD, Sofia, Bulgaria"," Qatar Computing Research Institute, Doha, Qatar",a non-iid framework for collaborative filtering with restricted boltzmann machines.
701,701,129.0," CBIO Mines ParisTech, INSERM, Institut Curie"," CBIO Mines ParisTech, INSERM, Institut Curie",intersecting singularities for multi-structured estimation.
702,702,130.0, U. Cambridge, U. Cambridge,structure discovery in nonparametric regression through compositional kernel search.
703,703,131.0," School of Computer Science, University of Massachusetts, Amherst, MA"," Department of Math and Statistics, University of Massachusetts, Amherst, MA",copy or coincidence? a model for detecting social influence and duplication events.
704,704,132.0," Department of Computer Science, University College London, UK"," Department of Computer Science, University College London, UK",smooth operators.
705,705,133.0," Rutgers University, Piscataway, NJ"," Brown University, Providence, RI",the cross-entropy method optimizes for quantiles.
706,706,134.0," Department of Electrical & Computer Engineering, Boston University, Boston, MA"," Department of Electrical & Computer Engineering, Boston University, Boston, MA",topic discovery through data dependent and random projections.
707,707,135.0," University of Alberta, Edmonton, Canada"," University of Alberta, Edmonton, Canada",bayesian learning of recursively factored environments.
708,708,136.0," Microsoft Research, India"," Microsoft Research, India",thompson sampling for contextual bandits with linear payoffs.
709,709,137.0," Department of Statistical Science, University College London, London, UK"," Department of Statistics, University of Michigan, Ann Arbor, MI",the bigraphical lasso.
710,710,138.0," Yahoo! Labs, Haifa, Israel"," Yahoo! Labs, Haifa, Israel",almost optimal exploration in multi-armed bandits.
711,711,139.0, University of Washington, Toyota Technological Institute at Chicago,deep canonical correlation analysis.
712,712,140.0, University of British Columbia, University of British Columbia,consistency of online random forests.
713,713,141.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA","sparse gaussian conditional random fields: algorithms, theory and application to energy forecasting."
714,714,142.0," Amazon.com, Seattle, WA"," Washington University in St. Louis, St. Louis, MO",fast image tagging.
715,715,143.0," Robotics Institute, Carnegie Mellon University, Pittsburgh, PA"," Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",expensive function optimization with stochastic binary outcomes.
716,716,144.0," School of Informatics, University of Edinburgh"," School of Informatics, University of Edinburgh",multiple-source cross-validation.
717,717,145.0, Georgia Institute of Technology, Georgia Institute of Technology,learning triggering kernels for multi-dimensional hawkes processes.
718,718,146.0," Université de Montréal, Montréal, Québec, Canada"," Université de Montréal, Montréal, Québec, Canada",on the difficulty of training recurrent neural networks.
719,719,147.0," Département d'Informatique et de Recherche Opérationelle, Université de Montréal, Montréal, Québec, Canada"," Département d'Informatique et de Recherche Opérationelle, Université de Montréal, Montréal, Québec, Canada",maxout networks.
720,720,148.0," University of Maryland, College Park, MD"," University of Maryland, College Park, MD",predictable dual-view hashing.
721,721,149.0," Stanford University, Computer Science Dept., Stanford, CA"," NVIDIA Corporation, Santa Clara, CA",deep learning with cots hpc systems.
722,722,150.0," Brigham and Women's Hospital, Boston, MA and Department of Electrical and Computer Engineering, Northeastern University, Boston, MA"," Department of Electrical and Computer Engineering, Northeastern University, Boston, MA",nonparametric mixture of gaussian processes with constraints.
723,723,151.0," Machine Learning Department, School of Computer Science, Carnegie Mellon University"," Machine Learning Department, School of Computer Science, Carnegie Mellon University",scale invariant conditional dependence measures.
724,724,152.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",learning policies for contextual submodular prediction.
725,725,153.0," Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL"," University of Illinois at Urbana-Champaign, Urbana, IL and Adobe Research, Adobe Systems Inc., San Francisco, CA",manifold preserving hierarchical topic models for quantization and approximation.
726,726,154.0," Nagoya Institute of Technology, Nagoya, Japan"," Nagoya Institute of Technology, Nagoya, Japan",safe screening of non-support vectors in pathwise svm computation.
727,727,155.0," Department of Computing Science, University of Alberta"," Department of Computing Science, University of Alberta",cost-sensitive multiclass classification risk bounds.
728,728,156.0," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI"," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI",semi-supervised clustering by input pattern assisted pairwise similarity matrix completion.
729,729,157.0," Dept. of Computer Engineering, Boǧaziçi University, Bebek, Istanbul, Turkey"," Sibnet Computers Ltd., Istanbul, Turkey",learning the β-divergence in tweedie compound poisson matrix factorization models.
730,730,158.0," Department of Computer Science, Stanford University, Stanford, CA"," Department of Computer Science, Stanford University, Stanford, CA",fast algorithms for sparse principal component analysis based on rayleigh quotient iteration.
731,731,159.0, Research @ Google, Carnegie Mellon University,nested chinese restaurant franchise processes: applications to user tracking and document modeling.
732,732,160.0," Georgia Institute of Technology, Atlanta, GA"," Georgia Institute of Technology, Atlanta, GA",tree-independent dual-tree algorithms.
733,733,161.0," Department of Computer Science and UCL Interactive Centre, University College London, UK"," Department of Computer Science and Centre for Computational Statistics and Machine Learning, University College London, UK",multilinear multitask learning.
734,734,162.0," Dept. of Computing Science, University of Alberta, Edmonton, AB, Canada"," Dept. of Computing Science, University of Alberta, Edmonton, AB, Canada",online learning under delayed feedback.
735,735,163.0," Department of Computer Science, University of British Columbia, Vancouver, BC, Canada"," Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",adaptive hamiltonian and riemann manifold monte carlo samplers.
736,736,164.0," Brown University, Providence, RI"," Brown University, Providence, RI",coco-q: learning in stochastic games with side payments.
737,737,165.0," Qualcomm Technologies, Inc., San Diego, CA"," University of Florida, Gainesville, FL",on a nonlinear generalization of sparse coding and dictionary learning.
738,738,166.0," Department of Statistics, Harvard University, Cambridge, MA"," Department of Statistics, Harvard University, Cambridge, MA",estimation of causal peer influence effects.
739,739,0.0, Google Research, University of Illinois,a discriminative latent variable model for online clustering.
740,740,1.0," Empirical Inference Department, Max Planck Institute for Intelligent Systems, Tübingen, Germany"," Empirical Inference Department, Max Planck Institute for Intelligent Systems, Tübingen, Germany",kernel mean estimation and stein effect.
741,741,2.0," Information Sciences Institute, Marina del Rey, CA and University of Southern California, Los Angeles, CA"," Santa Fe Institute, Santa Fe, NM and School of Informatics and Computing, Indiana University, Bloomington, IN",demystifying information-theoretic clustering.
742,742,3.0," Department of Computer Science, National University of Singapore, Singapore, Singapore"," Department of Computer Science, National University of Singapore, Singapore, Singapore",covering number for efficient heuristic-based pomdp planning.
743,743,4.0," Department of Mechanical Engineering, National University of Singapore, Singapore"," Department of Mechanical Engineering, National University of Singapore, Singapore",the coherent loss function for classification.
744,744,5.0," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong"," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong",fast stochastic alternating direction method of multipliers.
745,745,6.0," ETH Zürich, Zürich, Switzerland"," ETH Zürich, Zürich, Switzerland",active detection via adaptive submodularity.
746,746,7.0," School of Computer Science and Engineering, The Hebrew University, Jerusalem, Israel"," Department of Statistics, Rutgers University, NJ, and Baidu Inc., Beijing, China",accelerated proximal stochastic dual coordinate ascent for regularized loss minimization.
747,747,8.0," The University of Iowa, Iowa City, IA"," Microsoft Research, Redmond,WA",an adaptive accelerated proximal gradient method and its homotopy continuation for sparse optimization.
748,748,9.0," Ecole Polytechnique Fédérale de Lausanne, Lausanne, Switzerland and Idiap Research Institute, Martigny, Switzerland"," Idiap Research Institute, Martigny, Switzerland",recurrent convolutional neural networks for scene labeling.
749,749,10.0," Department of Statistics, University of Georgia, Athens, GA"," Departments of Statistics and EECS, University of California at Berkeley, Berkeley, CA",a statistical perspective on algorithmic leveraging.
750,750,11.0," Department of Electrical Engineering, Technion - Israel Institute of Technology, Haifa, Israel"," School of Computer Science, Tel Aviv University, Israel",thompson sampling for complex online problems.
751,751,12.0," Machine Learning Group, Computer Science Department, Faculty of Sciences, Université Libre de Bruxelles, Brussels, Belgium"," Department of Econometrics and Business Statistics, Monash University, Clayton, VIC, Australia",boosting multi-step autoregressive forecasts.
752,752,13.0," Indian Institute of Science, Bangalore, India"," Indian Institute of Science, Bangalore, India",a statistical convergence perspective of algorithms for rank aggregation from pairwise data.
753,753,14.0," Department of Electrical Engineering, The Technion - Israel Institute of Technology, Haifa, Israel"," Department of Electrical Engineering, The Technion - Israel Institute of Technology, Haifa, Israel",scaling up approximate value iteration with options: better policies with fewer iterations.
754,754,15.0," The Technion, Faculty of Electrical Engineering, Haifa, Israel"," The Technion, Faculty of Electrical Engineering, Haifa, Israel",latent bandits.
755,755,16.0, ANU & NICTA, NICTA & ANU,fast allocation of gaussian process experts.
756,756,17.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",von mises-fisher clustering models.
757,757,18.0," INRIA Saclay Île-de-France, Palaiseau, France"," LSTA, Université Pierre et Marie Curie, Paris",convergence rates for persistence diagram estimation in topological data analysis.
758,758,19.0," Department of Computer Science, University of Copenhagen, Copenhagen, Denmark"," Department of Computer Science, University of Copenhagen, Copenhagen, Denmark",buffer k-d trees: processing massive nearest neighbor queries on gpus.
759,759,20.0," School of Information & Computer Sciences, University of California, Irvine, CA"," Informatics Institute, University of Amsterdam, Amsterdam, Netherlands",austerity in mcmc land: cutting the metropolis-hastings budget.
760,760,21.0," School of EECS, Peking University"," School of EECS, Peking University",understanding the limiting factors of topic modeling via posterior contraction analysis.
761,761,22.0," Department of Engineering, University of Cambridge, Cambridge"," Department of Computer Science, Princeton University, Princeton, NJ",the inverse regression topic model.
762,762,23.0," School of Engineering and Applied Sciences, Harvard University, Cambridge, MA"," Department of Statistics, Harvard University, Cambridge, MA",a consistent histogram estimator for exchangeable graph models.
763,763,24.0," Operations Research Center, Massachusetts Institute of Technology, Cambridge, MA"," IBM Thomas J. Watson Research Center, Yorktown Heights, NY",latent variable copula inference for bundle pricing from retail transaction data.
764,764,25.0," Department of Computer Science, Princeton University, Princeton, NJ"," Department of Computer Science, Princeton University, Princeton, NJ",towards minimax online learning with unknown time horizon.
765,765,26.0," School of Engineering and Applied Sciences, Harvard University, Cambridge"," Center for Geographic Analysis, Harvard University, Cambridge",factorized point process intensities: a spatial analysis of professional.
766,766,27.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA","margins, kernels and non-linear smoothed perceptrons."
767,767,28.0," Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI"," Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI",robust regbayes: selectively incorporating first-order logic domain knowledge into bayesian models.
768,768,29.0," Courant Institute and Google Research, New York, NY"," Courant Institute, New York, NY",learning theory and algorithms for revenue optimization in second-price auctions with reserve.
769,769,30.0," Dept. of Computer Science, Cornell University, Ithaca, NY"," Dept. of Computer Science, Cornell University, Ithaca, NY",low-density parity constraints for hashing-based discrete integration.
770,770,31.0, Queensland University of Technology and UC Berkeley, Queensland University of Technology and UC Berkeley,prediction with limited advice and multiarmed bandits with paid observations.
771,771,32.0," Center for Pattern Recognition and Data Analytics, Deakin University, Australia"," Laboratory for Natural Language Understanding, Nuance Communications, Sunnyvale",bayesian nonparametric multilevel clustering with group-level contexts.
772,772,33.0," Département d'Informatique de l'Ecole Normale Supérieure, CNRS, INRIA, ENS, Paris, France"," Département d'Informatique de l'Ecole Normale Supérieure, CNRS, INRIA, ENS, Paris, France",large-margin metric learning for constrained partitioning problems.
773,773,34.0," Department of Computer Science, Stanford University, Stanford, California"," Max Planck Center for Visual Computing and Communication, Saarbrücken, Germany",wasserstein propagation for semi-supervised learning.
774,774,35.0," Dept. of Comp. Sci. & Tech., TNList Lab, State Key Lab of Intell. Tech. & Sys., Tsinghua University, China"," Dept. of Comp. Sci. & Tech., TNList Lab, State Key Lab of Intell. Tech. & Sys., Tsinghua University, China",max-margin infinite hidden markov models.
775,775,36.0," School of Computer Science and Technology, Tianjin University, Tianjin, P. R. China"," School of Computer Science and Technology, Tianjin University, Tianjin, P. R. China",efficient approximation of cross-validation for kernel methods using bouligand influence function.
776,776,37.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",generalized exponential concentration inequality for rényi divergence estimation.
777,777,38.0," School of Computer Science, Georgia Institute of Technology, Atlanta, GA"," Institute of Information Science, Academia Sinica, Taipei, Taiwan",boosting with online binary learners for the multiclass bandit problem.
778,778,39.0," Graduate School of Information Science and Technology, The University of Tokyo, Tokyo and JST, ERATO, Tokyo"," National Institute of Informatics, JST, ERATO, Tokyo",optimal budget allocation: theoretical guarantee and efficient algorithm.
779,779,40.0," Harvard University, Cambridge, MA"," Rensselaer Polytechnic Institute, Troy, NY",computing parametric ranking models via rank-breaking.
780,780,41.0, Queensland University of Technology," University of California, Berkeley",tracking adversarial targets.
781,781,42.0," Institute for Interdisciplinary Information Sciences, Tsinghua University, China"," Dept. of Comp. Sci. & Tech., TNList Lab, State Key Lab of Intell. Tech. & Sys., Tsinghua University, China",online bayesian passive-aggressive learning.
782,782,43.0," DeepMind Technologies, London, UK"," DeepMind Technologies, London, UK",deterministic policy gradient algorithms.
783,783,44.0," Department of Electrical and Computer Engineering, Duke University, Durham, NC"," Department of Electrical and Computer Engineering, Duke University, Durham, NC",modeling correlated arrival events with latent semi-markov processes.
784,784,45.0," Department of Statistics, University of Oxford, Oxford, UK"," Department of Statistics, University of Oxford, Oxford, UK",towards scaling up markov chain monte carlo: an adaptive subsampling approach.
785,785,46.0," University of Salerno, Italy"," PUC-Rio, Brazil",diagnosis determination: decision trees optimizing simultaneously worst and expected testing cost.
786,786,47.0," Department of Computer Science and Information Engineering, National Taiwan University"," Department of Computer Science and Information Engineering, National Taiwan University",condensed filter tree for cost-sensitive multi-label classification.
787,787,48.0," Toyota Technological Institute at Chicago, Chicago, IL"," MIT, CSAIL, Cambridge, MA",on measure concentration of random maximum a-posteriori perturbations perturbations.
788,788,49.0," School of Computer Science, University of Massachusetts, Amherst, MA"," School of Computer Science, University of Massachusetts, Amherst, MA",bias in natural actor-critic algorithms.
789,789,50.0," Aix Marseille Université, CNRS, LIF, Marseille, France"," Université Jean Monnet de Saint-Etienne, CNRS, Saint-Etienne, France",dimension-free concentration bounds on hankel matrices for spectral learning.
790,790,51.0," Department of Computer Science, Tsinghua University, Beijing, China"," Department of Computer Science, Tsinghua University, Beijing, China",on modelling non-linear topical dependencies.
791,791,52.0," School of Informatics, University of Edinburgh"," Département d'informatique, Université de Sherbrooke",a deep and tractable density estimator.
792,792,53.0, Microsoft Research, Stanford University and Microsoft Research,(near) dimension independent risk bounds for differentially private learning.
793,793,54.0," ICME, Stanford University, Stanford, CA"," International Computer Science Institute and Dept. of Statistics, University of California at Berkeley, Berkeley, CA",quasi-monte carlo feature maps for shift-invariant kernels.
794,794,55.0," Microsoft CISL, Redmond, WA"," Microsoft CISL, Redmond, WA",discriminative features via generalized eigenvectors.
795,795,56.0," Department of Computer Sciences, University of Wisconsin-Madison"," Department of Computer Science and Engineering, Arizona State University",forward-backward greedy algorithms for general convex smooth functions over a cardinality constraint.
796,796,57.0," Department of Computing Science, University of Alberta, Edmonton, AB, Canada"," Department of Computing Science, University of Alberta, Edmonton, AB, Canada",online learning in markov decision processes with changing cost sequences.
797,797,58.0," KTH, Royal Institute of technology, Stockholm, Sweden"," KTH, Royal Institute of technology, Stockholm, Sweden",unimodal bandits: regret lower bounds and optimal algorithms.
798,798,59.0," Yahoo! Labs, Bangalore, Karnataka, India"," IIT Bombay, Mumbai, Maharashtra, India",maximum mean discrepancy for class ratio estimation: convergence bounds and kernel selection.
799,799,60.0," CBIO Mines ParisTech, Institut Curie, France"," SequeL-INRIA Lille-Nord Europe, France",asymptotically consistent estimation of the number of change points in highly dependent time series.
800,800,61.0," ICNC-ELSC & Computer Science Department, The Hebrew University of Jerusalem, Jerusalem, Israel and The Gonda Brain Research Center, Bar Ilan University, Ramat-Gan, Israel"," The Gonda Brain Research Center, Bar Ilan University, Ramat-Gan, Israel",coordinate-descent for learning orthogonal matrices through givens rotations.
801,801,62.0," Dept. of Computer Science, Computing and Information Science, Cornell University, Ithaca, NY"," Dept. of Statistics & Biostatistics, Dept. of Computer Science, Rutgers University, Piscataway, NJ",densifying one permutation hashing via rotation for fast near neighbor search.
802,802,63.0," Department of Computer Science, The University of Texas, Austin, TX"," Department of Computer Science, The University of Texas, Austin, TX",a divide-and-conquer solver for kernel support vector machines.
803,803,64.0," Department of Computer Science, The University of Texas, Austin, TX"," IBM T.J. Watson Research Center, Yorktown Heights, NY",nuclear norm minimization via active subspace selection.
804,804,65.0," Princeton University, Computer Science Department and Center for Computational Intractability, Princeton"," Princeton University, Computer Science Department and Center for Computational Intractability, Princeton",provable bounds for learning some deep representations.
805,805,66.0," Department of Computer Science, University of Texas at Austin"," Department of Computer Science, University of Texas at Austin",large-scale multi-label learning with missing labels.
806,806,67.0," Department of Computer Science, The University of Texas at Austin"," Department of Computer Science, The University of Texas at Austin",learning graphs with a few hubs.
807,807,68.0," Département d'informatique et de génie logiciel, Université Laval, Québec, Canada"," Département d'informatique et de génie logiciel, Université Laval, Québec, Canada",agnostic bayesian learning of ensembles.
808,808,69.0," UC Berkeley, Berkeley, CA and School of ECE, Shiraz University, Shiraz, Iran"," Carnegie Mellon University, Pittsburgh and Max Planck Institute for Intelligent Systems, Tübingen, Germany",towards an optimal stochastic alternating direction method of multipliers.
809,809,70.0," Department of Statistics, University of California, Irvine, CA"," Department of Statistics, University of California, Irvine, CA",spherical hamiltonian monte carlo for constrained target distributions.
810,810,71.0," Department of Computer Science, University of British Columbia, Vancouver, BC, Canada"," Statistics Department, University of British Columbia, Vancouver, BC, Canada",efficient continuous-time markov chain estimation.
811,811,72.0," UC Berkeley & ICSI, Berkeley, CA"," UC Berkeley & ICSI, Berkeley, CA",decaf: a deep convolutional activation feature for generic visual recognition.
812,812,73.0," Language Technologies Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," Language Technologies Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",making the most of bag of words: sentence regularization with alternating direction method of multipliers.
813,813,74.0," University of Oxford, United Kingdom"," University of Oxford, United Kingdom and University of British Columbia, Canada",narrowing the gap: random forests in theory and in practice.
814,814,75.0," University of California, Berkeley, CA"," The University of Texas at Austin, Austin, TX",coherent matrix completion.
815,815,76.0," Dept. of Computer Science, University of Texas, Austin, TX"," Dept. of Computer Science, University of Texas, Austin, TX",admixture of poisson mrfs: a topic model with word dependencies.
816,816,77.0," Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada"," Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada",true online td(λ).
817,817,78.0," Department of Computer Science, The University of Texas, Austin, TX"," Department of Computer Science, The University of Texas, Austin, TX",memory efficient kernel approximation.
818,818,79.0," Department of Computer and Information Science, University of Oregon"," Department of Computer and Information Science, University of Oregon",learning sum-product networks with direct and indirect variable interactions.
819,819,80.0," Stanford University, Palo Alto. Khan Academy, Mountain View"," Redwood Institute for Theoretical Neuroscience, University of California at Berkeley",hamiltonian monte carlo without detailed balance.
820,820,81.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",filtering with abstract particles.
821,821,82.0," Department of Mathematical and Computing Sciences, Tokyo Institute of Technology, Tokyo, Japan"," Department of Mathematical and Computing Sciences, Tokyo Institute of Technology, Tokyo, Japan",stochastic dual coordinate ascent with alternating direction method of multipliers.
822,822,83.0," Princeton University Princeton, NJ"," Princeton University Princeton, NJ",deep supervised and convolutional generative stochastic network for protein secondary structure prediction.
823,823,84.0," University of Freiburg, Freiburg, Germany"," University of British Columbia, Vancouver, Canada",an efficient approach for assessing hyperparameter importance.
824,824,0.0," Computer Vision & Multimedia Laboratory, University of Geneva, Switzerland"," Computer Vision & Multimedia Laboratory, University of Geneva, Switzerland",an information geometry of statistical manifold learning.
825,825,1.0," ISLA, University of Amsterdam, Netherlands"," ISLA, University of Amsterdam, Netherlands",relative upper confidence bound for the k-armed dueling bandit problem.
826,826,2.0, eBay Research Laboratory, eBay Research Laboratory,compact random feature maps.
827,827,3.0," Department of Computer Science, Ben-Gurion University, Beer Sheva, Isreal"," Department of Computer Science, Ben-Gurion University, Beer Sheva, Isreal",concentration in unbounded metric spaces and algorithmic stability.
828,828,4.0," Department of Computer Science, Columbia University"," Microsoft Research, New England, Cambridge, MA",heavy-tailed regression with a generalized median-of-means.
829,829,5.0," INRIA Lille-Nord Europe, Villeneuve d'Ascq, France"," INRIA Lille-Nord Europe, Villeneuve d'Ascq, France",spectral bandits for smooth graph functions.
830,830,6.0," School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an, China"," Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China",robust principal component analysis with complex noise.
831,831,7.0," Department of Computer Science, Stanford University, Stanford, CA"," Department of Computer Science, Stanford University, Stanford, CA",scalable semidefinite relaxation for maximum a posterior estimation.
832,832,8.0," Department of Industrial Engineering and Operations Research, Columbia University"," Department of Industrial Engineering and Operations Research, Columbia University",square deal: lower bounds and improved relaxations for tensor recovery.
833,833,9.0, Washington University in St. Louis, Washington University in St. Louis,automated inference of point of view from user interactions in collective intelligence venues.
834,834,10.0," The Biodesign Institue, Arizona State University, Tempe, AZ"," The Biodesign Institue, Arizona State University, Tempe, AZ and School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ",rank-one matrix pursuit for matrix completion.
835,835,11.0," Department of Electrical Engineering, Stanford University, Stanford, CA"," Department of Electrical Engineering, Stanford University, Stanford, CA",near-optimal joint object matching via convex relaxation.
836,836,12.0," IBM Research, Yorktown Heights, NY"," Departments of Physics and Biology, MIT, Cambridge, MA",convex total least squares.
837,837,13.0," Department of Computer Science & Engineering, Indian Institute of Technology Bombay, India"," Department of Computer Science & Engineering, Indian Institute of Technology Bombay, India",on p-norm path following in multiple kernel learning for non-linear feature selection.
838,838,14.0," Department of Statistical Science, Cornell University, Ithaca, NY and Dept. of Statistics & Biostatistics, Dept. of Computer Science, Rutgers University, Piscataway, NJ"," Dept. of Statistics & Biostatistics, Rutgers University, Piscataway, NJ",gradient hard thresholding pursuit for sparsity-constrained optimization.
839,839,15.0," CSAIL, MIT, Cambridge, MA"," CSAIL, MIT, Cambridge, MA",a unified framework for consistency of regularized loss minimizers.
840,840,16.0," Center for Evolutionary Medicine and Informatics, Arizona State University, Tempe, AZ"," Center for Evolutionary Medicine and Informatics, Arizona State University, Tempe, AZ",geodesic distance function learning via heat flow on vector fields.
841,841,17.0," ETH Zürich, Zürich, Switzerland"," ETH Zürich, Zürich, Switzerland",near-optimally teaching the crowd to classify.
842,842,18.0," University of California, Berkeley, CA"," University of California, Berkeley, CA",on the convergence of no-regret learning in selfish routing.
843,843,19.0," University of Lille, LIFL, CNRS, INRIA Lille Nord Europe, Villeneuve d'Ascq, France"," University of Lille, LIFL, CNRS, INRIA Lille Nord Europe, Villeneuve d'Ascq, France",improving offline evaluation of contextual bandit algorithms via bootstrapping techniques.
844,844,20.0," Electrical Engineering Department, The Technion-Israel Institute of Technology, Haifa, Israel"," Mechanical Engineering Department, National University of Singapore, Singapore",scaling up robust mdps using function approximation.
845,845,21.0," Department of Computer Science, University of California, Irvine"," Department of Computer Science, University of California, Irvine",marginal structured svm with hidden variables.
846,846,22.0," University of British Columbia, Canada"," University of British Columbia, Canada and University of Oxford, United Kingdom and Canadian Institute for Advanced Research",linear and parallel learning of markov random fields.
847,847,23.0, University of Cambridge, University of Cambridge,pitfalls in the use of parallel inference for the dirichlet process.
848,848,24.0, Carnegie Mellon U, Tsinghua U,optimal pac multiple arm identification with applications to crowdsourcing.
849,849,25.0, Canadian Inst. for Advanced Research," Department of Computer Science, Cornell University",deep generative stochastic networks trainable by backprop.
850,850,26.0," Arizona State University, Tempe, AZ"," Arizona State University, Tempe, AZ",a highly scalable parallel algorithm for isotropic total variation models.
851,851,27.0," Department of EECS, University of California, Berkeley, Berkeley, CA"," Department of ECE, University of Illinois at Urbana-Champaign, Urbana, IL",statistical-computational phase transitions in planted models: the high-dimensional setting.
852,852,28.0," CMLA, UMR, CNRS, ENS Cachan, France"," CMLA, UMR, CNRS, ENS Cachan, France",gaussian process optimization with mutual information.
853,853,29.0," Microsoft Research, Redmond, WA"," Microsoft Research, Redmond, WA",aggregating ordinal labels from crowds by minimax conditional entropy.
854,854,30.0," Department of Computer Science & Engineering, University of Washington, Seattle, WA"," Department of Computer Science & Engineering, University of Washington, Seattle, WA",exchangeable variable models.
855,855,31.0," David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada"," Computer Science Department, Carnegie Mellon University, Pittsburgh, PA",clustering in the presence of background noise.
856,856,32.0," SAS Institute Inc., Cary, NC"," Arizona State University, Tempe, AZ",safe screening with variational inequalities and its application to lasso.
857,857,33.0," National Tsing Hua University, ROC", University of Illinois at Chicago,learning the consistent behavior of common users for target node prediction across social networks.
858,858,34.0," Courant Institute, New York University"," Courant Institute, New York Unversity",signal recovery from pooling representations.
859,859,35.0," Computer Science Department, Carnegie Mellon University, Pittsburgh, PA"," Microsoft Research, Redmond, WA",pac-inspired option discovery in lifelong reinforcement learning.
860,860,36.0," Department of Computer Science and Technology, Tsinghua University, Beijing, P.R. China and School of Software, Tsinghua University, Beijing, P.R. China"," School of Software, Tsinghua University, Beijing, P.R. China",multi-label classification via feature-aware implicit label space encoding.
861,861,37.0," Machine Learning Group, Department of Engineering, University of Cambridge, UK"," Machine Learning Group, Department of Engineering, University of Cambridge, UK",scalable gaussian process structured prediction for grid factor graph applications.
862,862,38.0," LTCI UMR, Telecom ParisTech, CNRS, Paris, France"," LTCI UMR, Telecom ParisTech, CNRS, Paris, France and CIMFAV, Facultad de Ingeniera, Universidad de Valparaso, Valparaso, Chile",anomaly ranking as supervised bipartite ranking.
863,863,39.0," Department of Mathematics, Stanford University"," Department of Electrical and Systems Engineering, University of Pennsylvania",hierarchical quasi-clustering methods for asymmetric networks.
864,864,40.0," NTT communication science laboratories, Atsugi-shi, Kanagawa"," NTT communication science laboratories, Atsugi-shi, Kanagawa",rectangular tiling process.
865,865,41.0," Department of Computer Science, University of Geneva, Switzerland"," Department of Business Informatics, University of Applied Sciences, Western Switzerland and Department of Computer Science, University of Geneva, Switzerland",two-stage metric learning.
866,866,42.0," University of Cambridge, Department of Engineering, Cambridge, UK"," University of Cambridge, Department of Engineering, Cambridge, UK",stochastic inference for scalable probabilistic modeling of binary matrices.
867,867,43.0," Department of Computer Science, The University of Texas, Austin, TX"," Department of Computer Science, The University of Texas, Austin, TX",elementary estimators for high-dimensional linear regression.
868,868,44.0," Department of Computer Science, The University of Texas, Austin, TX"," Department of Computer Science, The University of Texas, Austin, TX",elementary estimators for sparse covariance matrices and other structured moments.
869,869,45.0," University of Illinois at Urbana-Champaign and Advanced Digital Sciences Center, Singapore"," Singapore Management University, Singapore",graph-based semi-supervised learning: realizing pointwise smoothness probabilistically.
870,870,46.0," Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China"," Dept. of Comp. Sci. & Tech, TNList Lab, State Key Lab of Intell. Tech & Sys, Tsinghua University, Beijing, China",bayesian max-margin multi-task learning with data augmentation.
871,871,47.0," Walmart Labs, San Bruno, CA"," Exxon Mobil Corporate Strategic Research, Annandale, NJ",sparse reinforcement learning via convex optimization.
872,872,48.0," Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal"," Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal",gaussian process classification and active learning with multiple annotators.
873,873,49.0," Helsinki Institute for Information Technology and Department of Information and Computer Science, Aalto University, Finland"," Helsinki Institute for Information Technology and Department of Information and Computer Science, Aalto University, Finland",structured prediction of network response.
874,874,50.0," United States Naval Academy, Annapolis, MD"," United States Naval Academy, Annapolis, MD",an analysis of state-relevance weights and sampling distributions on l1-regularized approximate linear programming approximation accuracy.
875,875,51.0," Department of Information and Computer Science, Aalto University, Finland"," Helsinki Institute for Information Technology and Department of Computer Science, University of Helsinki",optimization equivalence of divergences improves neighbor embedding.
876,876,52.0," Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI"," Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI",an asynchronous parallel stochastic coordinate descent algorithm.
877,877,53.0, Toyota Technological Institute-Chicago, Max Planck Institute for Intelligent Systems,consistency of causal inference under the additive noise model.
878,878,54.0," University of Toronto, Toronto, Canada"," University of Toronto, Toronto, Canada",globally convergent parallel map lp relaxation solver using the frank-wolfe algorithm.
879,879,55.0," Queensland University of Technology, Brisbane, QLD, Australia"," University of California, Berkeley, CA",linear programming for large-scale markov decision problems.
880,880,56.0," Computer Science and Engineering Department, University of Texas at Arlington, Arlington, TX"," Computer Science and Engineering Department, University of Texas at Arlington, Arlington, TX",new primal svm solver with linear computational cost for big data classifications.
881,881,57.0," The University of British Columbia, Vancouver, Canada"," The University of British Columbia, Vancouver, Canada",memory (and time) efficient sequential monte carlo.
882,882,58.0," Arizona State University, Tempe, AZ"," Arizona State University, Tempe, AZ",scaling svm and least absolute deviations via exact data reduction.
883,883,59.0," Department of Computer and Information Sciences, Temple University, Philadelphia, PA"," Department of Computer and Information Sciences, Temple University, Philadelphia, PA",latent semantic representation learning for scene classification.
884,884,60.0," Microsoft Research New York, NY"," Computer Science Department, Stanford University, CA",least squares revisited: scalable approaches for multi-class prediction.
885,885,61.0," Carnegie Mellon University, Pittsburgh"," Google, NY",local algorithms for interactive clustering.
886,886,62.0," Machine Learning and Robotics Lab, University of Stuttgart, Germany"," Machine Learning and Robotics Lab, University of Stuttgart, Germany",model-based relational rl when object existence is partially observable.
887,887,63.0," Reinforcement Learning and Artificial Intelligence Laboratory, University of Alberta, Edmonton, AB, Canada"," Reinforcement Learning and Artificial Intelligence Laboratory, University of Alberta, Edmonton, AB, Canada",a new q (λ) with interim forward view and monte carlo equivalence.
888,888,64.0," Computer and Information Science Department, University of Oregon"," Computer and Information Science Department, University of Oregon",on robustness and regularization of structural support vector machines.
889,889,65.0," University of California, San Diego, La Jolla, CA"," University of California, San Diego, La Jolla, CA",guess-averse loss functions for cost-sensitive multiclass boosting.
890,890,66.0," Department of Computer Science, University of Toronto and Canadian Institute for Advanced Research"," Department of Computer Science, University of Toronto and Canadian Institute for Advanced Research",multimodal neural language models.
891,891,67.0,,,fast large-scale optimization by unifying stochastic gradient and quasi-newton methods.
892,892,68.0," Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX"," Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX",alternating minimization for mixed linear regression.
893,893,69.0," Washington University in St. Louis, St. Louis, MO"," Washington University in St. Louis, St. Louis, MO",stochastic neighbor compression.
894,894,70.0," Department of Computing Science, University of Alberta, Edmonton, AB, Canada"," Department of Computing Science, University of Alberta, Edmonton, AB, Canada",robust learning under uncertain test distributions: relating covariate shift to model misspecification.
895,895,71.0," Georgia Institute of Technology, Atlanta, GA"," Georgia Institute of Technology, Atlanta, GA",nonparametric estimation of multi-view latent variable models.
896,896,72.0, University of Toronto, Microsoft Research,structured generative models of natural source code.
897,897,73.0," IBM Thomas J. Watson Research Center, Yorktown Heights, NY"," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI",a single-pass algorithm for efficiently recovering sparse cluster centers of high-dimensional data.
898,898,74.0," Department of Statistics, Harvard University, Cambridge, MA"," Department of Statistics, Harvard University, Cambridge, MA",statistical analysis of stochastic gradient methods for generalized linear models.
899,899,75.0," Dept. of Statistics and Biostatistics, Dept. of Computer Science, Rutgers University, Piscataway, NJ"," Dept. of Computer Science, Computing and Information Science, Cornell University, Ithaca, NY",coding for random projections.
900,900,76.0," Graduate School of Informatics, Kyoto University"," Department of Statistics, University of Oxford",fast computation of wasserstein barycenters.
901,901,77.0," Chalmers University of Technology, Gothenburg, Sweden"," Indian Institute of Science, Bangalore, Karnataka, India",global graph kernels using geometric embeddings.
902,902,78.0," Department of Computer Science, University of Illinois at Chicago"," Department of Computer Science, University of Illinois at Chicago","topic modeling using topics from many domains, lifelong learning and big data."
903,903,79.0," School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israel"," School of Computer Science and Engineering, The Hebrew University of Jerusalem, Israel",k-means recovers ica filters when independent components are sparse.
904,904,80.0," Institute for Computational and Mathematical Engineering, Stanford University, Stanford, CA"," Dept. of Electrical Engineering & Dept. of Statistics, Stanford University, Stanford, CA",learning mixtures of linear classifiers.
905,905,81.0," Carnegie Mellon University, Pittsburgh, PA"," Carnegie Mellon University, Pittsburgh, PA",the falling factorial basis and its statistical applications.
906,906,82.0," Department of Computer Science, National University of Singapore, Republic of Singapore"," Department of Computer Science, National University of Singapore, Republic of Singapore",nonmyopic ε-bayes-optimal active learning of gaussian processes.
907,907,83.0," École Centrale Paris, Center for Visual Computing"," IBM Research, Dublin and Max Planck Institute for Intelligent Systems, Tübingen",a unifying view of representer theorems.
908,908,84.0," DiSTA, University of Insubria, Italy"," Amazon Development Center Germany, Germany",online clustering of bandits.
909,909,85.0," University of Cambridge, Department of Engineering, Cambridge, UK"," University of Cambridge, Department of Engineering, Cambridge, UK",cold-start active learning with robust ordinal matrix factorization.
910,910,86.0," Karlsruhe Institute of Technology, Germany"," Karlsruhe Institute of Technology, Germany",multivariate maximal correlation analysis.
911,911,87.0," NTT Software Innovation Center, Musashino-shi, Tokyo, Japan"," NTT Media Intelligence Laboratories, Yokosuka-shi, Kanagawa, Japan",efficient label propagation.
912,912,88.0, MPI for Intelligent Systems and Georgia Institute of Technology, MPI for Intelligent Systems and Georgia Institute of Technology,"estimating diffusion network structures: recovery conditions, sample complexity & soft-thresholding algorithm."
913,913,89.0," Shanghai Key Laboratory of Scalable Computing and Systems, Department of Computer Science and Engineering, Shanghai Jiao Tong University, China"," National Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, China",coupled group lasso for web-scale ctr prediction in display advertising.
914,914,90.0," Moscow State University, Moscow, Russia"," Moscow State University, Moscow, Russia and Higher School of Economics, Moscow, Russia",putting mrfs on a tensor train.
915,915,91.0," National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China"," Department of Computer Science and Engineering, Michigan State University, East Lansing, MI",efficient algorithms for robust one-bit compressive sensing.
916,916,92.0," Computer Science Department, Stanford University, Stanford, CA"," Adobe Research, San Francisco, CA",learning complex neural network policies with trajectory optimization.
917,917,93.0," University of Science and Technology of China, Hefei, P.R. China"," Microsoft Research, Beijing, P.R. China",composite quantization for approximate nearest neighbor search.
918,918,94.0," Graduate School of Engineering Science, Osaka University, Japan and CiNet, National Institute of Information and Communications Technology, Japan."," Department of Computer Science, University of Hamburg, Germany",local ordinal embedding.
919,919,95.0," Technion, Dept. of Computer Science, Haifa, Israel"," Cornell University, Dept. of Computer Science, Ithaca, NY",reducing dueling bandits to cardinal bandits.
920,920,96.0," Key Lab. of Machine Perception, Peking University, Beijing, China and Centre for Quantum Computation and Intelligent Systems, University of Technology, Sydney, Australia"," Microsoft Research, Haidian District, Beijing, China",large-margin weakly supervised dimensionality reduction.
921,921,97.0, Facebook Inc., Facebook Inc.,joint inference of multiple label types in large networks.
922,922,98.0," Technion, Haifa, Israel"," Yahoo Labs, Haifa, Israel",hard-margin active linear regression.
923,923,99.0," Department of Computer Science, Ben-Gurion University, Beer Sheva, Israel"," Department of Computer Science, Ben-Gurion University, Beer Sheva, Israel",maximum margin multiclass nearest neighbors.
924,924,100.0," Tsinghua University, Beijing, China"," Microsoft Research, Beijing, China",combinatorial partial monitoring game with linear feedback and its applications.
925,925,101.0," University of Basel, Basel, Switzerland"," University of Basel, Basel, Switzerland",sparse meta-gaussian information bottleneck.
926,926,102.0," Carnegie Mellon University, Pittsburgh PA"," Carnegie Mellon University, Pittsburgh PA",nonparametric estimation of rényi divergence and friends.
927,927,103.0," Intel-NTU, National Taiwan University, Taiwan"," Intel-NTU, National Taiwan University, Taiwan",robust inverse covariance estimation under noisy measurements.
928,928,104.0," Washington University in St. Louis, St. Louis, MO"," Columbia University, New York, NY",bayesian optimization with inequality constraints.
929,929,105.0," Columbia University, New York, NY"," Columbia University, New York, NY",circulant binary embedding.
930,930,106.0," Department of Computer Sciences, University of Wisconsin-Madison"," Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison",multiple testing under dependence via semiparametric graphical models.
931,931,107.0," Department of Computer Science & Engineering, Shanghai Jiao Tong University, Shanghai, China"," College of Computer Science & Technology, Zhejiang University, Hangzhou, China",making fisher discriminant analysis scalable.
932,932,108.0," KAIST, Daejeon, Korea"," KAIST, Daejeon, Korea",hierarchical dirichlet scaling process.
933,933,109.0, The University of Tokyo, The University of Tokyo,approximation analysis of stochastic gradient langevin dynamics by using fokker-planck equation and itô process.
934,934,110.0," Institute of Science and Technology Austria, Klosterneuburg, Austria"," Institute of Science and Technology Austria, Klosterneuburg, Austria",a pac-bayesian bound for lifelong learning.
935,935,111.0," Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot, Israel"," Department of Statistics, Rutgers University, Piscataway NJ and Baidu Inc., Beijing, China",communication-efficient distributed optimization using an approximate newton-type method.
936,936,112.0," Technion - Israel Institute of Technology, Haifa, Israel"," Technion - Israel Institute of Technology, Haifa, Israel",concept drift detection through resampling.
937,937,113.0," Computer Science, Purdue University, West Lafayette, IN"," International Computer Science Institute and Dept. of Statistics, University of California at Berkeley, Berkeley, CA","anti-differentiating approximation algorithms: a case study with min-cuts, spectral, and flow."
938,938,114.0," IPG IDSIA, Manno, Switzerland"," CNR IMATI, Milano, Italy",a bayesian wilcoxon signed-rank test based on the dirichlet process.
939,939,115.0," Computing Science Dept., University of Alberta, Edmonton, AB, Canada"," Computing Science Dept., University of Alberta, Edmonton, AB, Canada",min-max problems on factor-graphs.
940,940,116.0," Department of Computer Science, University of California, Irvine"," Machine Learning Group, University of Amsterdam",distributed stochastic gradient mcmc.
941,941,117.0," INRIA, LEAR Project-team, Grenoble, France"," INRIA, LEAR Project-team, Grenoble, France",nearest neighbors using compact sparse codes.
942,942,118.0," Computer Science and Engineering Department, University of Texas at Arlington, Arlington, TX"," Computer Science and Engineering Department, University of Texas at Arlington, Arlington, TX",optimal mean robust principal component analysis.
943,943,119.0," MTA-SZTE Research Group on Artificial Intelligence, Szeged, Hungary"," MTA-SZTE Research Group on Artificial Intelligence, Szeged, Hungary and INRIA Lille - Nord Europe, Villeneuve d’Ascq, France",preference-based rank elicitation using statistical models: the case of mallows.
944,944,120.0," Department of Computer Science, Tufts University, Medford, Massachusetts"," Department of Computer Science, Tufts University, Medford, Massachusetts",hierarchical conditional random fields for outlier detection: an application to detecting epileptogenic cortical malformations.
945,945,121.0," Georgia Institute of Technology, Atlanta, GA"," Massachusetts Institute of Technology, Cambridge, MA",a physics-based model prior for object-oriented mdps.
946,946,122.0," Nagoya Institute of Technology, Nagoya, Aichi, Japan"," Nagoya Institute of Technology, Nagoya, Aichi, Japan",outlier path: a homotopy algorithm for robust svm.
947,947,123.0," Department of Computer Science and Engineering, Hong Kong Univeristy of Science and Technology, Clear Water Bay, Hong Kong"," Department of Computer Science and Engineering, Hong Kong Univeristy of Science and Technology, Clear Water Bay, Hong Kong",ensemble-based tracking: aggregating crowdsourced structured time series data.
948,948,124.0, The University of Tokyo, The University of Tokyo,latent confusion analysis by normalized gamma construction.
949,949,125.0, NICTA and Australian National University, NICTA and Australian National University,"finito: a faster, permutable incremental gradient method for big data problems."
950,950,126.0," Google Research, New York, NY"," Courant Institute and Google Research, New York, NY",ensemble methods for structured prediction.
951,951,127.0," Department of Computing and Information Systems, The University of Melbourne, Victoria, Australia"," Department of Computing and Information Systems, The University of Melbourne, Victoria, Australia",standardized mutual information for clustering comparisons: one step further in adjustment for chance.
952,952,128.0," Department of Computer Science, Brown University, Providence, RI"," Department of Computer Science, Brown University, Providence, RI",preserving modes and messages via diverse particle selection.
953,953,129.0," Department of Electrical & Computer Engineering, Duke University, Durham, NC"," Department of Electrical & Computer Engineering, Duke University, Durham, NC",nonlinear information-theoretic compressive measurement design.
954,954,130.0," University of Dundee, Dundee, Scotland, UK"," University of Pennsylvania, Philadelphia",dual query: practical private query release for high dimensional data.
955,955,131.0," Google Research, New York, NY"," Google Research, New York, NY",deep boosting.
956,956,132.0," Google Inc, Mountain View, CA"," Google Inc, Mountain View, CA",distributed representations of sentences and documents.
957,957,133.0," Department of Chemistry, Stanford University, Stanford, CA"," Department of Chemistry, Stanford University, Stanford, CA",understanding protein dynamics with l1-regularized reversible hidden markov models.
958,958,134.0," University of Pennsylvania, Computer and Information Science Department, Philadelphia, PA"," Washington State University, School of Electrical Engineering and Computer Science, Pullman, WA",online multi-task learning for policy gradient methods.
959,959,135.0," Google Inc, New York, NY"," Google Inc, San Bruno, CA",affinity weighted embedding.
960,960,136.0," Department of Statistics, University of Pennsylvania"," Department of Computer Science & Engineering, University of Washington",learning the parameters of determinantal point process kernels.
961,961,137.0," The Selim and Rachel Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem"," The Selim and Rachel Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem",discrete chebyshev classifiers.
962,962,138.0, Google DeepMind, Google DeepMind,deep autoregressive networks.
963,963,139.0," Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, China"," Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, China","a convergence rate analysis for logitboost, mart and their variant."
964,964,140.0," The Hebrew University of Jerusalem, Jerusalem, Israel"," The Hebrew University of Jerusalem, Jerusalem, Israel",inferning with high girth graphical models.
965,965,141.0," Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI"," Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI",larning latent variable gaussian graphical models.
966,966,142.0," Google DeepMind, London, United Kingdom"," Google DeepMind, London, United Kingdom",stochastic backpropagation and approximate inference in deep generative models.
967,967,143.0," Queensland University of Technology, Brisbane, Australia"," Microsoft Research, New York NY",one practical algorithm for both stochastic and adversarial bandits.
968,968,144.0," Friedrich-Schiller-Universität Jena, Germany"," Friedrich-Schiller-Universität Jena, Germany",robust and efficient kernel hyperparameter paths with guarantees.
969,969,145.0," Computer Science Department, Carnegie Mellon University"," Robotics Institute, Carnegie Mellon University",active transfer learning under model shift.
970,970,146.0," Inria, Villers-lès-Nancy, France and Université de Lorraine, LORIA, Vandoeuvre-lès-Nancy, France"," Inria, Villers-lès-Nancy, France and Université de Lorraine, LORIA, Vandoeuvre-lès-Nancy, France",approximate policy iteration schemes: a comparison.
971,971,147.0," Intel Labs, Santa Clara, CA and School of Engineering and Applied Sciences, Harvard University, Cambridge, MA"," School of Engineering and Applied Sciences, Harvard University, Cambridge, MA",stable and efficient representation learning with nonnegativity constraints.
972,972,148.0," Massachusetts Institute of Technology, Cambridge, MA"," Massachusetts Institute of Technology, Cambridge, MA",sample efficient reinforcement learning with gaussian processes.
973,973,149.0," Department of Electrical, Computer and Energy Engineering, University of Colorado at Boulder, CO"," Department of Electrical, Computer and Energy Engineering, University of Colorado at Boulder, CO",memory and computation efficient pca via very sparse random projections.
974,974,150.0," Electrical Engineering Department, The Technion - Israel Institute of Technology, Haifa, Israel"," Electrical Engineering Department, The Technion - Israel Institute of Technology, Haifa, Israel",time-regularized interrupting options.
975,975,151.0," Max-Planck-Institute for Intelligent Systems, University of Cambridge", Max-Planck-Institute for Intelligent Systems,randomized nonlinear component analysis.
976,976,152.0," Department of Computer Science, University of Toronto, Toronto, ON, Canada"," Department of Computer Science, University of Toronto, Toronto, ON, Canada and Canadian Institute for Advanced Research, Toronto, ON, Canada",high order regularization for semi-supervised learning of structured output problems.
977,977,153.0," Tokyo Institute of Technology, Tokyo, Japan and Baidu Inc., Beijing, China"," Tokyo Institute of Technology, Tokyo, Japan",transductive learning with multi-class volume approximation.
978,978,154.0," Reasoning and Learning Laboratory, School of Computer Science, McGill University, Montreal, QC, Canada"," Reasoning and Learning Laboratory, School of Computer Science, McGill University, Montreal, QC, Canada",methods of moments for learning stochastic languages: unified presentation and empirical comparison.
979,979,155.0," ApSTAT Technologies Inc., Montral, QC, Canada"," ApSTAT Technologies Inc., Montral, QC, Canada",effective bayesian modeling of groups of related count time series.
980,980,156.0," Dorodnicyn Computing Centre of the Russian Academy of Sciences, Moscow, Russia"," Moscow State University, Moscow, Russia and Higher School of Economics, Moscow, Russia",variational inference for sequential distance dependent chinese restaurant process.
981,981,157.0," Harvard University, Cambridge, MA"," Harvard University, Cambridge, MA",discovering latent network structure in point process data.
982,982,158.0," University College London, Computer Science Department"," University College London, Gatsby Computational Neuroscience",a kernel independence test for random processes.
983,983,159.0," Dept. of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI"," Dept. of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI",learning to disentangle factors of variation with manifold interaction.
984,984,160.0," Bioinformatics Program, Boston University, Boston, MA"," Departments of Biomedical Engineering and Microbiology, Boston University, Boston, MA",learning modular structures from network data and node variables.
985,985,161.0," Graduate School of Information Science and Technology, The University of Tokyo, Hongo, Tokyo, Japan"," Graduate School of Information Science and Technology, The University of Tokyo, Hongo, Tokyo, Japan",probabilistic partial canonical correlation analysis.
986,986,162.0, Google DeepMind, Franklin and Marshall College,skip context tree switching.
987,987,163.0," Department of Computer Science and Engineering, UCSD, La Jolla, CA"," Department of Computer Science and Engineering, UCSD, La Jolla, CA",lower bounds for the gibbs sampler over mixtures of gaussians.
988,988,164.0, Criteo," Université de Montréal, Canadian Institute for Advanced Research",marginalized denoising auto-encoders for nonlinear representations.
989,989,165.0," Department of Computer Science, Laval University, Canada"," Department of Computer Science, University College London, UK",gaussian processes for bayesian estimation in ordinary differential equations.
990,990,166.0," University of Washington, Seattle, WA"," University of Washington, Seattle, WA",fast multi-stage submodular maximization.
991,991,167.0," TAO, INRIA, CNRS, LRI, Université Paris-Sud, France"," TAO, INRIA, CNRS, LRI, Université Paris-Sud, France",programming by feedback.
992,992,168.0," University of Cambridge, Department of Engineering, Cambridge, UK"," University of Cambridge, Department of Engineering, Cambridge, UK",probabilistic matrix factorization with non-random missing data.
993,993,169.0," Computer and Information Science, University of Pennsylvania"," Computer and Information Science, University of Pennsylvania","pursuit-evasion without regret, with an application to trading."
994,994,170.0," Department of Computer Science, University of Hamburg, Germany"," Department of Mathematics, University of Potsdam, Germany",the f-adjusted graph laplacian: a diagonal modification with a geometric interpretation.
995,995,171.0," School of Computer Science, The University of Adelaide, Australia"," Institute for Infocomm Research, Singapore",riemannian pursuit for big matrix recovery.
996,996,172.0," Idiap Research Institute, Martigny, Switzerland and École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland"," Idiap Research Institute, Martigny, Switzerland and École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland",dynamic programming boosting for discriminative macro-action discovery.
997,997,173.0," Rehabilitation Institute of Chicago, Northwestern University"," School of Computer Science, CMU",online stochastic optimization under correlated bandit feedback.
998,998,174.0," University of California, Berkeley, Berkeley, CA"," National University of Singapore, Singapore",weighted graph clustering with non-uniform uncertainties.
999,999,175.0," School of Computer Science, University of Massachusetts, Amherst, MA"," School of Computer Science, University of Massachusetts, Amherst, MA",genga: a generalization of natural gradient ascent with positive and.
1000,1000,176.0," Department of Computer Science, Boston University, Boston, MA"," Department of Computer Science, Boston University, Boston, MA",a bayesian framework for online classifier ensemble.
1001,1001,177.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",adaptivity and optimism: an improved exponentiated gradient algorithm.
1002,1002,178.0," School of EECS, Oregon State University, Corvallis, OR"," School of EECS, Oregon State University, Corvallis, OR",gaussian approximation of collective graphical models.
1003,1003,179.0,,,on learning to localize objects with minimal supervision.
1004,1004,180.0," Department of Computer Science, The University of Chicago and Department of Statistics", Toyota Technological Institute at Chicago,multiresolution matrix factorization.
1005,1005,181.0," School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon"," School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon",learnability of the superset label learning problem.
1006,1006,182.0," Microsoft Research, New York, NY"," Princeton University, Princeton, NJ",taming the monster: a fast and simple algorithm for contextual bandits.
1007,1007,183.0," Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI"," Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI",structured recurrent temporal restricted boltzmann machines.
1008,1008,184.0," Departments of Mathematics, Duke University, Durham, NC"," Departments of Statistical Science, Duke University, Durham, NC",scalable and robust bayesian inference via the median posterior.
1009,1009,185.0," Gatsby Unit, CSML, University College London, UK"," Gatsby Unit, CSML, University College London, UK",kernel adaptive metropolis-hastings.
1010,1010,186.0," School of Engineering and Applied Sciences, Harvard University"," School of Engineering and Applied Sciences, Harvard University",input warping for bayesian optimization of non-stationary functions.
1011,1011,187.0," MODE Lab, University of Washington, Seattle, WA"," MODE Lab, University of Washington, Seattle, WA",stochastic gradient hamiltonian monte carlo.
1012,1012,188.0," Department of Computing, Imperial College London, United Kingdom"," Department of Computing, Imperial College London, United Kingdom",a deep semi-nmf model for learning hidden representations.
1013,1013,189.0," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong"," Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong",asynchronous distributed admm for consensus optimization.
1014,1014,190.0," Universitat Politècnica de Catalunya, Barcelona, Catalunya"," The Hebrew University of Jerusalem, Jerusalem, Israel",spectral regularization for max-margin sequence tagging.
1015,1015,191.0," Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India"," Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India",learning by stretching deep networks.
1016,1016,192.0," Department of Electrical and Computer Engineering, The University of Texas at Austin, TX"," Department of Electrical and Computer Engineering, The University of Texas at Austin, TX",nonnegative sparse pca with provable guarantees.
1017,1017,193.0," School of Computer Science, University of Massachusetts Amherst, MA"," School of Computer Science, University of Massachusetts Amherst, MA",active learning of parameterized skills.
1018,1018,194.0," Department of Mathematics, MIT, School of Engineering and Applied Sciences, Harvard University"," School of Engineering and Applied Sciences, Harvard University",learning ordered representations with nested dropout.
1019,1019,195.0," Machine Learning Group, University of Amsterdam"," Machine Learning Group, University of Amsterdam",learning the irreducible representations of commutative lie groups.
1020,1020,196.0," Google DeepMind, London, United Kingdom"," Department of Computer Science, University of Toronto, Canada",towards end-to-end speech recognition with recurrent neural networks.
1021,1021,197.0," School of Informatics, The University of Edinburgh, Edinburgh"," School of Informatics, The University of Edinburgh, Edinburgh",multi-period trading prediction markets with connections to machine learning.
1022,1022,198.0," Machine Learning Group, University of Amsterdam"," Machine Learning Group, University of Amsterdam",efficient gradient-based inference through transformations between bayes nets and neural nets.
1023,1023,199.0, Google DeepMind, Google DeepMind,neural variational inference and learning in belief networks.
1024,1024,200.0," Department of Electrical and Computer Engineering, Duke University, Durham, NC"," Department of Electrical and Computer Engineering, Duke University, Durham, NC",scalable bayesian low-rank decomposition of incomplete multiway tensors.
1025,1025,201.0," University of Cambridge, Department of Engineering, Cambridge, UK"," University of Cambridge, Department of Engineering, Cambridge, UK",beta diffusion trees.
1026,1026,202.0," IBM Research-Brazil, Rio de Janeiro, Brazil"," IBM Research-Brazil, Rio de Janeiro, Brazil",learning character-level representations for part-of-speech tagging.
1027,1027,203.0," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA"," School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",saddle points and accelerated perceptron algorithms.
1028,1028,204.0," Colorado School of Mines, Department of Electrical Engineering and Computer Science, Golden, Colorado"," Computer Science and Engineering Department, University of Texas at Arlington, Arlington, TX",robust distance metric learning via simultaneous l1-norm minimization and maximization.
1029,1029,205.0," Computer and Information Science, University of Pennsylvania"," Computer and Information Science, University of Pennsylvania",learning from contagion (without timestamps).
1030,1030,206.0," Massachusetts Institute of Technology, Cambridge, MA"," Massachusetts Institute of Technology, Cambridge, MA",stochastic variational inference for bayesian time series models.
1031,1031,207.0," IDSIA, USI&SUPSI, Lugano, Switzerland"," IDSIA, USI&SUPSI, Lugano, Switzerland",a clockwork rnn.
1032,1032,208.0," Stanford University, Stanford, CA"," Stanford University, Stanford, CA",estimating latent-variable graphical models using moments and likelihoods.
1033,1033,209.0, The University of Texas at Austin," Microsoft Research, India",universal matrix completion.
1034,1034,210.0, The University of Texas at Austin, The University of Texas at Austin,finding dense subgraphs via low-rank bilinear optimization.
1035,1035,211.0," Department of Computer Science, University of Oxford, Oxford, UK"," Department of Computer Science, University of Oxford, Oxford, UK",compositional morphology for word representations and language modelling.
1036,1036,212.0, Microsoft Research, Microsoft Research,learning polynomials with neural networks.
1037,1037,213.0," The University of Texas at Austin, Texas"," The University of Texas at Austin, Texas",exponential family matrix completion under structural constraints.
1038,1038,214.0," School of Computer Science, McGill University, Montreal, Canada"," School of Computer Science, McGill University, Montreal, Canada",sample-based approximate regularization.
1039,1039,,first-author-affiliation,last-author-affiliation,title.
1040,1040,0.0,DeepMind,DeepMind,decoupled neural interfaces using synthetic gradients.
1041,1041,1.0,IST Austria,IST Austria,pixelcnn models with auxiliary variables for natural image modeling.
1042,1042,2.0,Google Research,UC Berkeley,tight bounds for approximate carathéodory and beyond.
1043,1043,3.0,Carnegie Mellon University,Carnegie Mellon University,robust adversarial reinforcement learning.
1044,1044,4.0,Columbia University,Columbia University,robust probabilistic modeling with bayesian data reweighting.
1045,1045,5.0,Yahoo! Research,Technion,multi-objective bandits: optimizing the generalized gini index.
1046,1046,6.0,TTIC,Toyota Technological Institute at Chicago,communication-efficient algorithms for distributed stochastic principal component analysis.
1047,1047,7.0,Università di Pisa,Università di Pisa,enumerating distinct decision trees.
1048,1048,8.0,DeepMind,DeepMind,understanding synthetic gradients and decoupled neural interfaces.
1049,1049,9.0,Google Deepmind,DeepMind,parallel multiscale autoregressive density estimation.
1050,1050,10.0,Weizmann Institute of Science,Weizmann Institute of Science,oracle complexity of second-order methods for finite-sum problems.
1051,1051,11.0,Deepmind,DeepMind,minimax regret bounds for reinforcement learning.
1052,1052,12.0,CMU,Carnegie Mellon University,post-inference prior swapping.
1053,1053,13.0,Weizmann Institute of Science,Weizmann Institute of Science,online learning with local permutations and delayed feedback.
1054,1054,14.0,RIKEN AIP / ATR,ATR / RIKEN,splice: fully tractable hierarchical extension of ica with pooling.
1055,1055,15.0,New York University,Massachusetts Institute of Technology,simultaneous learning of trees and representations for extreme classification and density estimation.
1056,1056,16.0,Peking University,,meprop: sparsified back propagation for accelerated deep learning with reduced overfitting.
1057,1057,17.0,DeepMind,DeepMind,video pixel networks.
1058,1058,18.0,ENS Paris-Saclay,ENS Cachan,global optimization of lipschitz functions.
1059,1059,19.0,University of Pennsylvania,University of Pennsylvania,fairness in reinforcement learning.
1060,1060,20.0,Columbia University,Columbia University,evaluating bayesian models with posterior dispersion indices.
1061,1061,21.0,University of British Columbia,University of British Columbia,model-independent online learning for influence maximization.
1062,1062,22.0,Carnegie Mellon University,Carnegie Mellon University,latent feature lasso.
1063,1063,23.0,Microsoft Research,Microsoft Research,resource-efficient machine learning in 2 kb ram for the internet of things.
1064,1064,24.0,Stanford University,Stanford University,learning important features through propagating activation differences.
1065,1065,25.0,MPI Tübingen,MPI Tübingen,adversarial variational bayes: unifying variational autoencoders and generative adversarial networks.
1066,1066,26.0,Princeton University,Stanford University,strong np-hardness for sparse optimization with concave penalty functions.
1067,1067,27.0,Politecnico di Milano,Politecnico di Milano,boosted fitted q-iteration.
1068,1068,28.0,University of Cambridge,University of Cambridge & Uber,automatic discovery of the statistical types of variables in a dataset.
1069,1069,29.0,Independent Researcher,Adobe Research,online learning to rank in stochastic click models.
1070,1070,30.0,Georgia Institute of Technology,Georgia Institute of Technology,online partial least square optimization: dropping convexity for better efficiency and scalability.
1071,1071,31.0,Nanjing University,Nanjing University,multi-class optimal margin distribution machine.
1072,1072,32.0,Preferred Networks / The University of Tokyo,University of Tokyo / RIKEN,evaluating the variance of likelihood-ratio gradient estimators.
1073,1073,33.0,Zalando Research,Zalando Research,learning texture manifolds with the periodic spatial gan.
1074,1074,34.0,The University of Iowa,The University of Iowa,stochastic convex optimization: faster local growth implies faster global convergence.
1075,1075,35.0,Deepmind,Stanford University,why is posterior sampling better than optimism for reinforcement learning?.
1076,1076,36.0,University of Almeria,Hugin Expert A/S,bayesian models of data streams with hierarchical power priors.
1077,1077,37.0,UC Berkeley,UC Berkeley,the sample complexity of online one-class collaborative filtering.
1078,1078,38.0,University of Illinios at Chicago/Shenzhen University,Northwestern University,kernelized support tensor machines.
1079,1079,39.0,Carnegie Mellon University,CMU,equivariance through parameter-sharing.
1080,1080,40.0,Princeton University,Princeton University,generalization and equilibrium in generative adversarial nets (gans).
1081,1081,41.0,"School of Mathematics, South China University of Technology",The Chinese University of Hong Kong,gsos: gauss-seidel operator splitting algorithm for multi-term nonsmooth convex composite optimization.
1082,1082,42.0,UC Berkeley,OpenAI / UC Berkeley,constrained policy optimization.
1083,1083,43.0,Carnegie Mellon University,Carnegie Mellon University,ordinal graphical models: a tale of two approaches.
1084,1084,44.0,Princeton University,Princeton University,efficient regret minimization in non-convex games.
1085,1085,45.0,The University of Haifa,MIT CSAIL,coresets for vector summarization with applications to network graphs.
1086,1086,46.0,University of Texas at Austin,UT Austin & Amazon,recovery guarantees for one-hidden-layer neural networks.
1087,1087,47.0,University of Science and Technology of China,Microsoft,dual supervised learning.
1088,1088,48.0,University of Oxford,University of Oxford,warped convolutions: efficient invariance to spatial transformations.
1089,1089,49.0,IBM T.J Watson Research Center,IBM,mcgan: mean and covariance feature matching gan.
1090,1090,50.0,UC Berkeley,Berkeley,breaking locality accelerates block gauss-seidel.
1091,1091,51.0,UC Berkeley,Berkeley,reinforcement learning with deep energy-based policies.
1092,1092,52.0,Massachusetts Institute of Technology,Harvard University,scalable bayesian rule lists.
1093,1093,53.0,Tsinghua University,Tsinghua University,identify the nash equilibrium in static games with random payoffs.
1094,1094,54.0,Duke University,Duke University,partitioned tensor factorizations for learning mixed membership models.
1095,1095,55.0,"Hebrew University, Jerusalem",Weizmann Institute of Science,failures of gradient-based deep learning.
1096,1096,56.0,Princeton,Tel Aviv University,learning infinite layer networks without the kernel trick.
1097,1097,57.0,Ecole Polytechnique Federale de Lausanne (EPFL),EPFL,graph-based isometry invariant representation learning.
1098,1098,58.0,Google Brain,Google Brain,conditional image synthesis with auxiliary classifier gans.
1099,1099,59.0,"Theoretical and Applied Computer Science Laboratory, University of Lorraine",University of Lorraine,stochastic dca for the large-sum of non-convex functions problem and its application to group variable selection in classification.
1100,1100,60.0,UC Berkeley,OpenAI,prediction and control with temporal segment models.
1101,1101,61.0,Massachusetts Institute of Technology,Massachusetts Institute of Technology,learning determinantal point processes with moments and cycles.
1102,1102,62.0,Microsoft Research / Princeton / IAS,Princeton University,follow the compressed leader: faster online learning of eigenvectors and faster mmwu.
1103,1103,63.0,University of Texas at Austin,"University of Texas, Austin",on mixed memberships and symmetric nonnegative matrix factorizations.
1104,1104,64.0,University of Illinois at Urbana-Champaign,University of Illinois,analytical guarantees on numerical precision of deep neural networks.
1105,1105,65.0,Tel Aviv University,EPFL,random fourier features for kernel ridge regression: approximation bounds and statistical guarantees.
1106,1106,66.0,MIT CSAIL,MIT,deriving neural architectures from sequence and graph kernels.
1107,1107,67.0,SK T-Brain,SK T-Brain,learning to discover cross-domain relations with generative adversarial networks.
1108,1108,68.0,the University of Edinburgh,University of Edinburgh,gradient projection iterative sketch for large-scale constrained least-squares.
1109,1109,69.0,Brown University,Brown University,an alternative softmax operator for reinforcement learning.
1110,1110,70.0,University of Cambridge,University of Cambridge & Uber,deep bayesian active learning with image data.
1111,1111,71.0,Indian Institute of Science,Indian Institute of Science,on kernelized multi-armed bandits.
1112,1112,72.0,EDF R&D & Université Paris-Sud,EDF Lab Paris-Saclay,nonnegative matrix factorization for time series recovery from a few temporal aggregates.
1113,1113,73.0,Hong Kong University of Science and Technology,Hong Kong University of Science and Technology,follow the moving leader in deep learning.
1114,1114,74.0,University of Maryland,Microsoft,logarithmic time one-against-some.
1115,1115,75.0,Facebook,Facebook,unsupervised learning by predicting noise.
1116,1116,76.0,New York University,Facebook,wasserstein generative adversarial networks.
1117,1117,77.0,,Boston University,connected subgraph detection with mirror descent on sdps.
1118,1118,78.0,Georgia Tech,Georgia Institute of Technology,fake news mitigation via point process based intervention.
1119,1119,79.0,University of Oxford,University of Birmingham,bayesian boolean matrix factorisation.
1120,1120,80.0,INRIA Lille,Inria Lille - Nord Europe,second-order kernel online convex optimization with adaptive sketching.
1121,1121,81.0,Leuphana University Lüneburg,Leuphana University,frame-based data factorizations.
1122,1122,82.0,The City University of New York,"City College of New York, CUNY",theoretical properties for neural networks with weight matrices of low displacement rank.
1123,1123,83.0,Stanford University,Stanford University,understanding black-box predictions via influence functions.
1124,1124,84.0,Tsinghua University,UC Berkeley,deep transfer learning with joint adaptation networks.
1125,1125,85.0,Stanford University,Stanford University,learning hierarchical features from deep generative models.
1126,1126,86.0,Iowa State University,Zhejiang University,prox-pda: the proximal primal-dual algorithm for fast distributed nonconvex optimization and learning over networks.
1127,1127,87.0,UC Berkeley,University of California at Berkeley,curiosity-driven exploration by self-supervised prediction.
1128,1128,88.0,Stanford University,Stanford,learning the structure of generative models without labeled data.
1129,1129,89.0,Cornell University,Cornell University,dueling bandits with weak regret.
1130,1130,90.0,Microsoft Research,Microsoft Research,nearly optimal robust matrix completion.
1131,1131,91.0,Tel Aviv University,Tel Aviv University,globally optimal gradient descent for a convnet with gaussian inputs.
1132,1132,92.0,HKU,University of Hong Kong,re-revisiting learning on hypergraphs: confidence interval and subgradient method.
1133,1133,93.0,University of Massachusetts,University of Massachusetts,meta networks.
1134,1134,94.0,Stanford University,Adobe Research & INRIA,bottleneck conditional density estimation.
1135,1135,95.0,University of Chicago,Microsoft Research,exploiting strong convexity from data with primal-dual first-order algorithms.
1136,1136,96.0,Cogitai,Brown University,interactive learning from policy-dependent human feedback.
1137,1137,97.0,CentraleSupelec,KU Leuven,learning to discover sparse graphical models.
1138,1138,98.0,Universita dell'Insubria,University of Insubria,on context-dependent clustering of bandits.
1139,1139,99.0,Princeton University,Princeton University,provable alternating gradient descent for non-negative matrix factorization with strong correlations.
1140,1140,100.0,Stanford,University of California at Berkeley,convexified convolutional neural networks.
1141,1141,101.0,Xian Jiaotong University,University of Technology Sydney,self-paced co-training.
1142,1142,102.0,Seoul National University,UNIST / AItrics,splitnet: learning to semantically split deep networks for parameter reduction and model parallelization.
1143,1143,103.0,Google Research,Google Research,learning deep latent gaussian models with markov chain monte carlo.
1144,1144,104.0,University of Texas at Austin,Carnegie Mellon University,doubly greedy primal-dual coordinate descent for sparse empirical risk minimization.
1145,1145,105.0,Technion - Israel Institute of Technology,Technion,end-to-end differentiable adversarial imitation learning.
1146,1146,106.0,IBM Research,IBM,local-to-global bayesian network structure learning.
1147,1147,107.0,Microsoft Research,Microsoft Research,provably optimal algorithms for generalized linear contextual bandits.
1148,1148,108.0,Duke University,Duke University,no spurious local minima in nonconvex low rank problems: a unified geometric analysis.
1149,1149,109.0,Google Brain / Cornell University,Google Brain,on the expressive power of deep neural networks.
1150,1150,110.0,The University of Tokyo / RIKEN,RIKEN / The University of Tokyo,semi-supervised classification based on classification from positive and unlabeled data.
1151,1151,111.0,UC Berkeley,Berkeley,model-agnostic meta-learning for fast adaptation of deep networks.
1152,1152,112.0,Columbia University,Columbia University,zero-inflated exponential family embeddings.
1153,1153,113.0,The University of Iowa,Nanjing University,a richer theory of convex constrained optimization with reduced projections and improved rates.
1154,1154,114.0,Northeastern University,Northeastern University,learning in pomdps with monte carlo tree search.
1155,1155,115.0,"THE GRADUATE CENTER, CUNY",City University of New York (CUNY),composing tree graphical models with persistent homology features for clustering mixed-type data.
1156,1156,116.0,Carnegie Mellon University,Microsoft Research,safety-aware algorithms for adversarial contextual bandit.
1157,1157,117.0,University of Central Florida,University of Central Florida,"coherence pursuit: fast, simple, and robust subspace recovery."
1158,1158,118.0,Weizmann Institute of Science,Weizmann Institute of Science,depth-width tradeoffs in approximating natural functions with neural networks.
1159,1159,119.0,Georgia Tech,Georgia Institute of Technology,iterative machine teaching.
1160,1160,120.0,Google Research,Courant Institute,adanet: adaptive structural learning of artificial neural networks.
1161,1161,121.0,University of Maryland,Cornell University,convex phase retrieval without lifting via phasemax.
1162,1162,122.0,DeepMind,DeepMind,darla: improving zero-shot transfer in reinforcement learning.
1163,1163,123.0,UCLA,UCLA,on relaxing determinism in arithmetic circuits.
1164,1164,124.0,Indiana University Bloomington,Indiana University Bloomington,adaptive multiple-arm identification.
1165,1165,125.0,Institute of Statistical Mathematics,AIST / RIKEN,tensor decomposition with smoothness.
1166,1166,126.0,DeepMind,DeepMind,automated curriculum learning for neural networks.
1167,1167,127.0,R. V. College of Engineering & Indian Institute of Science,Indian Institute of Science,attentive recurrent comparators.
1168,1168,128.0,Oberlin College,University of Arizona,an infinite hidden markov model with similarity-biased transitions.
1169,1169,129.0,Washington University in St. Louis,Washington University in St. Louis,efficient nonmyopic active search.
1170,1170,130.0,The University of Tokyo,The Univ. of Tokyo / RIKEN,asymmetric tri-training for unsupervised domain adaptation.
1171,1171,131.0,University of Central Florida,University of Central Florida,state-frequency memory recurrent neural networks.
1172,1172,132.0,MIT,Microsoft Research,batched high-dimensional bayesian optimization via structural kernel learning.
1173,1173,133.0,University of Michigan,University of Michigan,leveraging union of subspace structure to improve constrained clustering.
1174,1174,134.0,"Nanyang Technological University, Singapore",,source-target similarity modelings for multi-source transfer gaussian process regression.
1175,1175,135.0,Institute of Neuroinformatics,Institute of Neuroinformatics,delta networks for optimized recurrent network computation.
1176,1176,136.0,Brown University,"University of California, Irvine",from patches to images: a nonparametric generative model.
1177,1177,137.0,University of California at San Diego,Microsoft Research,active heteroscedastic regression.
1178,1178,138.0,IST Austria,IST Austria,multi-task learning with labeled and unlabeled tasks.
1179,1179,139.0,ETH Zurich,Swiss AI Lab,recurrent highway networks.
1180,1180,140.0,CSIRO Data61,Data61/ANU/UTS,fast bayesian intensity estimation for the permanental process.
1181,1181,141.0,UMass,Microsoft Research,active learning for cost-sensitive classification.
1182,1182,142.0,Vicarious AI,Vicarious AI,schema networks: zero-shot transfer with a generative causal model of intuitive physics.
1183,1183,143.0,Oxford,University of Cambridge & Uber,a birth-death process for feature allocation.
1184,1184,144.0,"University of California, San Diego",UCSD,diameter-based active learning.
1185,1185,145.0,Australian National University and Data61,Carnegie Mellon University,risk bounds for transferring representations with and without fine-tuning.
1186,1186,146.0,Saarland University,Saarland University,the loss surface of deep and wide neural networks.
1187,1187,147.0,Victoria University Wellington,Victoria University of Wellington,neural taylor approximations: convergence and exploration in rectifier networks.
1188,1188,148.0,University of Montreal,U. Montreal,sharp minima can generalize for deep nets.
1189,1189,149.0,Google Brain,Google Brain,geometry of neural network loss surfaces via random matrix theory.
1190,1190,150.0,Victoria University Wellington,Frostbite Labs and Victoria University,"the shattered gradients problem: if resnets are the answer, then what is the question?."
1191,1191,151.0,DeepMind,DeepMind,learning to learn without gradient descent by gradient descent.
1192,1192,152.0,Carnegie Mellon University,Carnegie Mellon University,"a semismooth newton method for fast, generic convex programming."
1193,1193,153.0,University of Alberta/Indiana University,University of Alberta/Indiana University,unifying task specification in reinforcement learning.
1194,1194,154.0,Yahoo Research,UCSD,efficient online bandit multiclass learning with o(sqrt{t}) regret.
1195,1195,155.0,Stanford University,Stanford University,orthogonalized als: a theoretically principled tensor decomposition algorithm for practical use.
1196,1196,156.0,Google Brain,Google Brain,learned optimizers that scale and generalize.
1197,1197,157.0,Shanghai Jiao Tong University,Peking University,approximate newton methods and their local convergence.
1198,1198,158.0,DeepMind,DeepMind,a distributional perspective on reinforcement learning.
1199,1199,159.0,Stanford University,FACEBOOK,active learning for accurate estimation of linear models.
1200,1200,160.0,Academia sinica,Academia Sinica,tensor decomposition via simultaneous power iteration.
1201,1201,161.0,Tsinghua University,IIIS,learning gradient descent: better generalization and longer horizons.
1202,1202,162.0,Columbia University,Columbia University,stochastic adaptive quasi-newton methods for minimizing expected values.
1203,1203,163.0,Harvard University,Council for Scientific and Industrial Research (CSIR),hierarchy through composition with multitask lmdps.
1204,1204,164.0,Google Research,Yahoo,adaptive feature selection: computationally efficient online sparse linear regression under rip.
1205,1205,165.0,University of Virginia,University of Virginia,a unified variance reduction-based framework for nonconvex low-rank matrix recovery.
1206,1206,166.0,Maluuba,Maluuba,learning algorithms for active learning.
1207,1207,167.0,University College London,University College London,practical gauss-newton optimisation for deep learning.
1208,1208,168.0,University of Alberta,University of Alberta,a laplacian framework for option discovery in reinforcement learning.
1209,1209,169.0,Georgia Tech,,emulating the expert: inverse optimization through online learning.
1210,1210,170.0,UC Berkeley,University of California at Berkeley,"an efficient, sparsity-preserving, online algorithm for low-rank approximation."
1211,1211,171.0,National Institute of Informatics,University of Tokyo / RIKEN,tensor balancing on statistical manifold.
1212,1212,172.0,UC Berkeley,Berkeley,modular multitask reinforcement learning with policy sketches.
1213,1213,173.0,Saarland University,Saarland University,variants of rmsprop and adagrad with logarithmic regret bounds.
1214,1214,174.0,Sapienza University of Rome,,algorithms for $\ell_p$ low-rank approximation.
1215,1215,175.0,KAUST,École Polytechnique,relative fisher information and natural gradient for learning large modular models.
1216,1216,176.0,The University of Melbourne,CSIRO,efficient orthogonal parametrisation of recurrent neural networks using householder reflections.
1217,1217,177.0,Georgia Institute of Technology,,lazifying conditional gradient algorithms.
1218,1218,178.0,University of Texas at Austin,University of Texas at Austin,data-efficient policy evaluation through behavior policy search.
1219,1219,179.0,University of Texas at Austin,University of Texas at Austin,exact map inference by avoiding fractional vertices.
1220,1220,180.0,"FIT, Monash University",Monash University,leveraging node attributes for incomplete relational data.
1221,1221,181.0,EPFL,EPFL,how close are the eigenvectors of the sample and actual covariance matrices?.
1222,1222,182.0,ETH Zurich,ETH Zurich,distributed and provably good seedings for k-means in constant rounds.
1223,1223,183.0,The Chinese University of Hong Kong,The Chinese University of Hong Kong,learning deep architectures via generalized whitened neural networks.
1224,1224,184.0,MILA,Ecole Polytechnique de Montreal,on orthogonality and learning rnns with long term dependencies.
1225,1225,185.0,George,,conditional accelerated lazy stochastic gradient descent.
1226,1226,186.0,Carnegie Mellon University,Microsoft Research,stochastic variance reduction methods for policy evaluation.
1227,1227,187.0,"University of Massachusetts, Amherst",University of Massachusetts Amherst,exact inference for integer latent-variable models.
1228,1228,188.0,POSTECH,POSTECH,bayesian inference on random simple graphs with power law degree distributions.
1229,1229,189.0,Microsoft Research / Princeton / IAS,Princeton University,faster principal component regression and stable matrix chebyshev approximation.
1230,1230,190.0,Google,Google,consistent k-clustering.
1231,1231,191.0,Stanford,Stanford,continual learning through synaptic intelligence.
1232,1232,192.0,Massachusetts Institute of Technology,MIT,tunable efficient unitary neural networks (eunn) and their application to rnns.
1233,1233,193.0,Lehigh University,Lehigh University,sarah: a novel method for machine learning problems using stochastic recursive gradient.
1234,1234,194.0,Carnegie Mellon University / Amazon AWS,Microsoft Research,optimal and adaptive off-policy evaluation in contextual bandits.
1235,1235,195.0,MIT,MIT,improving viterbi is hard: better runtimes imply faster clique algorithms.
1236,1236,196.0,CMU/Google DeepMind,Carnegie Mellon University,analogical inference for multi-relational embeddings.
1237,1237,197.0,Amazon Research Cambridge,,spectral learning from a single trajectory under finite-state policies.
1238,1238,198.0,University of Minnesota,Iowa State University,towards k-means-friendly spaces: simultaneous deep learning and clustering.
1239,1239,199.0,Boston University,Boston University,adaptive neural networks for efficient inference.
1240,1240,200.0,Carnegie Mellon University,CMU/Uber,the statistical recurrent unit.
1241,1241,201.0,EPFL,EPFL,approximate steepest coordinate descent.
1242,1242,202.0,Technion,Technion,consistent on-line off-policy evaluation.
1243,1243,203.0,Harvard University,Harvard Medical School,variational inference for sparse and undirected models.
1244,1244,204.0,Georgia Institute of Technology,Georgia Institute of Technology,know-evolve: deep temporal reasoning for dynamic knowledge graphs.
1245,1245,205.0,UC Berkeley,UC Berkeley,capacity releasing diffusion for speed and locality..
1246,1246,206.0,Johns Hopkins University,Johns Hopkins University,hyperplane clustering via dual principal component pursuit.
1247,1247,207.0,UNIST,UNIST / AItrics,combined group and exclusive sparsity for deep neural networks.
1248,1248,208.0,University of Oxford,"Google Brain, Google Inc.",input switched affine networks: an rnn architecture designed for interpretability.
1249,1249,209.0,University of Washington,,stingycd: safely avoiding wasteful updates in coordinate descent.
1250,1250,210.0,Microsoft Research,Microsoft Research,contextual decision processes with low bellman rank are pac-learnable.
1251,1251,211.0,Australian National University,Queensland University of Technology,tensor belief propagation.
1252,1252,212.0,Duke University,Duke,deep generative models for relational data with side information.
1253,1253,213.0,Microsoft Research / Princeton / IAS,Princeton University,doubly accelerated methods for faster cca and generalized eigendecomposition.
1254,1254,214.0,University of Michigan,Deakin University,multilevel clustering via wasserstein means.
1255,1255,215.0,Google Brain,Google Brain,online and linear-time attention by enforcing monotonic alignments.
1256,1256,216.0,"Institute of High Performance Computing, A*STAR",Princeton University,stochastic modified equations and adaptive stochastic gradient algorithms.
1257,1257,217.0,caltech.edu,caltech.edu,a simple multi-class boosting framework with theoretical guarantees and empirical proficiency.
1258,1258,218.0,Korea Advanced Institute of Science and Technology,KAIST,faster greedy map inference for determinantal point processes.
1259,1259,219.0,EPFL,EPFL,choicerank: identifying preferences from node traffic in networks.
1260,1260,220.0,Rutgers University,Rugters University,on the iteration complexity of support recovery via hard thresholding pursuit.
1261,1261,221.0,ETH Zurich,ETH Zurich,uniform deviation bounds for k-means clustering.
1262,1262,222.0,Massachusetts Institute of Technology,Google Brain,sequence tutor: conservative fine-tuning of sequence generation models with kl-control.
1263,1263,223.0,University of Wisconsin,University of Wisconsin-Madison,dissipativity theory for nesterov's accelerated method.
1264,1264,224.0,Google Research,"University of California, Davis",gradient boosted decision trees for high dimensional sparse output.
1265,1265,225.0,INRIA Lille,Inria Lille - Nord Europe,zonotope hit-and-run for efficient sampling from projection dpps.
1266,1266,226.0,Paderborn University,University of Oviedo,statistical inference for incomplete ranking data: the case of rank-dependent coarsening.
1267,1267,227.0,Rutgers,Rutgers,dual iterative hard thresholding: from non-convex sparse minimization to non-smooth concave maximization.
1268,1268,228.0,Google,Google,uniform convergence rates for kernel density estimation.
1269,1269,229.0,Baidu Research Silicon Valley AI Lab,Baidu,deep voice: real-time neural text-to-speech.
1270,1270,230.0,Facebook AI Research,Facebook AI Research,an analytical formula of population gradient for two-layered relu network and its applications in convergence and critical point analysis.
1271,1271,231.0,University of Liege,University of Liege,globally induced forest: a prepruning compression scheme.
1272,1272,232.0,"University of Massachusetts, Amherst","University of Massachusetts, Amherst",a divergence bound for hybrids of mcmc and variational inference and an application to langevin dynamics and sgvi.
1273,1273,233.0,EPFL,EPFL,just sort it! a simple and effective approach to active preference learning.
1274,1274,234.0,University of Rochester,University of Rochester,on the projection operator to a three-view cardinality constrained set.
1275,1275,235.0,Google,Google,density level set estimation on manifolds with dbscan.
1276,1276,236.0,LIP6 / SONY CSL,"Sony CSL, Japan",deepbach: a steerable model for bach chorales generation.
1277,1277,237.0,IIT and UCL,University College London,forward and reverse gradient-based hyperparameter optimization.
1278,1278,238.0,UC San Diego,Zillow,forest-type regression with general losses and robust forest.
1279,1279,239.0,University of Warwick,Imperial College London,on the sampling problem for kernel quadrature.
1280,1280,240.0,UCSD,Google Research,maximum selection and ranking under noisy comparisons.
1281,1281,241.0,KAIST / AItrics,IBM,sparse + group-sparse dirty models: statistical guarantees without unreasonable conditions and a case for non-convexity.
1282,1282,242.0,The University of Sydney,,algorithmic stability and hypothesis complexity.
1283,1283,243.0,Google Brain,Google,neural audio synthesis of musical notes with wavenet autoencoders.
1284,1284,244.0,Stanford University,Stanford University,adaptive sampling probabilities for non-smooth optimization.
1285,1285,245.0,KAIST,KAIST,confident multiple choice learning.
1286,1286,246.0,STANFORD,Microsoft Research,measuring sample quality with kernels.
1287,1287,247.0,University of Minnesota,University of Minnesota,active learning for top-$k$ rank aggregation from noisy comparisons.
1288,1288,248.0,University of Texas at Austin,UT Austin,compressed sensing using generative models.
1289,1289,249.0,Poznan University of Technology,Microsoft Research,consistency analysis for binary classification revisited.
1290,1290,250.0,MILA,University of Montreal,a closer look at memorization in deep networks.
1291,1291,251.0,University of Michigan,Google / U. Michigan,learning to generate long-term future via hierarchical prediction.
1292,1292,252.0,ETH Zurich,ETH,sub-sampled cubic regularization for non-convex optimization.
1293,1293,253.0,Carnegie Mellon University,Carnegie Mellon University,regret minimization in behaviorally-constrained zero-sum games.
1294,1294,254.0,Harvard,Google Brain and Princeton University,variational boosting: iteratively refining posterior approximations.
1295,1295,255.0,Tel Aviv University,Facebook AI Research and Tel Aviv University,learning to align the source code to the compiled object code.
1296,1296,256.0,Zhejiang University & Tencent AI Lab,University of Michigan,scaling up sparse support vector machines by simultaneous feature and sample reduction.
1297,1297,257.0,Google Research,Google,distributed mean estimation with limited communication.
1298,1298,258.0,DeepMind,DeepMind,cognitive psychology for deep neural networks: a shape bias case study.
1299,1299,259.0,MIT,MIT,sequence to better sequence: continuous revision of combinatorial structures.
1300,1300,260.0,Microsoft Research / Princeton / IAS,Microsoft Research / Princeton / IAS,natasha: faster non-convex stochastic optimization via strongly non-convex parameter.
1301,1301,261.0,Carnegie Mellon University,Carnegie Mellon University,reduced space and faster convergence in imperfect-information games via pruning.
1302,1302,262.0,University of Cambridge,University of Cambridge,lost relatives of the gumbel trick.
1303,1303,263.0,Microsoft Research,Microsoft Research,robustfill: neural program learning under noisy i/o.
1304,1304,264.0,University of Chicago,HKUST,efficient distributed learning with sparsity.
1305,1305,265.0,Carnegie Mellon University,CMU,nonparanormal information estimation.
1306,1306,266.0,Columbia University,Columbia University,visualizing and understanding multilayer perceptron models: a case study in speech processing.
1307,1307,267.0,"Ludwig-Maximilians-Universität München, Siemens AG",University of Munich,tensor-train recurrent neural networks for video classification.
1308,1308,268.0,Stanford University,Stanford,“convex until proven guilty”: dimension-free acceleration of gradient descent on non-convex functions.
1309,1309,269.0,Victoria University Wellington,Victoria University Wellington,strongly-typed agents are guaranteed to interact safely.
1310,1310,270.0,The Chinese University of Hong Kong,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",learning to aggregate ordinal labels by maximizing separating width.
1311,1311,271.0,University College London,UCL,programming with a differentiable forth interpreter.
1312,1312,272.0,University of Central Florida,University of Central Florida,innovation pursuit: a new approach to the subspace clustering problem.
1313,1313,273.0,Cornell University,Google,a unified maximum likelihood approach for estimating symmetric properties of discrete distributions.
1314,1314,274.0,Google Inc.,Google Inc.,axiomatic attribution for deep networks.
1315,1315,275.0,Microsoft Research,Citadel,sequence modeling via segmentations.
1316,1316,276.0,Syracuse University,Syracuse University,convergence analysis of proximal gradient with momentum for nonconvex optimization.
1317,1317,277.0,Caltech,STATS LLC.,coordinated multi-agent imitation learning.
1318,1318,278.0,Carnegie Mellon University,Carnegie Mellon University,uncorrelation and evenness: a new diversity-promoting regularizer.
1319,1319,279.0,Microsoft,Google Brain,differentiable programs with neural libraries.
1320,1320,280.0,Nagoya Institute of Technology,Nagoya Institute of Technology / RIKEN,selective inference for sparse high-order interaction models.
1321,1321,281.0,University of Texas at Austin,Microsoft,gradient coding: avoiding stragglers in distributed learning.
1322,1322,282.0,Cornell University,Cornell University,on calibration of modern neural networks.
1323,1323,283.0,Carnegie Mellon University,Amazon,latent lstm allocation: joint clustering and non-linear dynamic modeling of sequence data.
1324,1324,284.0,UC Berkeley,UC Berkeley,how to escape saddle points efficiently.
1325,1325,285.0,MIT,The Boeing Company,deep decentralized multi-task multi-agent reinforcement learning under partial observability.
1326,1326,286.0,Carnegie Mellon University,Carnegie Mellon University,learning latent space models with angular constraints.
1327,1327,287.0,Stanford University,Stanford University,developing bug-free machine learning systems with formal mathematics.
1328,1328,288.0,Ecole Polytechnique Federale de Lausanne (EPFL),,dictionary learning based on sparse distribution tomography.
1329,1329,289.0,The University of Tokyo / RIKEN,RIKEN / The University of Tokyo,learning discrete representations via information maximizing self-augmented training.
1330,1330,290.0,UC Berkeley,UC Berkeley,"sketched ridge regression: optimization perspective, statistical perspective, and model averaging."
1331,1331,291.0,Stanford,Stanford,estimating the unseen from multiple populations.
1332,1332,292.0,University of Pennsylvania,UPenn,meritocratic fairness for cross-population selection.
1333,1333,293.0,UIUC,UIUC,neural networks and rational functions.
1334,1334,294.0,Carnegie Mellon University,Carnegie Mellon University,input convex neural networks.
1335,1335,295.0,LIG,Univ. Grenoble Alpes,co-clustering through optimal transport.
1336,1336,296.0,Carnegie Mellon University,Carnegie Mellon University,optnet: differentiable optimization as a layer in neural networks.
1337,1337,297.0,Northeastern University,Northeastern University,multiple clustering views from multiple uncertain experts.
1338,1338,298.0,Facebook AI Research,Facebook AI Research,parseval networks: improving robustness to adversarial examples.
1339,1339,299.0,NC state university,,"clustering by sum of norms: stochastic incremental algorithm, convergence and cluster recovery."
1340,1340,300.0,"University of Geneva, HES",HES-UNIGE,regularising non-linear models using feature side-information.
1341,1341,301.0,Johns Hopkins,Linguee GmbH,clustering high dimensional dynamic data streams.
1342,1342,302.0,UC Berkeley,University of California at Berkeley,fast k-nearest neighbour search via prioritized dci.
1343,1343,303.0,University of Toronto,University of Toronto,deep spectral clustering learning.
1344,1344,304.0,Data61,Australian National University,joint dimensionality reduction and metric learning: a geometric take.
1345,1345,305.0,"Microsoft Research, India",Microsoft Research,protonn: compressed and accurate knn for resource-scarce devices.
1346,1346,306.0,Google,Google Brain,device placement optimization with reinforcement learning.
1347,1347,307.0,Disney Research Pittsburgh,Disney Research,dynamic word embeddings.
1348,1348,308.0,University of Science and Technology of China,Microsoft,asynchronous stochastic gradient descent with delay compensation.
1349,1349,309.0,Carnegie Mellon University,Carnegie Mellon University,improving stochastic policy gradients in continuous control with deep reinforcement learning using the beta distribution.
1350,1350,310.0,Telecom ParisTech,Telecom ParisTech,fractional langevin monte carlo: exploring levy driven stochastic differential equations for mcmc.
1351,1351,311.0,Amazon,Amazon.com,preferential bayesian optmization.
1352,1352,312.0,USC,USC,being robust (in high dimensions) can be practical.
1353,1353,313.0,University of Alberta,University of Alberta,differentially private ordinary least squares.
1354,1354,314.0,University of Wisconsin - Madison,University of Wisconsin Madison,"when can multi-site datasets be pooled for regression? hypothesis tests, $\ell_2$-consistency and neuroscience applications."
1355,1355,315.0,MIT / DeepMind,MIT,deep tensor convolution on multicores.
1356,1356,316.0,Baidu Silicon Valley AI Lab,Baidu SVAIL,gram-ctc: automatic unit selection and target decomposition for sequence labelling.
1357,1357,317.0,University of Maryland,University of Maryland,adaptive consensus admm for distributed optimization.
1358,1358,318.0,University of Southern California,Berkeley,combining model-based and model-free updates for trajectory-centric reinforcement learning.
1359,1359,319.0,Columbia University,,stochastic  bouncy  particle sampler.
1360,1360,320.0,MIT,MIT,max-value entropy search for efficient bayesian optimization.
1361,1361,321.0,University of Minnesota,University of Massachusetts Amherst,multilabel classification with group testing and codes.
1362,1362,322.0,MIT,MIT,priv’it: private and sample efficient identity testing.
1363,1363,323.0,UCLA,Oxford University and UCLA,learning from clinical judgments: semi-markov-modulated marked hawkes processes for risk prognosis.
1364,1364,324.0,IBM Research,IBM Research,mec: memory-efficient convolution for deep neural network.
1365,1365,325.0,Peking University,Peking University,coupling distributed and symbolic execution for natural language queries.
1366,1366,326.0,MSR-INRIA Joint Center,MSR-INRIA Joint Center,optimal algorithms for smooth and strongly convex distributed optimization in networks.
1367,1367,327.0,Georgia Tech,Georgia Tech,prediction under uncertainty in sparse spectrum gaussian processes with applications to filtering and control.
1368,1368,328.0,Carnegie Mellon University,Amazon,canopy --- fast sampling with cover trees.
1369,1369,329.0,Amazon,Amazon.com,bayesian optimization with tree-structured dependencies.
1370,1370,330.0,University of Minnesota,University of Minnesota,high-dimensional structured quantile regression.
1371,1371,331.0,Yale University,Yale,differentially private submodular maximization: data summarization in disguise.
1372,1372,332.0,Duke University,Duke University,learning to detect sepsis with a multitask gaussian process rnn classifier.
1373,1373,333.0,Peking University,,beyond filters: compact feature map for portable deep model.
1374,1374,334.0,Harvard University,Harvard University,image-to-markup generation with coarse-to-fine attention.
1375,1375,335.0,Tsinghua University,HKUST,projection-free distributed online learning in networks.
1376,1376,336.0,Technical University of Munich,Technical University of Munich,learning stable stochastic nonlinear dynamical systems.
1377,1377,337.0,Penn State University,Penn State University,a simulated annealing based inexact oracle for wasserstein loss minimization.
1378,1378,338.0,CMU,CMU/Uber,multi-fidelity bayesian optimisation with continuous approximations.
1379,1379,339.0,Princeton University,Princeton University,high-dimensional non-gaussian single index models via thresholded score function estimation.
1380,1380,340.0,University of Massachusetts Amherst,"University of Massachusetts, Amherst",differentially private learning of graphical models using cgms.
1381,1381,341.0,University of Michigan,University of Wisconsin-Madison,"isurvive: an interpretable, event-time prediction model for mhealth."
1382,1382,342.0,Facebook AI Research,Facebook AI Research,efficient softmax approximation for gpus.
1383,1383,343.0,Doshisha University,MITSUBISHI ELECTRIC RESEARCH LABORATORIES,multichannel end-to-end speech recognition.
1384,1384,344.0,TU Darmstadt,University of Lincoln,local bayesian optimization of motor skills.
1385,1385,345.0,Stanford University,Microsoft Research,improving gibbs sampler scan quality with dogs.
1386,1386,346.0,University of Cambridge,,parallel and distributed thompson sampling for large-scale accelerated exploration of chemical space.
1387,1387,347.0,University of Minnesota,University of Minnesota,robust structured estimation with single-index models.
1388,1388,348.0,TU Berlin / MathPlan,TU Berlin,minimizing trust leaks for robust sybil detection.
1389,1389,349.0,MIT,Massachusetts General Hospital,learning sleep stages from radio signals: a conditional adversarial architecture.
1390,1390,350.0,University of Cambridge,University of Cambridge,dropout inference in bayesian neural networks with alpha-divergences.
1391,1391,351.0,University of Cambridge,University of Cambridge,latent intention dialogue models.
1392,1392,352.0,Harvard,Bar Ilan University,robust guarantees of stochastic greedy algorithms.
1393,1393,353.0,Google DeepMind,DeepMind,count-based exploration with neural density models.
1394,1394,354.0,UC Berkeley,University of Cambridge,magnetic hamiltonian monte carlo.
1395,1395,355.0,University of Virginia,University of Virginia,uncertainty assessment and false discovery rate control in high-dimensional granger causal inference.
1396,1396,356.0,The Chinese University of Hong Kong,CUHK,toward efficient and accurate covariance matrix estimation on compressed data.
1397,1397,357.0,Princeton University,Princeton University,the price of differential privacy for online learning.
1398,1398,358.0,IBM Research - Tokyo,IBM Research - Tokyo,bidirectional learning for time-series models with hidden units.
1399,1399,359.0,University of Amsterdam,University of Amsterdam,multiplicative normalizing flows for variational bayesian neural networks.
1400,1400,360.0,University of Oxford,Oxford University and DeepMind,discovering discrete latent topics with neural variational inference.
1401,1401,361.0,ETH Zurich,ETH,guarantees for greedy maximization of non-submodular functions with applications.
1402,1402,362.0,University of Michigan,Microsoft Research,zero-shot task generalization with multi-task deep reinforcement learning.
1403,1403,363.0,Fred Hutchinson Cancer Center,Fred Hutchinson Cancer Center,probabilistic path hamiltonian monte carlo.
1404,1404,364.0,Ecole Polytechnique,Université de Corse,uncovering causality from multivariate hawkes integrated cumulants.
1405,1405,365.0,University of Virginia,University of Virginia,robust gaussian graphical model estimation with arbitrary corruption.
1406,1406,366.0,University​ of Melbourne,Ruhr-Universität Bochum,pain-free random differential privacy with sensitivity sampling.
1407,1407,367.0,Georgia Institute of Technology,Georgia Institute of Technology,learning hawkes processes from short doubly-censored event sequences.
1408,1408,368.0,Skoltech,HSE,variational dropout sparsifies deep neural networks.
1409,1409,369.0,Carnegie Mellon University,Carnegie Mellon University,toward controlled generation of text.
1410,1410,370.0,EPFL,EPFL,robust submodular maximization: a non-uniform partitioning approach.
1411,1411,371.0,University of Oxford,University of Oxford,stabilising experience replay for deep multi-agent reinforcement learning.
1412,1412,372.0,Duke university,Duke,stochastic gradient monomial gamma sampler.
1413,1413,373.0,University of Texas at Austin,,cost-optimal learning of causal graphs.
1414,1414,374.0,University of Michigan,University of Wisconsion-Madison,algebraic variety models for high-rank matrix completion.
1415,1415,375.0,Carnegie Mellon University,Carnegie Mellon University,differentially private clustering in high-dimensional euclidean spaces.
1416,1416,376.0,Monash University,Monash University,coherent probabilistic forecasts for hierarchical time series.
1417,1417,377.0,MILA,MILA,unimodal probability distributions for deep ordinal classification.
1418,1418,378.0,Duke university,Duke,adversarial feature matching for text generation.
1419,1419,379.0,Yale,Yale,probabilistic submodular maximization in sub-linear time.
1420,1420,380.0,Google DeepMind,DeepMind,the predictron:  end-to-end learning and planning.
1421,1421,381.0,University of Washington,University of Washington,stochastic gradient mcmc methods for hidden markov models.
1422,1422,382.0,IBM Research,Purdue,identification and model testing in linear structural equation models using auxiliary variables.
1423,1423,383.0,Facebook,University of Virginia,high-dimensional variance-reduced stochastic gradient expectation-maximization algorithm.
1424,1424,384.0,University of Tsukuba / NEC,University of Tsukuba / RIKEN AIP,differentially private chi-squared test by unit circle mechanism.
1425,1425,385.0,ENSAE / CREST,NTT,soft-dtw: a differentiable loss function for time-series.
1426,1426,386.0,Microsoft Research,University of Edinburgh,learning continuous semantic representations of symbolic expressions.
1427,1427,387.0,UT Austin,YALE,on approximation guarantees for greedy low rank optimization.
1428,1428,388.0,Technion,Technion,averaged-dqn: variance reduction and stabilization for deep reinforcement learning.
1429,1429,389.0,Xidian University,University of Texas at Austin,deep latent dirichlet allocation with topic-layer-adaptive stochastic gradient riemannian mcmc.
1430,1430,390.0,NYU,Massachusetts Institute of Technology,estimating individual treatment effect: generalization bounds and algorithms.
1431,1431,391.0,Peking University,Peking University,"collect at once, use effectively: making non-interactive locally private learning possible."
1432,1432,392.0,Gatech,Georgia Institute of Technology,variational policy for guiding point processes.
1433,1433,393.0,"University of California, San Diego",UCSD,dance dance convolution.
1434,1434,394.0,Facebook AI Research,Facebook,language modeling with gated convolutional networks.
1435,1435,395.0,ETH Zurich,ETH Zurich,"deletion-robust submodular maximization: data summarization with ""the right to be forgotten""."
1436,1436,396.0,DeepMind,DeepMind,feudal networks for hierarchical reinforcement learning.
1437,1437,397.0,Ludwig-Maximilians-Universität München,National University of Singapore,distributed batch gaussian process optimization.
1438,1438,398.0,Cornell University,Cornell University,recursive partitioning for personalization using observational data.
1439,1439,399.0,Rice University,Rice University,optimal densification for fast and accurate minwise hashing.
1440,1440,400.0,UCL,Gatsby Computational Neuroscience Unit,an adaptive test of independence with analytic kernel embeddings.
1441,1441,401.0,Gifs.com,Google Brain,deep value networks learn to evaluate and iteratively refine structured outputs.
1442,1442,402.0,Stanford University,Stanford University,world of bits: an open-domain platform for web-based agents.
1443,1443,403.0,Facebook AI Research,Facebook AI Research,convolutional sequence to sequence learning.
1444,1444,404.0,Max Planck Institute for Informatics,MPI for Informatics,analysis and optimization of graph decompositions by lifted multicuts.
1445,1445,405.0,California Institute of Technology,caltech.edu,deciding how to decide: dynamic routing in artificial neural networks.
1446,1446,406.0,Universidad Autónoma de Madrid,Universidad Autonoma de Madrid,scalable multi-class gaussian process classification using expectation propagation.
1447,1447,407.0,University of Texas at Austin,University of Texas at Austin,identifying best interventions through online importance sampling.
1448,1448,408.0,Georgia Tech,Georgia Institute of Technology,stochastic generative hashing.
1449,1449,409.0,Inria Saclay,,sliced wasserstein kernel for persistence diagrams.
1450,1450,410.0,Carnegie Mellon University,Carnegie Mellon University,deeply aggrevated: differentiable imitation learning for sequential prediction.
1451,1451,411.0,"WaveOne, Inc.","WaveOne, Inc.",real-time adaptive image compression.
1452,1452,412.0,Carnegie Mellon University,,improved variational autoencoders for text modeling using dilated convolutions.
1453,1453,413.0,Microsoft Research / Princeton / IAS,CMU,near-optimal design of experiments via regret minimization.
1454,1454,414.0,Deepmind,DeepMind,neural episodic control.
1455,1455,415.0,EURECOM,Eurecom,random feature expansions for deep gaussian processes.
1456,1456,416.0,University of British Columbia,MICROSOFT,deep iv: a flexible approach for counterfactual prediction.
1457,1457,417.0,ETH Zurich,ETH Zurich,"zipml: training linear models with end-to-end low precision, and a little bit of deep learning."
1458,1458,418.0,Indiana University,University of Alberta/Indiana University,adapting kernel representations online using submodular maximization.
1459,1459,419.0,Google Brain,UMass Amherst,end-to-end learning for structured prediction energy networks.
1460,1460,420.0,Google Brain,Google Brain,neural message passing for quantum chemistry.
1461,1461,421.0,Alan Turing Institute,University of Cambridge,grammar variational autoencoder.
1462,1462,422.0,MIT,MIT,robust budget allocation via continuous submodular functions.
1463,1463,423.0,Google Brain,Google Brain,neural optimizer search using reinforcement learning.
1464,1464,424.0,Purdue University,Ant Financial,asynchronous distributed variational gaussian processes for regression.
1465,1465,425.0,UCLA,Purdue,counterfactual data-fusion for online reinforcement learners.
1466,1466,426.0,Google Inc.,Google Brain,large-scale evolution of image classifiers.
1467,1467,427.0,city university of hong kong,city university of hong kong,spherical structured feature maps for kernel approximation.
1468,1468,428.0,Nanjing University,Nanjing University,a unified view of multi-label performance measures.
1469,1469,429.0,Google Brain,New York University,accelerating eulerian fluid simulation with convolutional networks.
1470,1470,430.0,Rutgers University,Rutgers Univeristy,rule-enhanced penalized regression by column generation using rectangular maximum agreement.
1471,1471,431.0,Deakin University,Deakin University,high dimensional bayesian optimization with elastic gaussian process.
1472,1472,432.0,University of Bonn,The University of Nottingham,nyström method with kernel k-means++ samples as landmarks.
1473,1473,433.0,Indian Institute of Technology Kanpur,IIT Kanpur,scalable generative models for multi-label learning with missing labels.
1474,1474,0.0,Rice University,OpenStax / Rice University,spline filters for end-to-end deep learning.
1475,1475,1.0,University of Bonn,EPFL,non-linear motor control by local learning in spiking neural networks.
1476,1476,2.0,DeepMind,DeepMind,implicit quantile networks for distributional reinforcement learning.
1477,1477,3.0,McGill University,McGill University / Facebook,an inference-based policy gradient method for learning options.
1478,1478,4.0,Tel Aviv University,"Tel Aviv University, Google",predict and constrain: modeling cardinality in deep structured prediction.
1479,1479,5.0,Microsoft Research,UCSC,differentially private matrix completion revisited.
1480,1480,6.0,Uber AI Labs,Uber AI Labs,differentiable plasticity: training plastic neural networks with backpropagation.
1481,1481,7.0,University of Science and Technology of China,Microsoft,model-level dual learning.
1482,1482,8.0,Stanford University,Stanford University,cover: learning covariate-specific vector representations with tensor decompositions.
1483,1483,9.0,Bielefeld University,"CITEC, Bielefeld University",tree edit distance learning via adaptive symbol embeddings.
1484,1484,10.0,Johns Hopkins University,Johns Hopkins University,gradually updated neural networks for large-scale image recognition.
1485,1485,11.0,Universty of Tübingen,University of Tübingen,one-shot segmentation in clutter.
1486,1486,12.0,UC Irvine,UC Irvine,active testing: an efficient and robust framework for estimating accuracy.
1487,1487,13.0,University of Maryland College Park,Microsoft Research,learning deep resnet blocks sequentially using boosting theory.
1488,1488,14.0,UC Berkeley,Berkeley,self-consistent trajectory autoencoder: hierarchical reinforcement learning with trajectory embeddings.
1489,1489,15.0,Stanford University,Stanford University,problem dependent reinforcement learning bounds which can identify bandit structure in mdps.
1490,1490,16.0,Johns Hopkins University,Johns Hopkins University,stochastic pca with $\ell_2$ and $\ell_1$ regularization.
1491,1491,17.0,,Columbia University in the City of New York,subspace embedding and linear regression with orlicz norm.
1492,1492,18.0,Qualcomm India Private Limited,IIT Madras,signal and  noise statistics oblivious orthogonal matching pursuit.
1493,1493,19.0,Carnegie Mellon University,Carnegie Mellon University / Bosch Center for AI,provable defenses against adversarial examples via the convex outer adversarial polytope.
1494,1494,20.0,Franklin & Marshall College,Franklin & Marshall College,learning the reward function for a misspecified model.
1495,1495,21.0,UNIST,Korea University,deep reinforcement learning in continuous action spaces: a case study in the game of simulated curling.
1496,1496,22.0,"IIIS, Tsinghua University","IIIS, Tsinghua University",do outliers ruin collaboration?.
1497,1497,23.0,UC Berkeley,Peking University,"dropout training, data-dependent regularization, and generalization bounds."
1498,1498,24.0,"IEMS, Northwestern University",Northwestern University,competitive multi-agent inverse reinforcement learning with sub-optimal demonstrations.
1499,1499,25.0,Imperial College London,Imperial College London,continual reinforcement learning with complex synapses.
1500,1500,26.0,University of Chicago,University of Chicago,equivalence of multicategory svm and simplex cone svm: fast computations and statistical theory.
1501,1501,27.0,Google,Princeton University,quickshift++: provably good initializations for sample-based mean shift.
1502,1502,28.0,Harvard University,Facebook,learning diffusion using hyperparameters.
1503,1503,29.0,Sapienza University,Google,learning a mixture of two multinomial logits.
1504,1504,30.0,Rutgers University,Rutgers University,crowdsourcing with arbitrary adversaries.
1505,1505,31.0,Carnegie Mellon University,Carnegie Mellon University,deep density destructors.
1506,1506,32.0,Rice University,Rice University,programmatically interpretable reinforcement learning.
1507,1507,33.0,Google Brain Robotics,"University of Cambridge, Alan Turing Institute",structured evolution with compact architectures for scalable policy optimization.
1508,1508,34.0,University of Oxford,ENS Paris,the weighted kendall and high-order kernels for permutations.
1509,1509,35.0,UC San Diego,UC San Diego,"the limits of maxing, ranking, and preference learning."
1510,1510,36.0,Columbia University,Columbia University Medical Center,black box fdr.
1511,1511,37.0,PURDUE UNIVERSITY,Purdue University,variable selection via penalized neural network: a drop-out-one loss approach.
1512,1512,38.0,Northwestern University,Rutgers University,clustering semi-random mixtures of gaussians.
1513,1513,39.0,Alan Turing Institute & University of Warwick,Carnegie Mellon University,leveraging well-conditioned bases: streaming and distributed summaries in minkowski $p$-norms.
1514,1514,40.0,DeepMind,DeepMind,learning by playing - solving sparse reward tasks from scratch.
1515,1515,41.0,Stanford University,Carnegie Mellen University,structured control nets for deep reinforcement learning.
1516,1516,42.0,Stanford,Caltech,stagewise safe bayesian optimization with gaussian processes.
1517,1517,43.0,Massachusetts Institute of Technology,University of Arizona,bayesian optimization of combinatorial structures.
1518,1518,44.0,Stanford University,Stanford University,graphrnn: generating realistic graphs with deep auto-regressive models.
1519,1519,45.0,TU Darmstadt,TU Darmstadt,dependent relational gamma process models for longitudinal networks.
1520,1520,46.0,Wichita State University,Wichita State University,k-means clustering using random matrix sparsification.
1521,1521,47.0,Stanford University,Stanford University,hierarchical clustering with structural constraints.
1522,1522,48.0,Idiap Research Institute,Idiap research institute,kronecker recurrent units.
1523,1523,49.0,Imperial College London,Microsoft Research Cambridge,semi-supervised learning via compact latent space clustering.
1524,1524,50.0,University of Edinburgh,University of Edinburgh,dynamic evaluation of neural sequence models.
1525,1525,51.0,Latent Logic LTD,University of Oxford,taco: learning task decomposition via temporal alignment for control.
1526,1526,52.0,Tsinghua University,Tsinghua University,a spectral approach to gradient estimation for implicit distributions.
1527,1527,53.0,ENSAE-CREST Paris,UC Irvine,quasi-monte carlo variational inference.
1528,1528,54.0,Harvard University,Harvard,learning to optimize combinatorial functions.
1529,1529,55.0,Columbia,Google Research,"proportional allocation: simple, distributed, and diverse matching with high entropy."
1530,1530,56.0,MIT,MIT,representation learning on graphs with jumping knowledge networks.
1531,1531,57.0,Technical University of Munich,Technical University of Munich,netgan: generating graphs via random walks.
1532,1532,58.0,Cornell University,Cornell University,inspectre: privately estimating the unseen.
1533,1533,59.0,University of Alberta,University of Alberta,locally private hypothesis testing.
1534,1534,60.0,UC Berkeley,Berkeley,latent space policies for hierarchical reinforcement learning.
1535,1535,61.0,Georgia Tech,Facebook AI Research,more robust doubly robust off-policy evaluation.
1536,1536,62.0,"University of California, Berkeley",UC Berkeley,learning to explain: an information-theoretic perspective on model interpretation.
1537,1537,63.0,Tencent AI Lab,Peking University,end-to-end active object tracking via reinforcement learning.
1538,1538,64.0,University of Illinois at Chicago,University of Illinois at Chicago,efficient and consistent adversarial bipartite matching.
1539,1539,65.0,Cornell University,Cornell University,sparsemap: differentiable sparse structured inference.
1540,1540,66.0,Istituto Italiano di Tecnologia - University College London,University College London,bilevel programming for hyperparameter optimization and meta-learning.
1541,1541,67.0,Technion – Israel Institute of Technology,Technion Israeli Institute of Technology,meta-learning by adjusting priors based on extended pac-bayes theory.
1542,1542,68.0,TU Wien,TU Wien,parameterized algorithms for the matrix completion problem.
1543,1543,69.0,Iowa State University,Iowa State University,nearly optimal robust subspace tracking.
1544,1544,70.0,Microsoft Research AI,Microsoft Research AI,katyusha x: simple momentum method for stochastic sum-of-nonconvex optimization.
1545,1545,71.0,Caltech,Amazon AI & Caltech,signsgd: compressed optimisation for non-convex problems.
1546,1546,72.0,MIT CSAIL,LabSix,synthesizing robust adversarial examples.
1547,1547,73.0,ETH Zürich,ETH Zurich,differentiable abstract interpretation for provably robust neural networks.
1548,1548,74.0,Tsinghua University,Georgia Institute of Technology,stochastic training of graph convolutional networks with variance reduction.
1549,1549,75.0,University of Amsterdam,Vector Institute,neural relational inference for interacting systems.
1550,1550,76.0,MPI Tübingen,Microsoft Research,which training methods for gans do actually converge?.
1551,1551,77.0,Max Planck Institute for Intelligent Systems and ETH Zurich,"MPI for Intelligent Systems Tübingen, Germany",learning independent causal mechanisms.
1552,1552,78.0,U-Tokyo,Purdue University,nonconvex optimization for regression with fairness constraints.
1553,1553,79.0,Stanford,Stanford University,fairness without demographics in repeated loss minimization.
1554,1554,80.0,Peking University,Peking University,msplit lbi: realizing feature selection and dense estimation simultaneously in few-shot and zero-shot learning.
1555,1555,81.0,Carnegie Mellon University,Petuum Inc. and CMU,nonoverlap-promoting variable selection.
1556,1556,82.0,Zhejiang University,Zhejiang University,towards more efficient stochastic decentralized learning: faster convergence and sparse communication.
1557,1557,83.0,DeepMind,DeepMind,graph networks as learnable physics engines for inference and control.
1558,1558,84.0,Cornell,Cornell University,an alternative view: when does sgd escape local minima?.
1559,1559,85.0,University of Rochester,University of Rochester,asynchronous decentralized parallel stochastic gradient descent.
1560,1560,86.0,Princeton University,Cornell University,an estimation and analysis framework for the rasch model.
1561,1561,87.0,University of Pennsylvania,University of Pennsylvania,mitigating bias in adaptive data gathering via differential privacy.
1562,1562,88.0,Univeristy at Buffalo,Apple,local private hypothesis testing: chi-square tests.
1563,1563,89.0,"DeepMind, University of Oxford",DeepMind,disentangling by factorising.
1564,1564,90.0,Inria Lille Nord-Europe,Montanuniversitaet Leoben,efficient bias-span-constrained exploration-exploitation in reinforcement learning.
1565,1565,91.0,Google DeepMind,Google DeepMind,learning to search with mctsnets.
1566,1566,92.0,University of Pittsburgh,University of Pittsburgh,decoupled parallel backpropagation with convergence guarantee.
1567,1567,93.0,Iowa State University,Iowa State University,on learning sparsely used dictionaries from incomplete samples.
1568,1568,94.0,UNSW,"Data61, The Australian National University and the University of Sydney",variational network inference: strong and stable with concrete support.
1569,1569,95.0,Yale University,Yale,weakly submodular maximization beyond cardinality constraints: does randomization help greedy?.
1570,1570,96.0,Yale University,Yale,data summarization at scale: a two-stage submodular approach.
1571,1571,97.0,Indiana University Bloomington,Indiana University Bloomington,best arm identification in linear bandits with linear dimension dependency.
1572,1572,98.0,Stanford University,Stanford University,learning with abandonment.
1573,1573,99.0,ETH Zurich,ETH Zurich,hyperbolic entailment cones for learning hierarchical embeddings.
1574,1574,100.0,Technical University of Denmark,DeepMind,generative temporal models with spatial memory for partially observed environments.
1575,1575,101.0,Facebook AI Research,University of Oxford,dice: the infinitely differentiable monte carlo estimator.
1576,1576,102.0,University of Kentucky,University of Kentucky,orthogonal recurrent neural networks with scaled cayley transform.
1577,1577,103.0,UC Berkeley,Berkeley,least-squares temporal difference learning for the linear quadratic regulator.
1578,1578,104.0,University of Toronto,University of Toronto,spotlight: optimizing device placement for training deep neural networks.
1579,1579,105.0,UC Berkeley,"Stanford, Google, UC Berkeley",universal planning networks: learning generalizable representations for visuomotor control.
1580,1580,106.0,Stanford,Stanford University,coordinated exploration in concurrent reinforcement learning.
1581,1581,107.0,Kyoto University / RIKEN AIP,Kyoto University / RIKEN AIP,a probabilistic framework for multi-view feature learning with many-to-many associations via neural networks.
1582,1582,108.0,Georgia Tech,Georgia Institute of Technology,learning steady-states of iterative algorithms over graphs.
1583,1583,109.0,MIT CSAIL,UC Berkeley,obfuscated gradients give a false sense of security: circumventing defenses to adversarial examples.
1584,1584,110.0,Yale,EPFL,fair and diverse dpp-based data summarization.
1585,1585,111.0,DeepMind,DeepMind,learning implicit generative models with the method of learned moments.
1586,1586,112.0,Duke University,Duke,chi-square generative adversarial network.
1587,1587,113.0,Johns Hopkins University,Johns Hopkins University,streaming principal component analysis in noisy setting.
1588,1588,114.0,Max Planck Institute for Informatics,MPI for Informatics,partial optimality and fast lower bounds for weighted correlation clustering.
1589,1589,115.0,Lehigh University & IBM T.J. Watson Research Center,Lehigh University,sgd and hogwild! convergence without the bounded gradients assumption.
1590,1590,116.0,Weierstrass Institute for Applied Analysis and Stochastics,Institute for Information Transmission Problems,computational optimal transport: complexity by accelerated gradient descent is better than by sinkhorn's algorithm.
1591,1591,117.0,University of Wisconsin-Madison,ECE at University of Wisconsin-Madison,stability and generalization of learning algorithms that converge to global optima.
1592,1592,118.0,EPFL,EPFL,optimal rates of sketched-regularized algorithms for least-squares regression over hilbert spaces.
1593,1593,119.0,Google,UC Berkeley,adafactor: adaptive learning rates with sublinear memory cost.
1594,1594,120.0,DeepMind,Google DeepMind,fast parametric learning with activation memorization.
1595,1595,121.0,Heidelberg University,Heidelberg Collaboratory for Image Processing,essentially no barriers in neural network energy landscape.
1596,1596,122.0,Loyola Marymount University,CSULB,deep linear networks with arbitrary loss: all local minima are global.
1597,1597,123.0,Rolls-Royce@NTU Corp Lab,Nanyang Technological University,generalized robust bayesian committee machine for large-scale gaussian process regression.
1598,1598,124.0,Imperial College London,Imperial College London,bayesian quadrature for multiple related integrals.
1599,1599,125.0,Purdue University,Purdue University,deep predictive coding network for object recognition.
1600,1600,126.0,RIKEN AIP,RIKEN AIP,neural inverse rendering for general reflectance photometric stereo.
1601,1601,127.0,Stanford University,Stanford University,on the relationship between data efficiency and error for uncertainty sampling.
1602,1602,128.0,MIT,(organization),selecting representative examples for program synthesis.
1603,1603,129.0,DeepMind,DeepMind,conditional neural processes.
1604,1604,130.0,Google,Google Brain,hierarchical long-term video prediction without supervision.
1605,1605,131.0,DeepMind,Google Deepmind,adversarial risk and the dangers of evaluating against weak attacks.
1606,1606,132.0,MIT,MIT,a classification-based study of covariate shift in gan distributions.
1607,1607,133.0,Carnegie Mellon University,Carnegie Mellen University,gated path planning networks.
1608,1608,134.0,UC Berkeley,OpenAI / UC Berkeley,automatic goal generation for reinforcement learning agents.
1609,1609,135.0,Johns Hopkins University,Johns Hopkins University,admm and accelerated admm as continuous dynamical systems.
1610,1610,136.0,University of Wisconsin-Madison,University of Wisconsin-Madison,dissipativity theory for accelerating stochastic variance reduction: a unified analysis of svrg and katyusha using semidefinite programs.
1611,1611,137.0,University of Pisa,Universita di Pisa,contextual graph markov model: a deep and generative approach to graph processing.
1612,1612,138.0,Facebook AI Research,Facebook AI Research,learning continuous hierarchies in the lorentz model of hyperbolic geometry.
1613,1613,139.0,"University of California, Davis","University of California, Davis",fast variance reduction method with stochastic batch size.
1614,1614,140.0,INRIA/ENS,University of Wisconsin-Madison,lyapunov functions for first-order methods: tight automated convergence guarantees.
1615,1615,141.0,Carnegie Mellon University,CMU,nonparametric regression with comparisons: escaping the curse of dimensionality with ordinal information.
1616,1616,142.0,Princeton University,Princeton University and Google Brain,the well-tempered lasso.
1617,1617,143.0,Tencent AI Lab,Hong Kong UST,transfer learning via learning to transfer.
1618,1618,144.0,UT Austin - Sentient Technologies,UT Austin - Sentient Technologies,pseudo-task augmentation: from deep multitask learning to intratask sharing—and back.
1619,1619,145.0,The University of Tokyo,RIKEN / The University of Tokyo,analysis of minimax error rate for crowdsourcing and its application to worker clustering model.
1620,1620,146.0,Hasso Plattner Institute,TU Kaiserslautern,deep one-class classification.
1621,1621,147.0,PUC-RIO,PUC-Rio,binary partitions with approximate  minimum impurity.
1622,1622,148.0,EPFL,EPFL,beyond 1/2-approximation for submodular maximization on massive data streams.
1623,1623,149.0,Columbia University,Columbia University,"yes, but did it work?: evaluating variational inference."
1624,1624,150.0,Newcastle University,Newcastle University,black-box variational inference for stochastic differential equations.
1625,1625,151.0,Hong Kong University of Science and Technology,University of Macau,online convolutional sparse coding with sample-dependent dictionary.
1626,1626,152.0,University of Utah,University of Utah,learning to speed up structured output prediction.
1627,1627,153.0,MIT,"MIT, TAU",differentially private identity and equivalence testing of discrete distributions.
1628,1628,154.0,Saudi Aramco,Saudi Aramco,information theoretic guarantees for empirical risk minimization with applications to model selection and large-scale optimization.
1629,1629,155.0,University of Amsterdam,University of Amsterdam,bock : bayesian optimization with cylindrical kernels.
1630,1630,156.0,University of Freiburg,University of Freiburg,bohb: robust and efficient hyperparameter optimization at scale.
1631,1631,157.0,University of Pennsylvania,Yale University,distributed nonparametric regression under communication constraints.
1632,1632,158.0,SUNY-Binghamton University,Purdue University,optimal tuning for divide-and-conquer kernel ridge regression with massive data.
1633,1633,159.0,Mines Paristech,ENS Paris,whinter: a working set algorithm for high-dimensional sparse second order interaction models.
1634,1634,160.0,Tencent AI Lab,Tecent AI Lab,safe element screening for submodular function minimization.
1635,1635,161.0,Facebook,Northwestern,feedback-based tree search for reinforcement learning.
1636,1636,162.0,DeepMind,DeepMind,transfer in deep reinforcement learning using successor features and generalised policy improvement.
1637,1637,163.0,University of Milan,IST Austria,data-dependent stability of stochastic gradient descent.
1638,1638,164.0,DeepMind,Deepmind,leapsandbounds: a method for approximately optimal algorithm configuration.
1639,1639,165.0,Yale,Yale,scalable deletion-robust submodular maximization: data summarization with privacy and fairness constraints.
1640,1640,166.0,University of Virginia,UCLA,covariate adjusted precision matrix estimation via nonconvex optimization.
1641,1641,167.0,Columbia University,,comparing dynamics: deep neural networks versus glassy systems.
1642,1642,168.0,"Institute of High Performance Computing, A*STAR, Singapore","IHPC, A*STAR",an optimal control approach to deep learning and applications to discrete-weight neural networks.
1643,1643,169.0,Idiap,Idiap research institute,not all samples are created equal: deep learning with importance sampling.
1644,1644,170.0,Google AI,Google Brain,"dynamical isometry and a mean field theory of cnns: how to train 10,000-layer vanilla convolutional neural networks."
1645,1645,171.0,DeepMind,Facebook AI Research,path consistency learning in tsallis entropy regularized mdps.
1646,1646,172.0,Brown University,Brown University,lipschitz continuity in model-based reinforcement learning.
1647,1647,173.0,Cornell University,Cornell University,linear spectral estimators and an application to phase retrieval.
1648,1648,174.0,Sharif University of Technology,Telecom ParisTech,bounds on the approximation power of feedforward neural networks.
1649,1649,175.0,Indian Institute of Science,Indian Institute of Science,testing sparsity over known and unknown bases.
1650,1650,176.0,University of Toronto,University of Toronto,inference suboptimality in variational autoencoders.
1651,1651,177.0,University of Texas at Austin,University of Texas at Austin,semi-implicit variational inference.
1652,1652,178.0,Georgia Institute of Technology,Georgia Institute of Technology,variance regularized counterfactual risk minimization via variational divergence minimization.
1653,1653,179.0,UCLA,UCLA,limits of estimating heterogeneous treatment effects: guidelines for practical algorithm design.
1654,1654,180.0,"University of California, Los Angeles","University of California, Los Angeles",a semantic loss function for deep learning with symbolic knowledge.
1655,1655,181.0,University of Texas at Austin,UT Austin & Amazon,stabilizing gradients for deep neural networks via efficient svd parameterization.
1656,1656,182.0,National University of Singapore,National University of Singapre,an efficient semismooth newton based algorithm for convex clustering.
1657,1657,183.0,Hong Kong University of Science and Technology,Hong Kong University of Science and Technology,lightweight stochastic optimization for minimizing finite sums with infinite data.
1658,1658,184.0,RIKEN AIP / Tohoku University,Tohoku University/RIKEN AIP,exploiting the potential of standard convolutional autoencoders for image restoration by evolutionary search.
1659,1659,185.0,Carnegie Mellon University,Google Brain,efficient neural architecture search via parameters sharing.
1660,1660,186.0,technion,Georgia Tech,non-convex conditional gradient sliding.
1661,1661,187.0,"University of California, Los Angeles",UCLA,stochastic variance-reduced cubic regularized newton method.
1662,1662,188.0, Princeton University and Institute for Advanced Study,Google Brain and Princeton University,on the optimization of deep networks: implicit acceleration by overparameterization.
1663,1663,189.0,"L2S, CentraleSupelec",CentralSupélec,the dynamics of learning: a random matrix approach.
1664,1664,190.0,UCLA,UCLA,learning k-way d-dimensional discrete codes for compact embedding representations.
1665,1665,191.0,University of Cambridge,"University of Cambridge, Alan Turing Institute",discovering interpretable representations for both deep generative and discriminative models.
1666,1666,192.0,SUNY at Buffalo,Duke,continuous-time flows for efficient inference and density estimation.
1667,1667,193.0,University of Oxford,Oxford and DeepMind,tighter variational bounds are not necessarily better.
1668,1668,194.0,Tsinghua University,UIC,predrnn++: towards a resolution of the deep-in-time dilemma in spatiotemporal predictive learning.
1669,1669,195.0,"University of California, Los Angeles",University of Oxford,radialgan: leveraging multiple datasets to improve target-specific predictive models using generative adversarial networks.
1670,1670,196.0,University of Toronto,University of Toronto and Vector Institute,differentiable compositional kernel learning for gaussian processes.
1671,1671,197.0,"SeoulTech, Rutgers University","SeoulTech, Rutgers University",markov modulated gaussian cox processes for semi-stationary intensity modeling of events data.
1672,1672,198.0,Criteo,Facebook AI Research,improved regret bounds for thompson sampling in linear quadratic control problems.
1673,1673,199.0,Imperial College London,Imperial College London,design of experiments for model discrimination hybridising analytical and data-driven approaches.
1674,1674,200.0,Criteo,Skoltech,anonymous walk embeddings.
1675,1675,201.0,UC Irvine,UC Irvine,improving optimization in models with continuous symmetry breaking.
1676,1676,202.0,RWTH,University of Edinburgh,conditional noise-contrastive estimation of unnormalised models.
1677,1677,203.0,Facebook,Ecole des Ponts - ParisTech,canonical tensor decomposition for knowledge base completion.
1678,1678,204.0,The Ohio State University,Ohio State University,the power of interpolation:  understanding the effectiveness of sgd in modern over-parametrized learning.
1679,1679,205.0,The Chinese University of Hong Kong,CUHK,a simple stochastic variance reduced algorithm with fast convergence rates.
1680,1680,206.0,ETH Zurich,ETH Zurich,escaping saddles with stochastic gradients.
1681,1681,207.0,University of Rochester,University of Rochester,$d^2$: decentralized training over decentralized data.
1682,1682,208.0,DeepMind,DeepMind,machine theory of mind.
1683,1683,209.0,DeepMind,DeepMind,"been there, done that: meta-learning with episodic recall."
1684,1684,210.0,University of Pittsburgh,University of Pittsburgh,faster derivative-free stochastic algorithm for shared memory machines.
1685,1685,211.0,The Ohio State University,The Ohio State University,coded sparse matrix multiplication.
1686,1686,212.0,University of Cambridge / Columbia University,Columbia University,augment and reduce: stochastic inference for large categorical distributions.
1687,1687,213.0,TU Darmstadt,University of Lincoln,efficient gradient-free variational inference using policy search.
1688,1688,214.0,Google,Google Brain,fixing a broken elbo.
1689,1689,215.0,Duke University,Duke,variational inference and model selection with generalized evidence bounds.
1690,1690,216.0,TECHNICAL UNIVERSITY OF CRETE,TECHNICAL UNIVERSITY OF CRETE,the generalization error of dictionary learning with moreau envelopes.
1691,1691,217.0,Carnegie Mellon University,CMU,network global testing by counting graphlets.
1692,1692,218.0,"University of California, Berkeley","University of California, Berkeley",large-scale sparse inverse covariance estimation via thresholding and max-det matrix completion.
1693,1693,219.0,Harvard Medical School,Harvard Medical School,robust and scalable models of microbiome dynamics.
1694,1694,220.0,CNRS/UTC Heudiasyc,"CNRS, Université de technologie de Compiègne",explicit inductive bias for transfer learning with convolutional networks.
1695,1695,221.0,"Magic Leap, Inc","Magic Leap, Inc.",gradnorm: gradient normalization for adaptive loss balancing in deep multitask networks.
1696,1696,222.0,Facebook,Facebook,optimizing the latent space of generative networks.
1697,1697,223.0,Fudan University,Fudan University,theoretical analysis of image-to-image translation with adversarial learning.
1698,1698,224.0,UC Berkeley,Berkeley,soft actor-critic: off-policy maximum entropy deep reinforcement learning with a stochastic actor.
1699,1699,225.0,Okinawa Institute of Science and Technology Graduate University,Okinawa Institute of Science and Technology,pipps: flexible model-based policy search robust to the curse of chaos.
1700,1700,226.0,"Bosch Center for Artificial Intelligence, Max Planck Institute for Intelligent Systems",Max Planck Institute for Intelligent Systems,probabilistic recurrent state-space models.
1701,1701,227.0,University of Oxford,Amazon,structured variationally auto-encoded optimization.
1702,1702,228.0,MIT,MIT,a robust approach to sequential information theoretic planning.
1703,1703,229.0,"University of California, Davis",UC Berkeley,error estimation for randomized least-squares algorithms via the bootstrap.
1704,1704,230.0,Stanford University,Stanford University,distributed asynchronous optimization with unbounded delays: how slow can you go?.
1705,1705,231.0,Tencent AI Lab,Tecent AI Lab,error compensated quantized sgd and its applications to large-scale distributed optimization.
1706,1706,232.0,California Institute of technology,Caltech,low-rank riemannian optimization on positive semidefinite stochastic matrices with applications to graph clustering.
1707,1707,233.0,Max Planck Institute for Intelligent Systems,University of Tübingen,"dissecting adam: the sign, magnitude and variance of stochastic gradients."
1708,1708,234.0,(organization),Huawei Noah’s Ark Lab,discovering and removing exogenous state variables and rewards for reinforcement learning.
1709,1709,235.0,University of Cambridge and MPI Tübingen,"MPI for Intelligent Systems Tübingen, Germany",differentially private database release via kernel mean embeddings.
1710,1710,236.0,Technion,Technion,extracting automata from recurrent neural networks using queries and counterexamples.
1711,1711,237.0,"Data61, the Australian National University",The Australian National University,neural dynamic programming for musical self similarity.
1712,1712,238.0,University of Texas at Austin,UT Austin & Amazon,learning long term dependencies via fourier recurrent units.
1713,1713,239.0,Imperial College London,Hellebore Capital Limited,autoregressive convolutional neural networks for asynchronous time series.
1714,1714,240.0,EPFL,EPFL,efficient model-based deep reinforcement learning with variational state tabulation.
1715,1715,241.0,UC Berkeley,Berkeley,regret minimization for partially observable deep reinforcement learning.
1716,1716,242.0,Purdue University,Purdue University,goodness-of-fit testing for discrete distributions via stein discrepancy.
1717,1717,243.0,NEC Corporation,-,unbiased objective estimation in predictive optimization.
1718,1718,244.0,Stanford University,OpenStax / Rice University,ultra large-scale feature selection using count-sketches.
1719,1719,245.0,Johns Hopkins University,Princeton,"matrix norms in data streams: faster, multi-pass and row-order."
1720,1720,246.0,Google Brain / Cornell University,Cornell University,can deep reinforcement learning solve erdos-selfridge-spencer games?.
1721,1721,247.0,Google Brain,Berkeley,the mirage of action-dependent baselines in reinforcement learning.
1722,1722,248.0,Rensselaer Polytechnic Institute,RPI,composite marginal likelihood methods for random utility models.
1723,1723,249.0,University of Paderborn,Yahoo Research,ranking distributions based on noisy sorting.
1724,1724,250.0,"CMLA, ENS Paris-Saclay","CMLA, ENS Paris Saclay",dicod: distributed convolutional coordinate descent for convolutional sparse coding.
1725,1725,251.0,Stanford University,Stanford University,exploring hidden dimensions in accelerating convolutional neural networks.
1726,1726,252.0,University of British Columbia,University of British Columbia,deep models of interactions across sets.
1727,1727,253.0,"University of California, Irvine","University of California, Irvine",contextnet: deep learning for star galaxy classification.
1728,1728,254.0,Zalando Research,Johannes Kepler University Linz,first order generative adversarial networks.
1729,1729,255.0,Tsinghua University,Tsinghua University,max-mahalanobis linear discriminant analysis networks.
1730,1730,256.0,Purdue University,Purdue University,learning maximum-a-posteriori perturbation models for structured prediction in polynomial time.
1731,1731,257.0,Telecom Paristech,"Télécom ParisTech, Université Paris-Saclay,Paris, France",structured output learning with abstention: application to accurate opinion prediction.
1732,1732,258.0,Georgia Institute of Technology,Georgia Institute of Technology,sbeed: convergent reinforcement learning with nonlinear function approximation.
1733,1733,259.0,Google Brain,University of Alberta,smoothed action value functions for learning gaussian policies.
1734,1734,260.0,"Google, Inc.",,towards end-to-end prosody transfer for expressive speech synthesis with tacotron.
1735,1735,261.0,Google,,"style tokens: unsupervised style modeling, control and transfer in end-to-end speech synthesis."
1736,1736,262.0,UCLA,UCLA,autoprognosis: automated clinical prognostic modeling via bayesian optimization with structured kernel learning.
1737,1737,263.0,University of Oxford,University of Oxford,tapas: tricks to accelerate (encrypted) prediction as a service.
1738,1738,264.0,Cornell University,Cornell University,end-to-end learning for the deep multivariate probit model.
1739,1739,265.0,Inria Parietal,NTT,differentiable dynamic programming for structured prediction and attention.
1740,1740,266.0,EPFL,EPFL,optimal distributed learning with multi-pass stochastic gradient methods.
1741,1741,267.0,UC Berkeley,UC Berkeley,byzantine-robust distributed learning: towards optimal statistical rates.
1742,1742,268.0,"University of California, Davis","University of California, Davis",sql-rank: a listwise approach to collaborative ranking.
1743,1743,269.0,UC Davis,"University of California, Davis",extreme learning to rank via low rank assumption.
1744,1744,270.0,Georgia Tech,Georgia Institute of Technology,adversarial attack on graph structured data.
1745,1745,271.0,Google,"University of Wisconsin, Madison",reinforcing adversarial robustness using model confidence induced by adversarial training.
1746,1746,272.0,"CNRS, Toulouse",CNRS,closed-form marginal likelihood in gamma-poisson matrix factorization.
1747,1747,273.0,Weizmann Institute of Science,Yale School of Medicine,learning binary latent variable models: a tensor eigenpair approach.
1748,1748,274.0,Tsinghua University,Microsoft,thompson sampling for combinatorial semi-bandits.
1749,1749,275.0,University of Cambridge,EPFL,let’s be honest: an optimal no-regret framework for zero-sum games.
1750,1750,276.0,UNIST,KAIST,deep asymmetric multi-task feature learning.
1751,1751,277.0,Georgia Tech,Georgia Institute of Technology / Facebook AI Research,learn from your neighbor: learning multi-modal mappings from sparse annotations.
1752,1752,278.0,UT Austin,UT Austin,stein variational message passing for continuous graphical models.
1753,1753,279.0,UC Berkeley,UC Berkeley,discrete-continuous mixtures in probabilistic programming: generalized semantics and inference algorithms.
1754,1754,280.0,Peking University,Microsoft Research Asia,towards binary-valued gates for robust lstm training.
1755,1755,281.0,Facebook AI Research and Tel Aviv University,Facebook AI Research and Tel Aviv University,fitting new speakers based on a short untranscribed sample.
1756,1756,282.0,Politecnico di Milano,Politecnico di Milano,stochastic variance-reduced policy gradient.
1757,1757,283.0,MILA / FAIR,U Montreal,convergent tree backup and retrace with function approximation.
1758,1758,284.0,Boston University,Boston,alternating randomized block coordinate descent.
1759,1759,285.0,Google,Google,shampoo: preconditioned stochastic tensor optimization.
1760,1760,286.0,MIT,MIT,stochastic wasserstein barycenters.
1761,1761,287.0,Stanford University,Stanford University,accelerating natural gradient with higher-order invariance.
1762,1762,288.0,Aalto University,Aalto University,learning unknown ode models with gaussian processes.
1763,1763,289.0,Inria Sophia Antipolis,Eurecom,constraining the dynamics of deep probabilistic models.
1764,1764,290.0,Google,Google,fast decoding in sequence models using discrete latent variables.
1765,1765,291.0,Cargenie Mellon University,Carnegie Mellon University,high performance zero-memory overhead direct convolutions.
1766,1766,292.0,Columbia University,Google Research,approximate leave-one-out for fast parameter tuning in high dimensions.
1767,1767,293.0,INRIA Lille,DeepMind,improved large-scale graph learning through ridge spectral sparsification.
1768,1768,294.0,Univeristy of Toronto,Vector Institute,distilling the posterior in bayesian neural networks.
1769,1769,295.0,Columbia University,"Department of Statistics, Columbia University",scalable approximate bayesian inference for particle tracking data.
1770,1770,296.0,Yandex,Yandex,weakly consistent optimal pricing algorithms in repeated posted-price auctions with strategic buyer.
1771,1771,297.0,Cornell University,Microsoft Research,practical contextual bandits with regression oracles.
1772,1772,298.0,University of Virginia,UCLA,stochastic variance-reduced hamilton monte carlo methods.
1773,1773,299.0,Telecom ParisTech,Télécom ParisTech,asynchronous stochastic quasi-newton mcmc for non-convex optimization.
1774,1774,300.0,"University of California, Los Angeles",University of Oxford,gain: missing data imputation using generative adversarial nets.
1775,1775,301.0,Montreal Institute for Learning Algorithms,DeepMind,synthesizing programs for images using reinforced adversarial learning.
1776,1776,302.0,Skolkovo Institute Of Science And Technology,Skoltech,geometry score: a method for comparing generative adversarial networks.
1777,1777,303.0,McGill University,McGill University,addressing function approximation error in actor-critic methods.
1778,1778,304.0,Imperial College London,Imperial College,fast bellman updates for robust mdps.
1779,1779,305.0,Politecnico di Milano,Politecnico di Milano,configurable markov decision processes.
1780,1780,306.0,University of Chicago,Yale University,prediction rule reshaping.
1781,1781,307.0,The University of Melbourne,The University of Melbourne,dimensionality-driven learning with noisy labels.
1782,1782,308.0,Google,"Google, USA",learning memory access patterns.
1783,1783,309.0,EPFL,"EPFL, Switzerland",geodesic convolutional shape optimization.
1784,1784,310.0,Oregon State University,Oregon State University,visualizing and understanding atari agents.
1785,1785,311.0,UC Berkeley,"EECS Department, University of California, Berkeley","an efficient, generalized bellman update for cooperative inverse reinforcement learning."
1786,1786,312.0,Google Brain,Google Brain,is generator conditioning causally related to gan performance?.
1787,1787,313.0,The Ohio State University,Seoul National University,k-beam minimax: efficient optimization for deep adversarial learning.
1788,1788,314.0,University of Illinois at Chicago,University of Waterloo,inductive two-layer modeling with parametric bregman transfer.
1789,1789,315.0,The University of Tokyo,RIKEN / The University of Tokyo,does distributionally robust supervised learning give robust classifiers?.
1790,1790,316.0,National University of Singapore,National University of Singapore,understanding generalization and optimization performance of deep cnns.
1791,1791,317.0,Loyola Marymount University,CSULB,the multilinear structure of relu networks.
1792,1792,318.0,Harvard University,Google Research,parallel and streaming algorithms for k-core decomposition.
1793,1793,319.0,EPFL,École polytechnique fédérale de Lausanne,fast approximate spectral clustering for dynamic networks.
1794,1794,320.0,Carnegie Mellon University,CMU,gradient descent learns one-hidden-layer cnn: don't be afraid of spurious local minima.
1795,1795,321.0,Saarland University,University of Tuebingen,neural networks should be wide enough to learn disconnected decision regions.
1796,1796,322.0,University of Washington,UW,greed is still good: maximizing monotone submodular+supermodular (bp) functions.
1797,1797,323.0,Massachusetts Institute of Technology,MIT,black-box adversarial attacks with limited queries and information.
1798,1798,324.0,IBM Research,Indian Institute of Science,using inherent structures to design lean 2-layer rbms.
1799,1799,325.0,ETH Zurich,ETH Zurich,not to cry wolf: distantly supervised multitask learning in critical care.
1800,1800,326.0,Facebook AI Research,"Facebook AI Research, NYU",composable planning with attributes.
1801,1801,327.0,DeepMind,Google DeepMind,measuring abstract reasoning in neural networks.
1802,1802,328.0,Yale University,Yale,projection-free online optimization with stochastic gradient: from convexity to submodularity.
1803,1803,329.0,The Australian National University,"Data61, the Australian National University",self-bounded prediction suffix tree via approximate string matching.
1804,1804,330.0,Google,Stanford University & Google,mentornet: learning data-driven curriculum for very deep neural networks on corrupted labels.
1805,1805,331.0,"Hebrew University of Jerusalem, Israel",Hebrew University of Jerusalem,curriculum learning by transfer learning: theory and experiments with deep networks.
1806,1806,332.0,RJ Research Consulting,Tecent AI Lab,composite functional gradient learning of generative  adversarial models.
1807,1807,333.0,Bar Ilan University,Bar Ilan University,lavan: localized and visible adversarial noise.
1808,1808,334.0,Harvard,Harvard,approximation guarantees for adaptive sampling.
1809,1809,335.0,Google AI,UW,constrained interacting submodular groupings.
1810,1810,336.0,Cornell University,Cornell University,residual unfairness in fair machine learning from prejudiced data.
1811,1811,337.0,Vanderbilt University,Vanderbilt University,adversarial regression with multiple learners.
1812,1812,338.0,Stanford,Stanford,representation tradeoffs for hyperbolic embeddings.
1813,1813,339.0,Singapore University Of Technology And Design,Singapore University of Technology and Design,improving sign random projections with additional information.
1814,1814,340.0,Lancaster University,Lancaster University,"bandits with delayed, aggregated anonymous feedback."
1815,1815,341.0,Microsoft Research AI,Princeton University,make the minority great again: first-order regret bound for contextual bandits.
1816,1816,342.0,Stanford University,OpenAI / University of Edinburgh,learning policy representations in multiagent systems.
1817,1817,343.0,Vrije Universiteit Brussel,DeepMind,learning to coordinate with coordination graphs in repeated single-stage multi-agent decision problems.
1818,1818,344.0,Peking University,Peking University,beyond finite layer neural networks: bridging deep architectures and numerical differential equations.
1819,1819,345.0,Tsinghua University,Microsoft Research,compressing neural networks using the variational information bottelneck.
1820,1820,346.0,Princeton University,Princeton University,scalable bilinear pi learning using state and action features.
1821,1821,347.0,Imperial College London,Imperial College London,time limits in reinforcement learning.
1822,1822,348.0,MIT,Amazon,semi-supervised learning on data streams via temporal label propagation.
1823,1823,349.0,Princeton University,Princeton University,implicit regularization in nonconvex statistical estimation: gradient descent converges linearly for phase retrieval and matrix completion.
1824,1824,350.0,University of Virginia,University of Virginia,a fast and scalable joint estimator for integrating additional knowledge in learning multiple related sparse gaussian graphical models.
1825,1825,351.0,KAIST,KAIST,bucket renormalization for approximate inference.
1826,1826,352.0,NEC,Institute of Statistical Mathematics,kernel recursive abc: point estimation with intractable likelihood.
1827,1827,353.0,NYU,"Facebook AI Research, NYU",modeling others using oneself in multi-agent reinforcement learning.
1828,1828,354.0,University of Chicago,University of Chicago,tropical geometry of deep neural networks.
1829,1829,355.0,Stellenbosch University,Stellenbosch University,learning dynamics of linear denoising autoencoders.
1830,1830,356.0,University of Washington,University of Washington,nonparametric variable importance using an augmented neural network with multi-task learning.
1831,1831,357.0,ETH Zürich,ETH Zurich,training neural machines with trace-based supervision.
1832,1832,358.0,Oregon State University,UC Berkeley,open category detection with pac guarantees.
1833,1833,359.0,UC Berkeley,UC Berkeley,saffron: an adaptive algorithm for online control of the false discovery rate.
1834,1834,360.0,Uppsala University,Uppsala University,learning localized spatio-temporal models from streaming data.
1835,1835,361.0,University of Michigan,University of Michigan,feasible arm identification.
1836,1836,362.0,University of Florida,University of Florida,"fast maximization of non-submodular, monotonic functions on the integer lattice."
1837,1837,363.0,MIT,Yale,decentralized submodular maximization: bridging discrete and continuous settings.
1838,1838,364.0,MIT,UT Austin & Amazon,towards fast computation of certified robustness for relu networks.
1839,1839,365.0,Stony Brook University,Stony Brook University,a two-step computation of the exact gan wasserstein distance.
1840,1840,366.0,Warwick University,University of Warwick,spatio-temporal bayesian on-line changepoint detection with model selection.
1841,1841,367.0,The University of Iowa,The University of Iowa,fast stochastic auc maximization with $o(1/n)$-convergence rate.
1842,1842,368.0,Stanford University,Stanford University,accurate uncertainties for deep learning using calibrated regression.
1843,1843,369.0,MILA,University of Montreal,neural autoregressive flows.
1844,1844,370.0,University of Oxford,University of Birmingham,probabilistic boolean tensor decomposition.
1845,1845,371.0,University of Virginia,UCLA,a primal-dual analysis of global optimality in nonconvex low-rank matrix recovery.
1846,1846,372.0,King Abdullah University of Science & Technology (KAUST),Univ. Grenoble Alpes,a delay-tolerant proximal-gradient algorithm for distributed learning.
1847,1847,373.0,National Research University Higher School of Economics,"King Abdullah University of Science and Technology (KAUST) - University of Edinburgh, Scotland",randomized block cubic newton method.
1848,1848,374.0,Indiana University,INDIANA UNIVERSITY,massively parallel algorithms and hardness for single-linkage clustering under $\ell_p$ distances.
1849,1849,375.0,Stanford University,,local density estimation in high dimensions.
1850,1850,376.0,Ohio State University,,to understand deep learning we need to understand kernel learning.
1851,1851,377.0,King's College London,The University of Nottingham,learning in reproducing kernel kreı̆n spaces.
1852,1852,378.0,The University of Tokyo / RIKEN,The University of Tokyo / RIKEN,functional gradient boosting based on residual network perception.
1853,1853,379.0,University of Texas at Austin,Carnegie Mellon University,"binary classification with karmic, threshold-quasi-concave metrics."
1854,1854,380.0,Toyota Technological Institute at Chicago,Toyota Technological Institute at Chicago,characterizing implicit bias in terms of optimization geometry.
1855,1855,381.0,Rice University,OpenStax / Rice University,prdeep: robust phase retrieval with a flexible deep network.
1856,1856,382.0,Duke University,Duke University,adversarial time-to-event modeling.
1857,1857,383.0,Yale University,Yale University,magan: aligning biological manifolds.
1858,1858,384.0,Stanford University,Weizmann Institute of Science,multicalibration: calibration for the (computationally-identifiable) masses.
1859,1859,385.0,University of Michigan,"University of Michigan, Ann Arbor",improving the privacy and accuracy of admm-based distributed algorithms.
1860,1860,386.0,covariant.ai,OpenAI / UC Berkeley,pixelsnail: an improved autoregressive generative model.
1861,1861,387.0,"MILA, University of Montreal",École Polytechnique de Montréal,focused hierarchical rnns for conditional sequence processing.
1862,1862,388.0,Aalto University & NVIDIA,NVIDIA,noise2noise: learning image restoration without clean data.
1863,1863,389.0,Uber ATG / University of Toronto,University of Toronto,learning to reweight examples for robust deep learning.
1864,1864,390.0,Brown University,Brown University,policy and value transfer in lifelong reinforcement learning.
1865,1865,391.0,Inria,Inria,gep-pg: decoupling exploration and exploitation in deep reinforcement learning algorithms.
1866,1866,392.0,Google Brain,Google Brain,a hierarchical latent vector model for learning long-term structure in music.
1867,1867,393.0,UIUC,UIUC,understanding the loss surface of neural networks for binary classification.
1868,1868,394.0,Google research,Google Brain,dynamical isometry and a mean field theory of rnns: gating enables signal propagation in recurrent neural networks.
1869,1869,395.0,University of Toronto,Vector Institute,reviving and improving recurrent back-propagation.
1870,1870,396.0,The University of Electro-Communications,Microsoft,riemannian stochastic recursive gradient algorithm with retraction and vector transport and its convergence analysis.
1871,1871,397.0,"University of California, Riverside","University of California, Riverside",learning compact neural networks with regularization.
1872,1872,398.0,"University of California, Berkeley",UC Berkeley,investigating human priors for playing video games.
1873,1873,399.0,University of Massachusetts Amherst,Stanford University,decoupling gradient-like learning rules from representations.
1874,1874,400.0,The University of Queensland,University of Queensland,invariance of weight distributions in rectified mlps.
1875,1875,401.0, Princeton University and Institute for Advanced Study,Princeton University,stronger generalization bounds for deep nets via a compression approach.
1876,1876,402.0,Fudan University,Fudan University,near optimal frequent directions for sketching dense and sparse matrices.
1877,1877,403.0,Carnegie Mellon University,Carnegie Mellon University,loss decomposition for fast learning in large output spaces.
1878,1878,404.0,University at Albany,"University at Albany, State University of New York",stochastic proximal algorithms for auc maximization.
1879,1879,405.0,University of Pennsylvania,University of Pennsylvania,accelerated spectral ranking.
1880,1880,406.0,TU Munich,Siemens AG,decomposition of uncertainty in bayesian deep learning for efficient and risk-sensitive learning.
1881,1881,407.0,RIKEN,"MIT, IBM",fast and scalable bayesian deep learning by weight-perturbation in adam.
1882,1882,408.0,University of Texas at Austin,UCLA,learning one convolutional layer with overlapping patches.
1883,1883,409.0,Rice University,OpenStax / Rice University,a spline theory of deep learning.
1884,1884,410.0,IBM Research,Harvard University,structured variational learning of bayesian neural networks with horseshoe priors.
1885,1885,411.0,University of Cambridge,University of Cambridge & Uber,variational bayesian dropout: pitfalls and fixes.
1886,1886,412.0,South China University of Technology,South China University of Technology,adversarial learning with local coordinate coding.
1887,1887,413.0,Stanford,Stanford University,learning representations and generative models for 3d point clouds.
1888,1888,414.0,KTH / EA SEED,KTH Royal Institute of Technology,bayesian uncertainty estimation for batch normalized deep networks.
1889,1889,415.0,University of Toronto,University of Toronto and Vector Institute,noisy natural gradient as variational inference.
1890,1890,416.0,University of Oxford,University of Oxford,deep variational reinforcement learning for pomdps.
1891,1891,417.0,Carnegie Mellon University,Carnegie Mellon University,recurrent predictive state policy networks.
1892,1892,418.0,DeepMind,DeepMind,the mechanics of n-player differentiable games.
1893,1893,419.0,Yonsei univ.,Yonsei University,improved training of generative adversarial networks using representative features.
1894,1894,420.0,Pontifícia Universidade Catolica do Rio Grande do Sul - PUCRS,PUCRS,hierarchical multi-label classification networks.
1895,1895,421.0,Idiap,Idiap research institute,knowledge transfer with jacobian matching.
1896,1896,422.0,Georgia Tech,Georgia Institute of Technology,towards black-box iterative machine teaching.
1897,1897,423.0,Amazon Research,UC Santa Barbara,improving the gaussian mechanism for differential privacy: analytical calibration and optimal denoising.
1898,1898,424.0,Politecnico di Milano,Politecnico di Milano,importance weighted transfer of samples in reinforcement learning.
1899,1899,425.0,Technion,Technion,beyond the one-step greedy approach in reinforcement learning.
1900,1900,426.0,University of Oxford,U Oxford,"optimization, fast and slow: optimally switching between local and bayesian optimization."
1901,1901,427.0,Fudan University,Fudan University,batch bayesian optimization via multi-objective acquisition ensemble for automated analog circuit design.
1902,1902,428.0,University of Toronto,Tecent AI Lab,graphical nonconvex optimization via an adaptive convex relaxation.
1903,1903,429.0,Columbia University,Columbia,approximate message passing for amplitude based optimization.
1904,1904,430.0,University of California Berkeley,"University of California, Berkeley",delayed impact of fair machine learning.
1905,1905,431.0,Max Planck Institute for Intelligent Systems,"MPI for Intelligent Systems Tübingen, Germany",tempered adversarial networks.
1906,1906,432.0,University of Oxford,Oxford,fast information-theoretic bayesian optimisation.
1907,1907,433.0,National University of Singapore,National University of Singapore,tight regret bounds for bayesian optimization in one dimension.
1908,1908,434.0,Google,Google,image transformer.
1909,1909,435.0,ETH Zurich and University of Zurich,University of Zurich,kernelized synaptic weight matrices.
1910,1910,436.0,IBM Research,EPFL,a distributed second-order algorithm you can trust.
1911,1911,437.0,,Boston,on acceleration with noise-corrupted gradients.
1912,1912,438.0,California Institute of Technology,Tel-Aviv University,gradient coding from cyclic mds codes and expander graphs.
1913,1913,439.0,MIT,Google Research,accelerating greedy coordinate descent methods.
1914,1914,440.0,Yandex,University of Amsterdam,finding influential training samples for gradient boosted decision trees.
1915,1915,441.0,University of Alberta,University of Alberta,improving regression performance with distributional losses.
1916,1916,442.0,University of Oxford,University of Oxford,qmix: monotonic value function factorisation for deep multi-agent reinforcement learning.
1917,1917,443.0,INRIA,INRIA,learning to act in decentralized partially observable mdps.
1918,1918,444.0,University of Cambridge,University of Cambridge,local convergence properties of saga/prox-svrg and acceleration.
1919,1919,445.0,University of Technology Sydney,Newcastle University,stein points.
1920,1920,446.0,PROWLER.io,PROWLER.io,large-scale cox process inference using variational fourier features.
1921,1921,447.0,University of Science and Technology of China,The University of Iowa,sadagrad: strongly adaptive stochastic gradient methods.
1922,1922,448.0,University of Minnesota,University of Southern California,gradient primal-dual algorithm converges to second-order stationary solution for  nonconvex distributed optimization over networks.
1923,1923,449.0,Northwestern University,Intel Corporation,a progressive batching l-bfgs method for machine learning.
1924,1924,450.0,National University of Singapore,Qihoo/360,wsnet: compact and efficient networks through weight sampling.
1925,1925,451.0,University of Cambridge,Univ of Toronto | Toronto,entropy-sgd optimizes the prior of a pac-bayes bound: generalization properties of entropy-sgd and data-dependent priors.
1926,1926,452.0,University of Cambridge / The Alan Turing Institute,,"high-quality prediction intervals for deep learning: a distribution-free, ensembled approach."
1927,1927,453.0,Cornell University,Google,competitive caching with machine learned advice.
1928,1928,454.0,Google,Google,approximation algorithms for cascading prediction models.
1929,1929,455.0,MIT,Microsoft Research,orthogonal machine learning: power and limitations.
1930,1930,456.0,NEC Corporation,National Institute of Informatics,causal bandits with propagating inference.
1931,1931,457.0,DeepMind,DeepMind,mix & match - agent curricula for reinforcement learning.
1932,1932,458.0,DeepMind,Google Deepmind,the uncertainty bellman equation and exploration.
1933,1933,459.0,Caltech,Microsoft Research,hierarchical imitation and reinforcement learning.
1934,1934,460.0,National University of Singapore,National University of Singapore,policy optimization with demonstrations.
1935,1935,461.0,Delft University of Technology,Delft University of Technology,fast gradient-based methods with exponential rate: a hybrid control framework.
1936,1936,462.0,Univ Iowa,The University of Iowa,level-set methods for finite-sum constrained convex optimization.
1937,1937,463.0,Rice University,"Rice University, Baylor College of Medicine",a theoretical explanation for perplexing behaviors of backpropagation-based visualizations.
1938,1938,464.0,IBM Watson,IBM Watson,a boo(n) for evaluating architecture performance.
1939,1939,465.0,"University of California, Berkeley",UC Berkeley,rllib: abstractions for distributed reinforcement learning.
1940,1940,466.0,University of Washington,,global convergence of policy gradient methods for the linear quadratic regulator.
1941,1941,467.0,Princeton University,Northwestern U,the edge density barrier: computational-statistical tradeoffs in combinatorial inference.
1942,1942,468.0,"University of California, Los Angeles","University of California, Los Angeles",sound abstraction and decomposition of probabilistic programs.
1943,1943,469.0,Google Deepmind,Deepmind,parallel wavenet: fast high-fidelity speech synthesis.
1944,1944,470.0,Stanford University,Stanford University,modeling sparse deviations for compressed sensing using generative models.
1945,1945,471.0,Technion,Technion,revealing common statistical behaviors in heterogeneous populations.
1946,1946,472.0,Wichita State University,Wichita State University,improved nearest neighbor search using auxiliary information and priority functions.
1947,1947,473.0,IIT Bombay,IIT Bombay,trainable calibration measures for neural networks from kernel mean embeddings.
1948,1948,474.0,Politecnico di Milano,,quanttree: histograms for change detection in multivariate data streams.
1949,1949,475.0,Purdue University,Purdue University,"an iterative, sketching-based framework for ridge regression."
1950,1950,476.0,"Institute of Software, Chinese Academy of Sciences",Northwestern University,learning low-dimensional temporal representations.
1951,1951,477.0,Microsoft Research,Microsoft Research,rapid adaptation with conditionally shifted neurons.
1952,1952,478.0,Peking University,Peking University,pde-net: learning pdes from data.
1953,1953,479.0,Johns Hopkins University,Johns Hopkins University,theoretical analysis of sparse subspace clustering with missing entries.
1954,1954,480.0,BAE Systems FAST Labs,BAE Systems FAST Labs,topological mixture estimation.
1955,1955,481.0,MPI - ETH,EPFL,on matching pursuit and coordinate descent.
1956,1956,482.0,INRIA,"CNRS, Ecole Normale Superieure",frank-wolfe with subsampling oracle.
1957,1957,483.0,University of Alberta,Mitsubishi Electric Research Labs,reinforcement learning with function-valued action spaces for partial differential equation control.
1958,1958,484.0,University of Oxford,University of Oxford,fourier policy gradients.
1959,1959,485.0,UC Berkeley,MILA,adaptive three operator splitting.
1960,1960,486.0,EPFL,EPFL,a conditional gradient framework for composite convex minimization with applications to semidefinite programming.
1961,1961,487.0,Sun Yat-sen University,Sun Yat-sen University,learning semantic representations for unsupervised domain adaptation.
1962,1962,488.0,University of Toronto,Vector Institute,learning adversarially fair and transferable representations.
1963,1963,489.0,Weizmann Institute of Science,Weizmann Institute of Science,spurious local minima are common in two-layer relu neural networks.
1964,1964,490.0,Seoul National University,Seoul National University,efficient end-to-end learning for quantizable representations.
1965,1965,491.0,Indian Institute of Technology Hyderabad,IIT Hyderabad,solving partial assignment problems using random clique complexes.
1966,1966,492.0,UCLA,UCLA,generalized earley parser: bridging symbolic grammars and sequence data for future prediction.
1967,1967,493.0,University Of California Berkeley,University of California at Berkeley,convergence guarantees for a class of non-convex and   non-smooth optimization problems.
1968,1968,494.0,Princeton Univerisity,University of Wisconsin-Madison,estimation of markov chain via rank-constrained likelihood.
1969,1969,495.0,INRIA,University of Washington,efficient first-order algorithms for adaptive signal denoising.
1970,1970,496.0,"University of California, Los Angeles",UCLA,continuous and discrete-time accelerated stochastic mirror descent for strongly convex functions.
1971,1971,497.0,Columbia University,Columbia University,noisin: unbiased regularization for recurrent neural networks.
1972,1972,498.0,University of Southern California,University of Southern California,hierarchical deep generative models for multi-rate multivariate time series.
1973,1973,499.0,Microsoft Research Cambridge,UC Irvine,disentangled sequential autoencoder.
1974,1974,500.0,New York University,Facebook / NYU,stochastic video generation with a learned prior.
1975,1975,501.0,MILA,University of Montreal,mutual information neural estimation.
1976,1976,502.0,NYU / Facebook AI Research,New York University,adversarially regularized autoencoders.
1977,1977,503.0,Duke University,Duke,policy optimization as wasserstein gradient flows.
1978,1978,504.0,University of Michigan,Google / U. Michigan,self-imitation learning.
1979,1979,505.0,EPFL,École polytechnique fédérale de Lausanne,spectrally approximating large graphs with smaller graphs.
1980,1980,506.0,"L2S, CentraleSupelec",CentralSupélec,on the spectrum of random features maps of high dimensional data.
1981,1981,507.0,"InfiniaML, Inc.",Georgia Institute of Technology,learning registered point processes from idiosyncratic observations.
1982,1982,508.0,Columbia University,Columbia University,deep bayesian nonparametric tracking.
1983,1983,509.0,Two Sigma Investments,Two Sigma Investments,learning and memorization.
1984,1984,510.0,University of Amsterdam,University of Amsterdam,attention-based deep multiple instance learning.
1985,1985,511.0,The University of Tokyo / RIKEN,RIKEN / The University of Tokyo,classification from pairwise similarity and unlabeled data.
1986,1986,512.0,UCSD,University of California at San Diego,analyzing the robustness of nearest neighbors to adversarial examples.
1987,1987,513.0,Johns Hopkins University,Johns Hopkins University,on the implicit bias of dropout.
1988,1988,514.0,Stanford University,stanford university,convolutional imputation of matrix networks.
1989,1989,515.0,Carnegie Mellon University,Amazon,detecting and correcting for label shift with black box predictors.
1990,1990,516.0,Carnegie Mellon University,Petuum Inc. and CMU,orthogonality-promoting distance metric learning: convex relaxation and theoretical analysis.
1991,1991,517.0,University of Tübingen,University of Tübingen,comparison-based random forests.
1992,1992,518.0,Télécom ParisTech,Télécom ParisTech,a probabilistic theory of supervised similarity learning for pointwise roc curve optimization.
1993,1993,519.0,Cornell University,Rugters University,provable variable selection for streaming features.
1994,1994,520.0,University of Michigan,Johns Hopkins University,out-of-sample extension of graph adjacency spectral embedding.
1995,1995,521.0,Boston University,Boston University,gradient descent for sparse rank-one matrix completion for crowd-sourced aggregation of sparsely interacting workers.
1996,1996,522.0,University of Virginia,UCLA,fast and sample efficient inductive matrix completion via multi-phase procrustes flow.
1997,1997,523.0,Duke University,Duke University,dcfnet: deep neural network with decomposed convolutional filters.
1998,1998,524.0,Saarland University,University of Tuebingen,optimization landscape and expressivity of deep cnns.
1999,1999,525.0,University of Toronto,University of Toronto,scalable gaussian processes with grid-structured eigenfunctions (gp-grief).
2000,2000,526.0,University of Massachusetts Amherst,University of Massachusetts Amherst,learning in integer latent variable models with nested automatic differentiation.
2001,2001,527.0,UC Berkeley and Georgia Tech,University of California at Berkeley,cycada: cycle-consistent adversarial domain adaptation.
2002,2002,528.0,Nanjing University,Nanjing University,rectify heterogeneous models with semantic mapping.
2003,2003,529.0,"Quadrant.ai, D-Wave",D-Wave,dvae++: discrete variational autoencoders with overlapping transformations.
2004,2004,530.0,Caltech,UC Irvine,iterative amortized inference.
2005,2005,531.0,MPI Tübingen & Cambridge,"University of Cambridge, Alan Turing Institute",blind justice: fairness with encrypted sensitive attributes.
2006,2006,532.0,University of California San Diego,University of California San Diego,active learning with logged data.
2007,2007,533.0,Microsoft Research,Microsoft Research,a reductions approach to fair classification.
2008,2008,534.0,University of Pennsylvania,Microsoft Research,preventing fairness gerrymandering: auditing and learning for subgroup fairness.
2009,2009,535.0,KTH Royal Institute of Technology,KTH Royal Institute of Technology,bayesian model selection for change point detection and clustering.
2010,2010,536.0,Microsoft,Microsoft,a unified framework for structured low-rank matrix learning.
2011,2011,537.0,University of Washington,University of Washington,firing bandits: optimizing crowdfunding.
2012,2012,538.0,University of Texas at Austin,University of Texas at Austin,multi-fidelity black-box optimization with hierarchical partitions.
2013,2013,539.0,"CRIL UMR CNRS 8188, Univ. Artois","CRIL UMR CNRS 8188, Univ. Artois",compiling combinatorial prediction games.
2014,2014,540.0,Duke University,Duke University,rates of convergence of spectral methods for graphon estimation.
2015,2015,541.0,Massachusetts Institute of Technology,Massachusetts Institute of Technology,characterizing and learning equivalence classes of causal dags under interventions.
2016,2016,542.0,MIT,MIT,minimal i-map mcmc for scalable structure discovery in causal dag models.
2017,2017,543.0,ETH Zurich,Caltech,strassennets: deep learning with a multiplication budget.
2018,2018,544.0,Pohang University of Science and Techonology,POSTECH,gradient-based meta-learning with learned layerwise metric and subspace.
2019,2019,545.0,Tencent AI Lab,Tecent AI Lab,candidates vs. noises estimation for large multi-class classification problem.
2020,2020,546.0,Orange Labs,LS2N,"craftml, an efficient clustering-based random forest for extreme multi-label learning."
2021,2021,547.0,"Telefónica Research, Barcelona",Telefonica,overcoming catastrophic forgetting with hard attention to the task.
2022,2022,548.0,Texas A&M University,Rice University,deep k-means: re-training and parameter sharing with harder cluster assignments for compressing deep convolutions.
2023,2023,549.0,Google Brain Amsterdam,DeepMind,efficient neural audio synthesis.
2024,2024,550.0,University of Southern California,Amazon,born again neural networks.
2025,2025,551.0,Stanford University,Google,adaptive sampled softmax with kernel based sampling.
2026,2026,552.0,Duke,Duke,jointgan: multi-domain joint distribution learning with generative adversarial nets.
2027,2027,553.0,DeepMind,DeepMind,autoregressive quantile networks for generative modeling.
2028,2028,554.0,Carnegie Mellon University,University of Southern California,on the power of over-parametrization in neural networks with quadratic activation.
2029,2029,555.0,MIT,UC Berkeley,on the limitations of first-order approximation in gan dynamics.
2030,2030,556.0,"Baidu Research, USA",UIUC,learning to explore via meta-policy gradient.
2031,2031,557.0,University College London,UCL,mean field multi-agent reinforcement learning.
2032,2032,558.0,Google Inc.,Google,online linear quadratic control.
2033,2033,559.0,Google Research,D. E. Shaw & Co.,online learning with abstention.
2034,2034,560.0,INRIA,Inria,celer: a fast solver for the lasso with dual extrapolation.
2035,2035,561.0,LIVE (CNRS),IGN,cut-pursuit algorithm for regularizing nonsmooth functionals with graph total variation.
2036,2036,562.0,Element AI,University of Montreal,augmented cyclegan: learning many-to-many mappings from unpaired data.
2037,2037,563.0,Inria,INRIA,mixed batches and symmetric discriminators for gan training.
2038,2038,564.0,Tencent AI Lab,Tecent AI Lab,an algorithmic framework of variable metric over-relaxed hybrid proximal extra-gradient method.
2039,2039,565.0,University of Minnesota,University of Virginia,learning hidden markov models from pairwise co-occurrences with application to topic modeling.
2040,2040,566.0,University of Wisconsin-Madison,ECE at University of Wisconsin-Madison,draco: byzantine-resilient distributed training via redundant gradients.
2041,2041,567.0,Princeton University,,communication-computation efficient gradient coding.
2042,2042,568.0,University of Illinois Urbana-Champaign,University of Illinois UC,"submodular hypergraphs: p-laplacians, cheeger inequalities and spectral clustering."
2043,2043,569.0,University of Texas at Austin,Tsinghua University,smac: simultaneous mapping and clustering using spectral decompositions.
2044,2044,570.0,University of Oxford,University of Oxford,on nesting monte carlo estimators.
2045,2045,571.0,Dartmouth College,UT Austin,stein variational gradient descent without gradient.
2046,2046,572.0,Amazon Research Tübingen,"MPI for Intelligent Systems Tübingen, Germany",detecting non-causal artifacts in multivariate linear regression models.
2047,2047,573.0,Université catholique de Louvain,Université catholique de Louvain,the hierarchical adaptive forgetting variational filter.
2048,2048,574.0,MIT Computer Science and Artificial Intelligence Laboratory,MIT,junction tree variational autoencoder for molecular graph generation.
2049,2049,575.0,Harvard University,Harvard University,semi-amortized variational autoencoders.
2050,2050,576.0,Twitter,"University of California, Davis",adaptive exploration-exploitation tradeoff for opportunistic bandits.
2051,2051,577.0,Microsoft Research,Microsoft Research,semiparametric contextual bandits.
2052,2052,578.0,Google,Google,interpretability beyond feature attribution: quantitative testing with concept activation vectors (tcav).
2053,2053,579.0,Harvard University,Harvard University,weightless: lossy weight encoding for deep neural network compression.
2054,2054,580.0,IBM Research,IBM Research,parallel bayesian network structure learning.
2055,2055,581.0,UW-Madison; Princeton University,"University of Wisconsin, Madison",temporal poisson square root graphical models.
2056,2056,582.0,THE PENNSYLVANIA STATE UNIVERSITY,penn state university,minimax concave penalized multi-armed bandit model with high-dimensional covariates.
2057,2057,583.0,Nanjing University,Nanjing University,dynamic regret of strongly adaptive methods.
2058,2058,584.0,University of Utah,University of Utah,distributed clustering via lsh based data partitioning.
2059,2059,585.0,Carnegie Mellon University,Carnegie Mellon University,learning to branch.
2060,2060,586.0,Cornell,Stanford university,minibatch gibbs sampling on large graphical models.
2061,2061,587.0,UC Berkeley,UC Berkeley,on the theory of variance reduction for stochastic gradient monte carlo.
2062,2062,588.0,University of Toronto,University of Toronto,using reward machines for high-level task specification and decomposition in reinforcement learning.
2063,2063,589.0,New York University,Facebook Artificial Intelligence Research,generalization without systematicity: on the compositional skills of sequence-to-sequence recurrent networks.
2064,2064,590.0,Uber AI Labs,Uber AI Labs,pathwise derivatives beyond the reparameterization trick.
2065,2065,591.0,Tsinghua University,Tsinghua University,message passing stein variational gradient descent.
2066,2066,592.0,Philips Research,Aalto University,state space gaussian processes with non-gaussian likelihood.
2067,2067,593.0,Cornell University,Cornell University,constant-time predictive distributions for gaussian processes.
2068,2068,594.0,UC Berkeley,Google,gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks.
2069,2069,595.0,The University of Chicago,Toyota Technological Institute,on the generalization of equivariance and convolution in neural networks to the action of compact groups.
2070,2070,596.0,Tsinghua University,Tsinghua University,racing thompson: an efficient algorithm for thompson sampling with non-conjugate priors.
2071,2071,597.0,Weizmann Institute of Science,Weizmann Institute of Science,probably approximately metric-fair learning.
2072,2072,598.0,University of Southern California,Univ. of Southern California,neural program synthesis from diverse demonstration videos.
2073,2073,599.0,Seoul National University,Microsoft AI & Research,video prediction with appearance and motion conditions.
2074,2074,600.0,Columbia University,Columbia University,crvi: convex relaxation for variational inference.
2075,2075,601.0,MIT,MIT,bayesian coreset construction via greedy iterative geodesic ascent.
2076,2076,602.0,Carnegie Mellon University,Uber/CMU,transformation autoregressive networks.
2077,2077,603.0,Indian Institute of Technology,Max Planck Institute for Intelligent Systems,learning equations for extrapolation and control.
2078,2078,604.0,Facebook,Facebook AI Research,analyzing uncertainty in neural machine translation.
2079,2079,605.0,Facebook AI Research,Facebook,hierarchical text generation and planning for strategic dialogue.
2080,2080,606.0,UIUC,Purdue,budgeted experiment design for causal structure learning.
2081,2081,607.0,Massachusetts Institute of Technology,MICROSOFT,accurate inference for adaptive linear models.
2082,2082,608.0,Shanghai Jiao Tong University,Shanghai Jiao Tong University,path-level network transformation for efficient architecture search.
2083,2083,609.0,DeepMind,DeepMind,progress & compress: a scalable framework for continual learning.
2084,2084,610.0,Google Brain,Google Brain,learning longer-term dependencies in rnns with auxiliary losses.
2085,2085,611.0,Google,Google Brain,understanding and simplifying one-shot architecture search.
2086,2086,612.0,University of Illinois at Urbana-Champaign (UIUC),University of Illinois at Urbana-Champaign,fully decentralized multi-agent reinforcement learning with networked agents.
2087,2087,613.0,Brown University,Brown University,state abstractions for lifelong reinforcement learning.
2088,2088,614.0,Carnegie Mellon University,University of Utah,bounding and counting linear regions of deep neural networks.
2089,2089,615.0,"Preferred Networks, Inc.","Preferred Networks, Inc.",clipped action policy gradient.
2090,2090,616.0,Google Brain Amsterdam,DeepMind,impala: scalable distributed deep-rl with importance weighted actor-learner architectures.
2091,2091,617.0,"FIT, Monash University",University of Texas at Austin,inter and intra topic structure learning with word embeddings.
2092,2092,618.0,University of Washington,University of Washington,oi-vae: output interpretable vaes for nonlinear group factor analysis.
2093,2093,619.0,EPFL,EPFL,the hidden vulnerability of distributed learning in byzantium.
2094,2094,620.0,EPFL,EPFL,asynchronous byzantine machine learning (the case of sgd).
2095,2095,0.0,Technion,Technion,selectivenet: a deep neural network with an integrated reject option.
2096,2096,1.0,Aalto University,Mila / U. Montreal,manifold mixup: better representations by interpolating hidden states.
2097,2097,2.0,Idiap & EPFL,Idiap research institute,processing megapixel images with deep attention-sampling models.
2098,2098,3.0,Korea Advanced Institute of Science and Technology (KAIST),KAIST,tapnet: neural network augmented with task-adaptive projection for few-shot learning.
2099,2099,4.0,"Stanford, Google, UC Berkeley",UC Berkeley,online meta-learning.
2100,2100,5.0,Kongsberg Seatex,None,training neural networks with local error signals.
2101,2101,6.0,MILA,HEC Montreal & MILA,gmnn: graph markov neural networks.
2102,2102,7.0,Korea University,Korea University,self-attention graph pooling.
2103,2103,8.0,Los Alamos National Laboratory & University of Washington,Los Alamos National Laboratory,combating label noise in deep learning using abstention.
2104,2104,9.0,"Institute of Automation, Chinese Academy of Sciences","Institute of Automation, Chinese Academy of Sciences",lgm-net: learning to generate matching networks for few-shot learning.
2105,2105,10.0,Google,Google Brain,self-attention generative adversarial networks.
2106,2106,11.0,Sun Yat-sen University,Sun Yat-sen University,multivariate-information adversarial ensemble for scalable joint distribution matching.
2107,2107,12.0,Google Brain,Google Brain,high-fidelity image generation with fewer labels.
2108,2108,13.0,CNRS GREYC UMR 6072,Unicaen,revisiting precision recall definition for generative modeling.
2109,2109,14.0,UCLA,UCLA,wasserstein of wasserstein loss for learning generative models.
2110,2110,15.0,TU Munich,TU Munich,flat metric minimization with applications in generative modeling.
2111,2111,16.0,University of Maryland,University of Maryland,entropic gans meet vaes: a statistical approach to compute sample likelihoods in gans.
2112,2112,17.0,Arizona State University,Intel Corporation,non-parametric priors for generative adversarial networks.
2113,2113,18.0,Shanghai Jiao Tong University,Peking University,lipschitz generative adversarial nets.
2114,2114,19.0,Seoul National University,Seoul National University,hexagan: generative adversarial nets for real world classification.
2115,2115,20.0,DeepMind,DeepMind,graph matching networks for learning the similarity of graph structured objects.
2116,2116,21.0,Delft University of Technology,TUDelft,bayesnas: a bayesian approach for neural architecture search.
2117,2117,22.0,AITRICS,Oxford and DeepMind,set transformer: a framework for attention-based permutation-invariant neural networks.
2118,2118,23.0,"University of Maryland, College Park",University of Maryland,shallow-deep networks: understanding and mitigating network overthinking.
2119,2119,24.0,Texas A&M University,Texas A&M University,graph u-nets.
2120,2120,25.0,Carnegie Mellon University,Carnegie Mellon University / Bosch Center for AI,satnet: bridging deep learning and logical reasoning using a differentiable satisfiability solver.
2121,2121,26.0,Google Research,Google Research,area attention.
2122,2122,27.0,Google Brain,Google Brain,the evolved transformer.
2123,2123,28.0,"""University of Washington, Seattle""",UW,jumpout : improved dropout for deep neural networks with relus.
2124,2124,29.0,Ecole normale supérieure,ENSAE / CREST,stochastic deep networks.
2125,2125,30.0,Facebook AI Research,Facebook AI Research,elf opengo: an analysis and open reimplementation of alphazero.
2126,2126,31.0,Univ. Paris-Sud,Facebook Artificial Intelligence Research,making deep q-learning methods robust to time discretization.
2127,2127,32.0,Ant Financial Service Group,Georgia Tech,nonlinear distributional gradient temporal-difference learning.
2128,2128,33.0,DeepMind,DeepMind,composing entropic policies using divergence correction.
2129,2129,34.0,University of Cambridge,"University of Cambridge, Alan Turing Institute",tibgm: a transferable and information-based graphical model approach for reinforcement learning.
2130,2130,35.0,Stanford University,Stanford University,multi-agent adversarial inverse reinforcement learning.
2131,2131,36.0,Imperial College London,Imperial College London,policy consolidation for continual reinforcement learning.
2132,2132,37.0,McGill University,McGill University / DeepMind,off-policy deep reinforcement learning without exploration.
2133,2133,38.0,Imperial College London,Imperial College London,random expert distillation: imitation learning via expert policy support estimation.
2134,2134,39.0,Baidu Research,Duke University,revisiting the softmax bellman operator: new benefits and new perspective.
2135,2135,40.0,Google DeepMind,Google DeepMind,an investigation of model-free planning.
2136,2136,41.0,Inria,UPMC,curious: intrinsically motivated modular multi-goal reinforcement learning.
2137,2137,42.0,MIT,Princeton,task-agnostic dynamics priors for deep reinforcement learning.
2138,2138,43.0,"University of California, Berkeley",UC Berkeley,diagnosing bottlenecks in deep q-learning algorithms.
2139,2139,44.0,Intel AI,Oregon State University US,collaborative evolutionary reinforcement learning.
2140,2140,45.0,Seoul National University,Seoul National University,emi: exploration with mutual information.
2141,2141,46.0,National Taiwan University / RIKEN,RIKEN / The University of Tokyo,imitation learning from imperfect demonstration.
2142,2142,47.0,NALBI Inc.,Seoul National University,curiosity-bottleneck: exploration by distilling task-specific novelty .
2143,2143,48.0,Université Libre de Bruxelles,Vrije Universiteit Brussel,dynamic weights in multi-objective deep reinforcement learning.
2144,2144,49.0,University of Oxford,University of Oxford,fingerprint policy optimisation for robust reinforcement learning.
2145,2145,50.0,Stanford University,Google Inc,an investigation into neural net optimization via hessian eigenvalue density.
2146,2146,51.0,Peking Unversity,Peking University,differentiable linearized admm.
2147,2147,52.0,University of Tsukuba / RIKEN AIP,Shinshu University,adaptive stochastic natural gradient method for one-shot neural architecture search.
2148,2148,53.0,National University of Singapore,National University of Singapore,a quantitative analysis of the effect of batch normalization on gradient descent.
2149,2149,54.0,Google Brain,DeepMind,the effect of network width on stochastic gradient descent and generalization: an empirical study.
2150,2150,55.0,University of Texas,Facebook,adagrad stepsizes: sharp convergence over nonconvex landscapes.
2151,2151,56.0,New York University,IBM Research,beyond backprop: online alternating minimization with auxiliary variables.
2152,2152,57.0,Cornell University,Cornell,swalp : stochastic weight averaging in low precision training.
2153,2153,58.0,Princeton University,Princeton University,efficient optimization of loops and limits with randomized telescoping sums.
2154,2154,59.0,Google & Tel Aviv University,Google,self-similar epochs: value in arrangement.
2155,2155,60.0,Technical University of Munich,Technical University of Munich,adversarial attacks on node embeddings via graph poisoning.
2156,2156,61.0,Max-Planck-Institute for Intelligent Systems,Facebook AI Research,first-order adversarial vulnerability of neural networks and input dimension.
2157,2157,62.0,EPFL,EPFL,on certifying non-uniform bounds against adversarial attacks.
2158,2158,63.0,Tsinghua University,Tsinghua University,improving adversarial robustness via promoting ensemble diversity.
2159,2159,64.0,Carnegie Mellon University,Carnegie Mellon University / Bosch Center for AI,adversarial camera stickers: a physical camera-based attack on deep learning systems.
2160,2160,65.0,Microsoft Research,Microsoft Research Redmond,adversarial examples from computational constraints.
2161,2161,66.0,The University of Hong Kong,The Chinese University of Hong Kong,popqorn: quantifying robustness of recurrent neural networks.
2162,2162,67.0,UC Berkeley,University of Chicago,using pre-training can improve model robustness and uncertainty.
2163,2163,68.0,Criteo AI Lab,Criteo AI Lab,generalized no free lunch theorem for adversarial robustness.
2164,2164,69.0,MIT,Massachusetts Institute of Technology,proven: verifying robustness of neural networks with a probabilistic approach.
2165,2165,70.0,Carnegie Mellon University,Carnegie Mellon University,on learning invariant representations for domain adaptation.
2166,2166,71.0,Technion,Technion,lexicographic and depth-sensitive margins in homogeneous and non-homogeneous deep models.
2167,2167,72.0,Austrian Academy of Sciences,Acoustics Research Institute,adversarial generation of time-frequency features with application in audio synthesis.
2168,2168,73.0,Weizmann Institute of Science,Weizmann Institute of Science,on the universality of invariant networks.
2169,2169,74.0, Princeton University and Institute for Advanced Study,Carnegie Mellon University,fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks.
2170,2170,75.0,Qualcomm AI Research,University of Amsterdam & Qualcomm,gauge equivariant convolutional networks and the icosahedral cnn.
2171,2171,76.0,National University of Defense Technology,Samsung AI Centre / University of Edinburgh,feature-critic networks for heterogeneous domain generalization.
2172,2172,77.0,University of Amsterdam,University of Amsterdam,learning to convolve: a generalized weight-tying approach.
2173,2173,78.0,Johns Hopkins University,Johns Hopkins University,on dropout and nuclear norm regularization.
2174,2174,79.0,Carnegie Mellon University,Massachusetts Institute of Technology,gradient descent finds global minima of deep neural networks.
2175,2175,80.0,Toyota Technological Institute at Chicago,University of Washington,composable core-sets for determinant maximization: a simple near-optimal algorithm.
2176,2176,81.0,National University of Singapore,NUS,sublinear time nearest neighbor search over generalized weighted space.
2177,2177,82.0,Rice University,Rice University,compressing gradient optimizers via count-sketches.
2178,2178,83.0,Toyota Technological Institute at Chicago (TTIC),MIT,scalable fair clustering.
2179,2179,84.0,EPFL,EPFL,conditional gradient methods via stochastic path-integrated differential estimator.
2180,2180,85.0,"Petuum, Inc. and Carnegie Mellon University",Petuum Inc. and CMU, fault tolerance in iterative-convergent machine learning.
2181,2181,86.0,Google Brain,Google Brain,static automatic batching in tensorflow.
2182,2182,87.0,Cornell University,Cornell Univeristy,improving neural network quantization without retraining using outlier channel splitting.
2183,2183,88.0,Stanford University,Stanford University,memory-optimal direct convolutions for maximizing classification accuracy in embedded applications.
2184,2184,89.0,ETH Zurich,ETH Zurich,dl2: training and querying neural networks with logic.
2185,2185,90.0,University of Minnesota Twin Cities,Iowa State University,pa-gd: on the convergence of perturbed alternating gradient descent to second-order stationary points for structured nonconvex optimization.
2186,2186,91.0,The Ohio State University,The Ohio State University,improved zeroth-order variance reduced algorithms and analysis for nonconvex optimization.
2187,2187,92.0,University of Pittsburgh,University of Pittsburgh,faster stochastic alternating direction method of multipliers for nonconvex optimization.
2188,2188,93.0,UCLA,"University of California, Los Angeles",lower bounds for smooth nonconvex finite-sum optimization.
2189,2189,94.0,KAUST,KAUST,nonconvex variance reduced optimization with arbitrary sampling.
2190,2190,95.0,EPFL,EPFL,error feedback fixes signsgd and other gradient compression schemes.
2191,2191,96.0,"University of Minnesota, Twin Cities",Microsoft Research,a composite randomized incremental gradient method.
2192,2192,97.0,ETH Zürich,ETH Zurich,optimal continuous dr-submodular maximization and applications to provable mean field inference.
2193,2193,98.0,SUTD,Singapore university of technology and design,multiplicative weights updates as a distributed constrained optimization algorithm: convergence to second-order stationary points almost always.
2194,2194,99.0,Cainiao AI,The University of Iowa,katalyst: boosting convex katayusha for  non-convex problems with a  large condition number.
2195,2195,100.0,Microsoft Research,Microsoft Research Montreal,safe policy improvement with baseline bootstrapping.
2196,2196,101.0,University of Alberta,University of Waterloo,distributional reinforcement learning for efficient exploration.
2197,2197,102.0,Politecnico di Milano,Politecnico di Milano,optimistic policy optimization via multiple importance sampling.
2198,2198,103.0,University of Liverpool,University of Liverpool,neural logic reinforcement learning.
2199,2199,104.0,Harvard University,Max Planck Institute (MPI-SWS),learning to collaborate in markov decision processes.
2200,2200,105.0,Georgia Tech,Georgia Tech,predictor-corrector policy optimization.
2201,2201,106.0,"University of California, Berkeley","Stanford, Google, UC Berkeley",learning a prior over intent via meta-inverse reinforcement learning.
2202,2202,107.0,Google Brain,Google Brain,deepmdp: learning continuous latent space models for representation learning.
2203,2203,108.0,UT Austin,University of Texas at Austin,importance sampling policy evaluation with an estimated behavior policy.
2204,2204,109.0,EPFL,GOOGLE BRAIN,learning from a learner.
2205,2205,110.0,McGill University,Stanford University,separable value functions across time-scales.
2206,2206,111.0,University of Massachusetts Amherst,University of Massachusetts Amherst,learning action representations for reinforcement learning.
2207,2207,112.0,Amazon,Amazon.com,bayesian counterfactual risk minimization.
2208,2208,113.0,DeepMind,DeepMind,per-decision option discounting.
2209,2209,114.0,Stanford University,Stanford University,tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds.
2210,2210,115.0,Google,GOOGLE BRAIN,a theory of regularized markov decision processes.
2211,2211,116.0,Brown University,Brown,discovering options for exploration by minimizing cover time.
2212,2212,117.0,Carnegie Mellon University,Stanford University,policy certificates: towards accountable reinforcement learning.
2213,2213,118.0,Google AI Residency Program,Google / University of Alberta,the value function polytope in reinforcement learning.
2214,2214,119.0,Stanford,Stanford University,data shapley:  equitable valuation of data for machine learning.
2215,2215,120.0,Stevens Institute of Technology,Inria,feature grouping as a stochastic regularizer for high-dimensional structured data.
2216,2216,121.0,Google Research,Google,metric-optimized example weights.
2217,2217,122.0,University of Bremen,University of Bremen,improving model selection by employing the test data.
2218,2218,123.0,IBM Research,New York University,topological data analysis of decision boundaries with application to model selection.
2219,2219,124.0,Carnegie Mellon University,Microsoft,contextual memory trees.
2220,2220,125.0,Wuhan University,Nanjing University of Science and Technology,sparse extreme multi-label learning with oracle property.
2221,2221,126.0,Google AI,Google,shape constraints for set functions.
2222,2222,127.0,Hebrew University of Jerusalem,"Hebrew University of Jerusalem, Israel",on the power of curriculum learning in training deep networks.
2223,2223,128.0,KTH Royal Institute of Technology,KTH Royal Institute of Technology,voronoi boundary classification: a high-dimensional geometric approach via weighted monte carlo integration.
2224,2224,129.0,MIT,UCLA,robust decision trees against adversarial examples.
2225,2225,130.0,Worcester Polytechnic Institute,Worcester Polytechnic Institute,automatic classifiers as scientific instruments: one step further away from ground-truth.
2226,2226,131.0,University of Texas at Dallas,The University of Texas at Dallas,"look ma, no latent variables: accurate cutset networks via compilation."
2227,2227,132.0,IRISA,Université côte d'Azur,optimal transport for structured data with application on graphs.
2228,2228,133.0,Google,Google,learning optimal linear regularizers.
2229,2229,134.0,The University of Tokyo / RIKEN,RIKEN / The University of Tokyo,on symmetric losses for learning from corrupted labels.
2230,2230,135.0,University of Wisconsin-Madison,"University of Wisconsin, Madison",aucµ: a performance metric for multi-class machine learning models.
2231,2231,136.0,University of Bath,University of Bath,regularization in directable environments with application to tetris.
2232,2232,137.0,University of Connecticut,University of Connecticut,improved dynamic graph learning through fault-tolerant sparsification.
2233,2233,138.0,Nanjing University,Nanjing University,heterogeneous model reuse via optimizing multiparty multiclass margin.
2234,2234,139.0,Technion,Technion,rethinking lossy compression: the rate-distortion-perception tradeoff.
2235,2235,140.0,"Shenzhen Institutes of Advanced Technology,Chinese Academy of Sciences",University of Texas at Arlington / Tencent AI Lab,collaborative channel pruning for deep networks.
2236,2236,141.0,Hailo,Hailo Technologies,"same, same but different: recovering neural network quantization error through weight factorization."
2237,2237,142.0,University of Central Florida,KAUST and Baidu SVAIL,gdpp: learning diverse generations using determinantal point processes.
2238,2238,143.0,Xidian University,Xidian University,co-representation network for generalized zero-shot learning.
2239,2239,144.0,McGill University,McGill University,geometrics: exploiting geometric structure for graph-encoded objects.
2240,2240,145.0,Google Brain,Google Brain,efficientnet: rethinking model scaling for convolutional neural networks.
2241,2241,146.0,Ecole Polytechnique Federale de Lausanne (EPFL),EPFL,geometry aware convolutional filters for omnidirectional images representation.
2242,2242,147.0,University of Hamburg,University of Hamburg,a personalized affective memory model for improving emotion recognition.
2243,2243,148.0,Indiana University,Indiana University / Google Brain,temporal gaussian mixture layer for videos.
2244,2244,149.0,Carnegie Mellon University,Carnegie Mellon University,regret circuits: composability of regret minimizers.
2245,2245,150.0,Mitsubishi Electric Research Laboratories,Mitsubishi Electric Research Labs,game theoretic optimization via gradient-based nikaido-isoda function.
2246,2246,151.0,Carnegie Mellon University,Carnegie Mellon University,stable-predictive optimistic counterfactual regret minimization.
2247,2247,152.0,Duke University,Duke,when samples are strategically selected.
2248,2248,153.0,Carnegie Mellon University,Carnegie Mellon University,statistical foundations of virtual democracy.
2249,2249,154.0,London School of Economics,Harvard University,optimal auctions through deep learning.
2250,2250,155.0,Tsinghua University,Google Research,learning to clear the market.
2251,2251,156.0,ENS Paris Saclay - Criteo AI Lab,ENS Paris Saclay & Criteo AI Lab,learning to bid in revenue-maximizing auctions.
2252,2252,157.0,DeepMind,DeepMind,open-ended learning in symmetric zero-sum games.
2253,2253,158.0,Facebook AI Research,Carnegie Mellon University,deep counterfactual regret minimization.
2254,2254,159.0,Bocconi University,"Harvard University, USA",generalized approximate survey propagation for high-dimensional estimation.
2255,2255,160.0,ANU,"Data61, The Australian National University and the University of Sydney",boosted density estimation remastered.
2256,2256,161.0,Skolkovo Institute of Science and Technology,University of Arizona ,inference and sampling of $k_{33}$-free ising models.
2257,2257,162.0,Université Paris Sud,Université Savoie Mont-Blanc,random matrix improved covariance estimation for a large class of metrics.
2258,2258,163.0,Florida International University,Florida International University,dual entangled polynomial code: three-dimensional coding for distributed matrix multiplication.
2259,2259,164.0,Stanford University,Stanford University,neural joint source-channel coding.
2260,2260,165.0,"University of California, San Diego",UCSD,doubly-competitive distribution estimation.
2261,2261,166.0,Johns Hopkins University,ShanghaiTech University,homomorphic sensing.
2262,2262,167.0,Iowa State University,Iowa State University,phaseless pca: low-rank matrix recovery from column-wise phaseless measurements.
2263,2263,168.0,University of Illinois at Urbana-Champaign,University of Washington,rate distortion for model compression:from theory to practice.
2264,2264,169.0,The Pennsylvania State University,Pennsylvania State University,formal privacy for functional data with gaussian perturbations.
2265,2265,170.0,UMass Amherst,"University of Massachusetts, Amherst",graphical-model based estimation and inference for differential privacy.
2266,2266,171.0,Facebook AI Research,Facebook AI Research,white-box vs black-box: bayes optimal strategies for membership inference.
2267,2267,172.0,University of Alberta,University of Alberta,an optimal private stochastic-mab algorithm based on optimal private stopping rule.
2268,2268,173.0,Johns Hopkins University,Johns Hopkins University,sublinear space private algorithms under the sliding window model.
2269,2269,174.0,UMass Amherst,Microsoft Research,locally private bayesian inference for count models.
2270,2270,175.0,Tel Aviv University,Microsoft,low latency privacy preserving inference.
2271,2271,176.0,Cornell University,Cornell/Google,communication complexity in locally private distribution estimation and heavy hitters.
2272,2272,177.0,UC Santa Barbara,UC Santa Barbara,poission subsampled r\'enyi differential privacy.
2273,2273,178.0,Pennsylvania State University,Pennsylvania State University,benefits and pitfalls of the exponential mechanism with applications to hilbert spaces and functional pca.
2274,2274,179.0,University of Bergen,University of Bergen,refined complexity of pca with outliers.
2275,2275,180.0,UC Berkeley,UC Berkeley,on efficient optimal transport: an analysis of greedy and accelerated mirror descent algorithms.
2276,2276,181.0,Institut de Physique Théorique,CNRS,passed & spurious: descent algorithms and local minima in spiked matrix-tensor models.
2277,2277,182.0,UC San Diego,University of Wisconsin-Madison,teaching a black-box learner.
2278,2278,183.0,University of Virginia,"Biocomplexity Institute and Dept of Computer Science, University of Virginia",pac learnability of node functions in networked dynamical systems.
2279,2279,184.0,UC Berkeley,UC Berkeley,online learning with kernel losses.
2280,2280,185.0,Carnegie Mellon University,Carnegie Mellon University,nearest neighbor and kernel survival analysis: nonasymptotic error bounds and strong consistency rates.
2281,2281,186.0,University of Birmingham,University of Birmingham,fast rates for a knn classifier robust to unknown asymmetric label noise.
2282,2282,187.0,Inria Saclay,Carnegie Mellon University,uniform convergence rate of the kernel density estimator adaptive to intrinsic volume dimension.
2283,2283,188.0,University of Washington,University of Washington,maximum likelihood estimation for  learning populations of parameters.
2284,2284,189.0,Seoul National University,UCLA,projection onto minkowski sums with application to constrained learning.
2285,2285,190.0,Georgia Institute of Technology,University of Wisconsin-Madison,blended conditonal gradients.
2286,2286,191.0,UCLA math,Alibaba US,acceleration of svrg and katyusha x by inexact preconditioning.
2287,2287,192.0,University of Connecticut,IBM T.J. Watson Research Center,characterization of convex objective functions and optimal expected convergence rates for sgd.
2288,2288,193.0,EPFL,EPFL,a conditional-gradient-based augmented lagrangian framework.
2289,2289,194.0,Telecom Paristech,KAUST,sgd: general analysis and improved rates.
2290,2290,195.0,KTH Royal Institute of Technology,KTH Royal Institute of Technology,curvature-exploiting acceleration of elastic net computations.
2291,2291,196.0,EPFL,EPFL,decentralized stochastic optimization and gossip algorithms with compressed communication.
2292,2292,197.0,RIKEN AIP,Nagoya Institute of Technology / RIKEN,safe grid search with optimal complexity.
2293,2293,198.0,KAUST,KAUST,saga with arbitrary sampling.
2294,2294,199.0,"University of California, Berkeley","University of California, Berkeley",natural analysts in adaptive data analysis.
2295,2295,200.0,DeepMind,DeepMind/University of Alberta,capsandruns: an improved method for approximately optimal algorithm configuration.
2296,2296,201.0,University College London,Imperial College London,leveraging low-rank relations between surrogate tasks in structured prediction.
2297,2297,202.0,Google AI,Kakao Mobility,training well-generalizing classifiers for fairness metrics and other data-dependent constraints.
2298,2298,203.0,Purdue University,Purdue University,optimality implies kernel sum classifiers are statistically efficient.
2299,2299,204.0,University of California Berkeley,"University of California, Berkeley",the implicit fairness criterion of unconstrained learning.
2300,2300,205.0,KAIST,KAIST,weak detection of signal in the spiked wigner model.
2301,2301,206.0,UC Berkeley,UC Berkeley,rademacher complexity for adversarially robust generalization.
2302,2302,207.0,Carnegie Mellon University,Microsoft Research,provably efficient rl with rich observations via latent state decoding.
2303,2303,208.0,University of Illinois at Urbana-Champaign,University of Illinois at Urbana-Champaign,information-theoretic considerations in batch reinforcement learning.
2304,2304,209.0,University of Cambridge / Columbia University,DeepMind,a contrastive divergence for combining variational inference and mcmc.
2305,2305,210.0,University of Oxford,University of Auckland,calibrated approximate bayesian inference.
2306,2306,211.0,TU Darmstadt,TU Darmstadt,moment-based variational inference for markov jump processes.
2307,2307,212.0,Tsinghua University,Tsinghua University,understanding mcmc dynamics as flows on the wasserstein space.
2308,2308,213.0,MIT,MIT,lr-glm: high-dimensional bayesian inference using low-rank data approximations.
2309,2309,214.0,University of Oxford,University of Oxford,amortized monte carlo integration.
2310,2310,215.0,The Institute of Statistical Mathematics,Newcastle University,stein point markov chain monte carlo.
2311,2311,216.0,University of British Columbia,University of British Columbia,fast and simple natural-gradient variational inference with mixture of exponential-family approximations.
2312,2312,217.0,Georgia Institution of Technology,Georgia Institute of Technology,particle flow bayes' rule.
2313,2313,218.0,Columbia University,UT Dallas,correlated variational auto-encoders.
2314,2314,219.0,University of Oxford,University of Oxford,towards a unified analysis of random fourier features.
2315,2315,220.0,"Gatsby Unit, University College London",Gatsby Computational Neuroscience Unit,learning deep kernels for exponential family densities.
2316,2316,221.0,"University of Sydney, CSIRO","NVIDIA, University of Sydney",bayesian deconditional kernel mean embeddings.
2317,2317,222.0,Inria,Inria,a kernel perspective for regularizing deep neural networks.
2318,2318,223.0,ETH Zurich,ETH Zurich,a persistent weisfeiler--lehman procedure for graph classification.
2319,2319,224.0,Stanford University,Stanford University,rehashing kernel evaluation in high dimensions.
2320,2320,225.0,Aalto University,Aalto University,large-scale sparse kernel canonical correlation analysis.
2321,2321,226.0,Stanford,Stanford,a kernel theory of modern data augmentation.
2322,2322,227.0,Mines ParisTech (ARMINES),Google,kernelpsi: a post-selection inference framework for nonlinear variable selection.
2323,2323,228.0,King's College London,The University of Nottingham,scalable learning in reproducing kernel krein spaces.
2324,2324,229.0,"IBM Research, MIT-IBM Watson AI Lab",University of Michigan,dirichlet simplex nest and geometric inference.
2325,2325,230.0,Aalto University,Aalto University,bayesian leave-one-out cross-validation for large data.
2326,2326,231.0,UC Berkeley,Voleon Group and University of California at Berkeley,rao-blackwellized stochastic gradients for discrete distributions.
2327,2327,232.0,Shanghai Jiao Tong University,MIT,neurally-guided structure inference.
2328,2328,233.0,Yale School of Public Health,The Ohio State University,bayesian joint spike-and-slab graphical lasso.
2329,2329,234.0,Frankfurt Institute for Advanced Studies,Frankfurt Institute for Advanced Studies ,rotation invariant householder parameterization for bayesian pca.
2330,2330,235.0,University of Arizona,Uber AI Labs & The University of Arizona,a framework for bayesian optimization in embedded subspaces.
2331,2331,236.0,XIDIAN UNIVERSITY,University of Texas at Austin,convolutional poisson gamma belief network.
2332,2332,237.0,Technical University of Munich,Technical University of Munich,automatic posterior transformation for likelihood-free inference.
2333,2333,238.0,Aalto University,Aalto University,active learning for decision-making from imbalanced observational data.
2334,2334,239.0,UCLA,UCLA,validating causal inference models via influence functions.
2335,2335,240.0,MIT,MIT,"ithemal: accurate, portable and fast basic block throughput estimation using deep neural networks."
2336,2336,241.0,UC Berkeley,UC Berkeley,learning to groove with inverse sequence transformations.
2337,2337,242.0,Tencent AI Lab,Tecent AI Lab,grid-wise control for multi-agent reinforcement learning in video game ai.
2338,2338,243.0,Google Research,Googl,holist: an environment for machine learning of higher order logic theorem proving.
2339,2339,244.0,MIT-IBM Watson AI Lab / IBM Research,MIT-IBM Watson AI Lab / IBM Research,molecular hypergraph grammar with its application to molecular optimization.
2340,2340,245.0,KAIST,KAIST,graph neural network for music score data and modeling expressive piano performance.
2341,2341,246.0,Princeton University,Princeton University,learning to prove theorems via interacting with proof assistants.
2342,2342,247.0,MIT,MIT,circuit-gnn: graph neural networks for distributed circuit design.
2343,2343,248.0,Weizmann Institute of Science,Technion,learning to optimize multigrid pde solvers.
2344,2344,249.0,UC MErced,"University of California, Merced",a block coordinate descent proximal method for simultaneous filtering and parameter estimation.
2345,2345,250.0,EPFL,EPFL,learning hawkes processes under synchronization noise.
2346,2346,251.0,Georgia Institution of Technology,Georgia Institute of Technology,generative adversarial user model for reinforcement learning based recommendation system.
2347,2347,252.0,University of Washington,University of Washington,a statistical investigation of long memory in language and music.
2348,2348,253.0,AWS AI Labs,Amazon Research,deep factors for forecasting.
2349,2349,254.0,Cardiff University,Cardiff University,weakly-supervised temporal localization via occurrence count learning.
2350,2350,255.0,Volkswagen Group,Volkswagen Group,switching linear dynamics for variational bayes filtering.
2351,2351,256.0,Johns Hopkins University,Johns Hopkins University + Microsoft Semantic Machines,imputing missing events in continuous-time event streams.
2352,2352,257.0,Technion,Technion - Israeli Institute of Technology,understanding and controlling memory in recurrent neural networks.
2353,2353,258.0,"Bosch Center for Artificial Intelligence, University of Tübingen",Lincoln University,recurrent kalman networks: factorized inference in high-dimensional deep feature spaces.
2354,2354,259.0,ENSAE Paris,Google and CREST/ENSAE,subspace robust wasserstein distances.
2355,2355,260.0,University of Oxford,University of Birmingham,decomposing feature-level variation with covariate gaussian process latent variable models.
2356,2356,261.0,Oak Ridge National Laboratory,,active manifolds: a non-linear analogue to active subspaces.
2357,2357,262.0,Aarhus University,"Aarhus University, MADALGO",optimal minimal margin maximization with boosting.
2358,2358,263.0,IBM Research,IBM Research,generalized linear rule models.
2359,2359,264.0,IBM Research AI,,"fast incremental von neumann graph entropy computation: theory, algorithm, and applications."
2360,2360,265.0,INRA / AgroParisTech / Paris Saclay,INRA,variational inference for sparse network reconstruction from count data.
2361,2361,266.0,Cornell University,Cornell University,simplifying graph convolutional networks.
2362,2362,267.0,Harvard University,Harvard,robust influence maximization for hyperparametric models.
2363,2363,268.0,Oregon State University,Oregon State University,"hypergan: a generative model for diverse, performant neural networks."
2364,2364,269.0,University of Cambridge,PROWLER.io,rates of convergence for sparse variational gaussian process regression.
2365,2365,270.0,ETH Zurich - Max Planck Institute,Google Brain,challenging common assumptions in the unsupervised learning of disentangled representations.
2366,2366,271.0,"University of Waterloo, Vector Institute",University of Waterloo,sum-of-squares polynomial flow.
2367,2367,272.0,Seoul National University,Seoul National University,flowavenet : a generative flow for raw audio.
2368,2368,273.0,Microsoft Research Cambridge,Universitat Tubingen/CIN,are generative classifiers more robust to adversarial attacks?.
2369,2369,274.0,University of Illinois at Urbana-Champaign,UIUC,"a gradual, semi-discrete approach to generative network training via explicit wasserstein minimization."
2370,2370,275.0,University of Oxford,Oxford and DeepMind,disentangling disentanglement in variational autoencoders.
2371,2371,276.0,University of Cambridge,"Microsoft Research, Cambridge",eddi: efficient dynamic discovery of high-value information with partial vae.
2372,2372,277.0,The University of Tokyo,Preferred Networks Inc. ,a wrapped normal distribution on hyperbolic space for gradient-based learning.
2373,2373,278.0,University of Amsterdam,University of Amsterdam & Qualcomm,emerging convolutions for generative normalizing flows.
2374,2374,279.0,Google Brain,Google Brain,a large-scale study on regularization and normalization in gans.
2375,2375,280.0,Duke University,Duke,variational annealing of gans: a langevin perspective.
2376,2376,281.0,University of Bremen,Vector Institute and University of Toronto,invertible residual networks.
2377,2377,282.0,Ambient.ai,University of Freiburg and Bosch Center for Artificial Intelligence,nas-bench-101: towards reproducible neural architecture search.
2378,2378,283.0,Tsinghua University,Hangzhou Dianzi University,approximated oracle filter pruning for destructive cnn width optimization.
2379,2379,284.0,Peking University,University of Sydney,legonet: efficient convolutional neural networks with lego filters.
2380,2380,285.0,University of Toronto,University of Toronto and Vector Institute,sorting out lipschitz function approximation.
2381,2381,286.0,MIT,(organization),"graph element networks: adaptive, structured computation and memory."
2382,2382,287.0,KAIST,"KAIST, AITRICS",training cnns with selective allocation of channels.
2383,2383,288.0,Stanford University,Stanford University,equivariant transformer networks.
2384,2384,289.0,IPROVA,Swisscom,overcoming multi-model forgetting.
2385,2385,290.0,IBM Research AI,IBM Research,bayesian nonparametric federated learning of neural networks.
2386,2386,291.0,University of Technology Sydney,RIKEN / The University of Tokyo,how does disagreement help generalization against label corruption?.
2387,2387,292.0,University of Toronto,University of Toronto,eigendamage: structured pruning in the kronecker-factored eigenbasis.
2388,2388,293.0,Apple Inc.,"Apple, Inc.",addressing the loss-metric mismatch with adaptive loss alignment.
2389,2389,294.0,DeepMind,Google DeepMind,deep compressed sensing.
2390,2390,295.0,The University of Hong Kong,sensetime,differentiable dynamic normalization for learning deep representation.
2391,2391,296.0,Peking University,Georgia Institute of Technology,toward understanding the importance of noise in training neural networks.
2392,2392,297.0,Univeristy of Oxford,University of Oxford,cheap orthogonal constraints in neural networks: a simple parametrization of the orthogonal and unitary group.
2393,2393,298.0,"Denso IT Laboratory, Inc.","National Institute of Advanced Industrial Science and Technology, Japan",breaking inter-layer co-adaptation by classifier anonymization.
2394,2394,299.0,Mila - McGill University,Google / University of Alberta,understanding the impact of entropy on policy optimization.
2395,2395,300.0,Stanford University,Stanford University,"probability functional descent: a unifying perspective on gans, variational inference, and reinforcement learning."
2396,2396,301.0,MIT,DeepMind,social influence as intrinsic motivation for multi-agent deep reinforcement learning.
2397,2397,302.0,Siemens & Ludwig Maximilian University of Munich,Siemens AG and University of Munich,maximum entropy-regularized multi-goal reinforcement learning.
2398,2398,303.0,Georgia Institute of Technology,Georgia Institute of Technology,imitating latent policies from observation.
2399,2399,304.0,UC Berkeley,UC Berkeley,solar: deep structured representations for model-based reinforcement learning.
2400,2400,305.0,KAIST,KAIST,dimension-wise importance sampling weight clipping for sample-efficient reinforcement learning.
2401,2401,306.0,Google DeepMind,DeepMind,structured agents for physical construction.
2402,2402,307.0,Georgia Institute of Technology,Georgia Institute of Technology,learning novel policies for tasks.
2403,2403,308.0,"Salesforce Research, UC Berkeley",Salesforce,taming maml: efficient unbiased meta-reinforcement learning.
2404,2404,309.0,UC Berkeley,Carnegie Mellon University,self-supervised exploration via disagreement.
2405,2405,310.0,UC Berkeley,UC Berkeley,efficient off-policy meta-reinforcement learning via probabilistic context variables.
2406,2406,311.0,Technion,Technion,the natural language of actions.
2407,2407,312.0,California Institute of Technology,Caltech,control regularization for reduced variance reinforcement learning.
2408,2408,313.0,Salesforce Research,Salesforce,on the generalization gap in reparameterizable reinforcement learning.
2409,2409,314.0,"Bosch Center for Artificial Intelligence, Max Planck Institute for Intelligent Systems",Bosch Center for Artificial Intelligence,trajectory-based off-policy deep reinforcement learning.
2410,2410,315.0,University of Illinois Urbana-Champaign,Technion,a deep reinforcement learning perspective on internet congestion control.
2411,2411,316.0,NNAISENSE,NNAISENSE SA,model-based active exploration.
2412,2412,317.0,University of Texas at Austin,University of Texas at Austin,extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations.
2413,2413,318.0,Technion,Technion,distributional multivariate policy evaluation and exploration with the bellman gan.
2414,2414,319.0,Man AHL,University of Oxford,a baseline for any order gradient estimation in stochastic computation graphs.
2415,2415,320.0,ETH Zurich,ETH Zurich,remember and forget for experience replay.
2416,2416,321.0,Uber AI Labs,Uber AI Labs,tensor variable elimination for plated factor graphs.
2417,2417,322.0,MIT,New York University,predicate exchange: inference with declarative knowledge.
2418,2418,323.0,Columbia University,University of Chicago,discriminative regularization for latent variable models with applications to electrocardiography.
2419,2419,324.0,University of Cambridge,University of Cambridge,hierarchical decompositional mixtures of variational autoencoders.
2420,2420,325.0,EPFL,EPFL,finding mixed nash equilibria of generative adversarial networks.
2421,2421,326.0,University of Amsterdam,DeepMind,compile: compositional imitation learning and execution.
2422,2422,327.0,"UCA, Inria","Inria UCA,",sparse multi-channel variational autoencoder for the joint analysis of heterogeneous data.
2423,2423,328.0,Xi'an Jiaotong University,HKUST,deep generative learning via variational gradient flow.
2424,2424,329.0,UC Berkeley,OpenAI / UC Berkeley,flow++: improving flow-based generative models with variational dequantization and architecture design.
2425,2425,330.0,University of Pennsylvania,University of Pennsylvania,learning neurosymbolic generative models via program synthesis.
2426,2426,331.0,CMU & TTIC,UC Berkeley,theoretically principled trade-off between robustness and accuracy.
2427,2427,332.0,ETH Zurich,ETH Zurich,the odds are odd: a statistical test for detecting adversarial examples.
2428,2428,333.0,MIT,MIT,me-net: towards effective adversarial robustness with matrix estimation.
2429,2429,334.0,Carnegie Mellon University,Carnegie Mellon University / Bosch Center for AI,certified adversarial robustness via randomized smoothing.
2430,2430,335.0,"University of California, San Diego",Google,"imperceptible, robust, and targeted adversarial examples for automatic speech recognition."
2431,2431,336.0,Seoul National University,Seoul National University,parsimonious black-box adversarial attacks via efficient combinatorial optimization.
2432,2432,337.0,Carnegie Mellon University,Carnegie Mellon University / Bosch Center for AI,wasserstein adversarial examples via projected sinkhorn iterations.
2433,2433,338.0,University of Maryland,University of Maryland,transferable clean-label poisoning attacks on deep neural nets.
2434,2434,339.0,University of Central Florida,Google,nattack: learning the distributions of adversarial examples for an improved  black-box  attack on deep neural networks.
2435,2435,340.0,Cornell University,Cornell University,simple black-box adversarial attacks.
2436,2436,341.0,Purdue University,Purdue,causal identification under markov equivalence: completeness results.
2437,2437,342.0,MIT,Massachusetts Institute of Technology,counterfactual off-policy evaluation with gumbel-max structural causal models.
2438,2438,343.0,Carnegie Mellon University,Carnegie Mellon University,causal discovery and forecasting in nonstationary environments with state-space models.
2439,2439,344.0,Cornell University,Cornell University,classifying treatment responders under causal effect monotonicity.
2440,2440,345.0,Johns Hopkins University,Johns Hopkins University,learning models from data with measurement error: tackling underreporting.
2441,2441,346.0,Purdue University,Purdue,adjustment criteria for generalizing experimental findings.
2442,2442,347.0,UCLA,UCLA,conditional independence in testing bayesian networks.
2443,2443,348.0,UCLA,Purdue,sensitivity analysis of linear structural causal models.
2444,2444,349.0,UC Berkeley,UC Berkeley,more efficient off-policy evaluation through regularized targeted learning.
2445,2445,350.0,Uppsala University,Uppsala University,inferring heterogeneous causal effects in presence of spatial confounding.
2446,2446,351.0,Duke University,Duke University,adversarially learned representations for information obfuscation and inference.
2447,2447,352.0,University College London,Microsoft Research Cambridge,adaptive neural trees.
2448,2448,353.0,University of Salzburg,Microsoft,connectivity-optimized representation learning via persistent homology.
2449,2449,354.0,California Institute of Technology,Austrian Academy of Sciences,minimal achievable sufficient statistic learning.
2450,2450,355.0,Yandex,Yandex,learning to route in similarity graphs.
2451,2451,356.0,Faculty,Faculty,invariant-equivariant representation learning for multi-class data.
2452,2452,357.0,Massachusetts Institute of Technology,MIT,infinite mixture prototypes for few-shot learning.
2453,2453,358.0,USC Information Sciences Institute,USC ISI,mixhop: higher-order graph convolutional architectures via sparsified neighborhood mixing.
2454,2454,359.0,NC State University,Salesforce,learn to grow: a continual structure learning framework for overcoming catastrophic forgetting.
2455,2455,360.0,Technion,Technion,exploration conscious reinforcement learning revisited.
2456,2456,361.0,Texas A&M and Facebook AI Research,University of Pennsylvania,complexity of linear regions in deep networks.
2457,2457,362.0,Saarland University,Saarland University,on connected sublevel sets in deep learning.
2458,2458,363.0,Google Brain,Google Brain,adversarial examples are a natural consequence of test error in noise.
2459,2459,364.0,"Mila, University of Montreal",CentraleSupélec,greedy layerwise learning can scale to imagenet.
2460,2460,365.0,University of Oxford,University of Oxford,on the impact of the activation function on deep neural networks training.
2461,2461,366.0,MIT,MIT,estimating information flow in deep neural networks.
2462,2462,367.0,Peking University,Peking University,the anisotropic noise in stochastic gradient descent: its behavior of escaping from sharp minima and regularization effects.
2463,2463,368.0,Labatie-AI,Labatie-AI,characterizing well-behaved vs. pathological deep neural networks.
2464,2464,369.0,"""Department of Bio and Brain Engineering, KAIST, Korea""",KAIST,understanding geometry of encoder-decoder cnns.
2465,2465,370.0,UC Berkeley,Calculation Consulting,traditional and heavy tailed self regularization in neural network models.
2466,2466,371.0,"Télécom ParisTech, Université Paris-Saclay",EPFL,almost surely constrained convex optimization.
2467,2467,372.0,Google Inc.,Brown University,generalized majorization-minimization.
2468,2468,373.0,Alibaba Group (US) Inc,alibaba group,on the computation and communication complexity of parallel sgd with dynamic batch sizes for stochastic non-convex optimization.
2469,2469,374.0,RIKEN Center for Advanced Intelligence Project,The University of Tokyo / RIKEN,simple stochastic gradient methods for non-smooth non-convex regularized optimization.
2470,2470,375.0,Boston University,Stony Brook University,surrogate losses for online learning of stepsizes in stochastic non-convex optimization.
2471,2471,376.0,Columbia University,"Columbia University, USA",efficient dictionary learning with gradient descent.
2472,2472,377.0,"University of California, Los Angeles",Alibaba US,plug-and-play methods provably converge with properly trained denoisers.
2473,2473,378.0,The University of Electro-Communications,Microsoft,riemannian adaptive stochastic gradient algorithms on matrix manifolds.
2474,2474,379.0,The University of Iowa,The University of Iowa,stochastic optimization for dc functions and non-smooth non-convex regularizers with non-asymptotic convergence.
2475,2475,380.0,Colorado School of Mines,Colorado School of Mines,alternating minimizations converge to second-order optimal solutions.
2476,2476,381.0,Carnegie Mellon University,Carnegie Mellon University,provably efficient imitation learning from observation alone.
2477,2477,382.0,Microsoft Research,Microsoft Research,dead-ends and secure exploration in reinforcement learning.
2478,2478,383.0,DeepMind,DeepMind,statistics and samples in distributional reinforcement learning.
2479,2479,384.0,Zhejiang University,Zhejiang University,hessian aided policy gradient.
2480,2480,385.0,Princeton University,Princeton University,provably efficient maximum entropy exploration.
2481,2481,386.0,Harvard University,Harvard University,combining parametric and nonparametric models for off-policy evaluation.
2482,2482,387.0,Princeton,Princeton University,sample-optimal parametric q-learning using linearly additive features.
2483,2483,388.0,Politecnico di Milano,Politecnico di Milano,transfer of samples in policy search via multiple importance sampling.
2484,2484,389.0,Technion,Technion,action robust reinforcement learning and applications in continuous control.
2485,2485,390.0,IBM Research,Ecole Polytechnique,kernel-based reinforcement learning in robust markov decision processes.
2486,2486,391.0,Nanjing University,Nanjing University,optimal algorithms for lipschitz bandits with heavy-tailed rewards.
2487,2487,392.0,"CNRS Université Paris-Sud, Inria Paris, EDF R&D",Université paris Sud,target tracking for contextual bandits: application to demand side management.
2488,2488,393.0,LinkedIn Corp.,IIT Madras,correlated bandits or: how to minimize mean-squared error online.
2489,2489,394.0,Texas A&M University,Texas A & M University,stay with me: lifetime maximization through heteroscedastic linear bandits with reneging.
2490,2490,395.0,Google Research,Facebook AI Research,"garbage in, reward out: bootstrapping exploration in multi-armed bandits."
2491,2491,396.0,University of Copenhagen,University of Southern California,beating stochastic and adversarial semi-bandits optimally and simultaneously.
2492,2492,397.0,Boston University,University of Wisconsion-Madison,bilinear bandits with low-rank structure .
2493,2493,398.0,The Chinese University of Hong Kong,DeepMind/University of Alberta,online learning to rank with features.
2494,2494,399.0,Netflix,Netflix,on the design of estimators for bandit off-policy evaluation.
2495,2495,400.0,University of California Berkeley,IBM Research,dynamic learning with frequent new product launches: a sequential multinomial logit bandit problem.
2496,2496,401.0,"Sorbonne Université, LIP6","LIP6, Sorbonne Universite",context-aware zero-shot learning for object recognition.
2497,2497,402.0,University of Chicago,University of Chicago,band-limited training and inference for convolutional neural networks.
2498,2498,403.0,Boston University,Boston University,learning classifiers for target domain with limited or no labels.
2499,2499,404.0,UC Berkeley,UC Berkeley,population based augmentation: efficient learning of augmentation policy schedules.
2500,2500,405.0,University of Freiburg,University of Freiburg,anomaly detection with multiple-hypotheses predictions.
2501,2501,406.0,Max Planck Institute for Intelligent Systems,"MPI for Intelligent Systems Tübingen, Germany",kernel mean matching for content addressability of gans.
2502,2502,407.0,MIT CSAIL,MIT,neural inverse knitting: from images to manufacturing instructions.
2503,2503,408.0,Adobe,Adobe,making convolutional networks shift-invariant again.
2504,2504,409.0,Fudan University,Fudan University,generative modeling of infinite occluded objects for compositional scene representation.
2505,2505,410.0,University of British Columbia,Emory University,imexnet - a forward stable deep neural network.
2506,2506,411.0,Berkeley,UC Berkeley,do imagenet classifiers generalize to imagenet?.
2507,2507,412.0,MIT,MIT,exploring the landscape of spatial robustness.
2508,2508,413.0,USC,University of Southern California,sever: a robust meta-algorithm for stochastic optimization.
2509,2509,414.0,Princeton University,IBM Research,analyzing federated learning through an adversarial lens.
2510,2510,415.0,UQAM,Université de Montréal,fairwashing: the risk of rationalization.
2511,2511,416.0,University of Toronto,Vector Institute,understanding the origins of bias in word embeddings.
2512,2512,417.0,"""University of Washington, Seattle""",UW,bias also matters: bias attribution for deep neural network explanation.
2513,2513,418.0,Peking University,Peking University,interpreting adversarially trained convolutional neural networks.
2514,2514,419.0,Georgia Tech,Georgia Institute of Technology,counterfactual visual explanations.
2515,2515,420.0,The Ohio State University,The Ohio State University,data poisoning attacks on stochastic bandits.
2516,2516,421.0,Tsinghua University,"University of California, Los Angeles",on the convergence and robustness of adversarial training.
2517,2517,422.0,UT Austin,UT Austin,learning with bad training data via iterative trimmed loss minimization.
2518,2518,423.0,Czech Technical University in Prague,Czech technical university in Prague,on discriminative learning of prediction uncertainty.
2519,2519,424.0,The Chinese University of Hong Kong,Tencent; The Chinese University of Hong Kong,understanding and utilizing deep neural networks trained with noisy labels.
2520,2520,425.0,University of Wisconsin - Madison,University of Wisconsin-Madison,does data augmentation lead to positive margin?.
2521,2521,426.0,IST Austria,IST Austria,robust learning from untrusted sources.
2522,2522,427.0,KAIST,KAIST,selfie: refurbishing unclean samples for robust deep learning.
2523,2523,428.0,UIUC,UIUC,zeno: distributed stochastic gradient descent with suspicion-based fault-tolerance.
2524,2524,429.0,University of Massachusetts Amherst,"University of Massachusetts, Amherst",concentration inequalities for conditional value at risk.
2525,2525,430.0,University of Virginia,Kuwait University,data poisoning attacks in multi-party learning.
2526,2526,431.0,Princeton University,Google Research,distributed weighted matching via randomized composable coresets.
2527,2527,432.0,McGill University,University of British Columbia,multivariate submodular optimization.
2528,2528,433.0,University of Tokyo,NTT,beyond adaptive submodularity: approximation guarantees of greedy policy with adaptive submodularity ratio.
2529,2529,434.0,Technical University of Munich,New York University,approximating orthogonal matrices with effective givens factorization.
2530,2530,435.0,University of Verona,PUC-RJ,new results on information theoretic clustering.
2531,2531,436.0,ETH Zurich,MIT,improved parallel algorithms for density-based network clustering.
2532,2532,437.0,University of Texas at Austin,University of Texas at Austin,submodular observation selection and information gathering for quadratic models.
2533,2533,438.0,University of Florida,University of Florida,submodular cost submodular cover with an approximate oracle.
2534,2534,439.0,Yale,Yale,"submodular streaming in all its glory: tight approximation, minimum memory and low adaptive complexity."
2535,2535,440.0,Google Research,Cornell,hiring under uncertainty.
2536,2536,441.0,Stanford University,Stanford University,position-aware graph neural networks.
2537,2537,442.0,University of Florida,Oregon State University,detecting overlapping and correlated communities without pure nodes: identifiability and algorithm.
2538,2538,443.0,ETH Zürich,MIT,learning generative models across incomparable spaces.
2539,2539,444.0,Purdue University,Purdue University,relational pooling for graph representations.
2540,2540,445.0,Tsinghua University,Tsinghua University,disentangled graph convolutional networks.
2541,2541,446.0,California Institute of Technology,Caltech,open vocabulary learning on source code with a graph-structured cache.
2542,2542,447.0,Istituto Italiano di Tecnologia - University College London,NEC Laboratories Europe,learning discrete structures for graph neural networks.
2543,2543,448.0,McGill/Mila,McGill University,compositional fairness constraints for graph embeddings.
2544,2544,449.0,LIP6 - Sorbonne Universités,LIP6 - Sorbonne Universités,a recurrent neural cascade-based model for continuous-time diffusion.
2545,2545,450.0,Duke University,IIT Kanpur,stochastic blockmodels meet graph neural networks.
2546,2546,451.0,Cornell University,Cornell University,distributed learning with sublinear communication.
2547,2547,452.0,Alibaba Group (US) Inc,,on the linear speedup analysis of communication efficient momentum sgd for distributed non-convex optimization.
2548,2548,453.0,McGill University/Facebook AI Research,Facebook,stochastic gradient push for distributed deep learning.
2549,2549,454.0,Carnegie Mellon University,Carnegie Mellon University,collective model fusion for multiple black-box experts.
2550,2550,455.0,Pennsylvania State University,Pennsylvania State University,trading redundancy for communication: speeding up distributed sgd for non-convex optimization.
2551,2551,456.0,KAIST,UW,"trimming the $\ell_1$ regularizer: statistical analysis, optimization, and applications to deep learning."
2552,2552,457.0,Stanford University,Stanford University,compressed factorization: fast and accurate low-rank factorization of compressively-sensed data.
2553,2553,458.0,Johns Hopkins University,"Johns Hopkins University, USA",noisy dual principal component pursuit.
2554,2554,459.0,University of Texas at Austin,"Google Research, NY",learning a compressed sensing measurement matrix via gradient unrolling.
2555,2555,460.0,Universite de Rouen Normandie / Criteo AI Lab,Université de Montpellier,screening rules for lasso with  non-convex sparse regularizers.
2556,2556,461.0,ANU,"Data61, the Australian National University",monge blunts bayes: hardness results for adversarial training.
2557,2557,462.0,Osaka University,Nara Institute of Science and Technology,better generalization with less data using robust gradient descent.
2558,2558,463.0,MIT,MIT,near optimal finite time identification of arbitrary linear dynamical systems.
2559,2559,464.0,"Data61, The Australian National University and the University of Sydney",ANU,lossless or quantized boosting with integer arithmetic.
2560,2560,465.0,Microsoft Research,University of Minnesota,orthogonal random forest for causal inference.
2561,2561,466.0,"Laboratoire de Mathématiques d'Orsay, Univ. Paris-Sud; CNRS, Université Paris Saclay, France",CREST,monk --  outlier-robust mean embedding estimation by median-of-means.
2562,2562,467.0,Google Brain,Google Brain,the advantages of multiple classes for reducing overfitting from test set reuse.
2563,2563,468.0,University of Southern California,Northwestern U,on the statistical rate of nonlinear recovery in generative models with heavy-tailed data.
2564,2564,469.0,Technical University of Denmark,Technical University of Denmark,"phase transition in pca with missing data: reduced signal-to-noise ratio, not sample size!."
2565,2565,470.0,Telecom ParisTech,Université Paris Nanterre,on medians of (randomized) pairwise means.
2566,2566,471.0,Rutgers University,Florida State University,accelerated linear convergence of stochastic momentum methods in wasserstein distances.
2567,2567,472.0,Massachusetts Institute of Technology,Microsoft Research,sgd without replacement: sharper rates for general smooth convex functions.
2568,2568,473.0,Institute for Information Transmission Problems,MIT,on the complexity of approximating wasserstein barycenters.
2569,2569,474.0,Inria,Inria,estimate sequences for variance-reduced stochastic composite optimization.
2570,2570,475.0,UC Berkeley,UC Berkeley,a dynamical systems perspective on nesterov acceleration.
2571,2571,476.0,Tsinghua University,MIT,random shuffling beats sgd after finite epochs.
2572,2572,477.0,University of Wisconsin-Madison,University of Wisconsin-Madison,first-order algorithms converge faster than $o(1/k)$ on convex problems.
2573,2573,478.0,Boston University,Boston University,improved convergence for $\ell_1$ and $\ell_\infty$ regression via iteratively reweighted least squares.
2574,2574,479.0,Télécom ParisTech,Université de Montpellier,optimal mini-batch and step sizes for saga.
2575,2575,480.0,Peking University,Stanford University,differential inclusions for modeling nonsmooth admm variants: a continuous limit theory.
2576,2576,481.0,University of Bristol,University of Bristol,distribution calibration for regression.
2577,2577,482.0,Imperial College London,Imperial College London,graph convolutional gaussian processes.
2578,2578,483.0,University of Oxford,U Oxford,asynchronous batch bayesian optimisation with improved local penalisation.
2579,2579,484.0,"Corporate Research, Robert Bosch GmbH",Bosch Center for Artificial Intelligence,goode: a gaussian off-the-shelf ordinary differential equation solver.
2580,2580,485.0,University of Cambirdge; Max Planck Tübingen,Cambridge University,overcoming mean-field approximations in recurrent gaussian process models.
2581,2581,486.0,University of Oxford,MPI for Intelligent Systems,ares and mars - adversarial and mmd-minimizing regression for sdes.
2582,2582,487.0,Queen Mary University of London,Aalto University,end-to-end probabilistic inference for nonstationary audio analysis.
2583,2583,488.0,Imperial College,Imperial College London and PROWLER.io,deep gaussian processes with importance-weighted variational inference.
2584,2584,489.0,Washington University in St. Louis,Washington University in St. Louis,automated model selection with bayesian quadrature.
2585,2585,490.0,University of Oxford,Oxford,beyond the chinese restaurant and pitman-yor processes: statistical models with double power-law behavior.
2586,2586,491.0,University of Bath,University of Bath,dp-gp-lvm: a bayesian non-parametric model for learning multivariate dependency structures.
2587,2587,492.0,Columbia University,Columbia University,random function priors for correlation modeling.
2588,2588,493.0,University of Edinburgh,Google,variational russian roulette for deep bayesian nonparametrics.
2589,2589,494.0,Florida State University,Florida State University,incorporating grouping information into bayesian decision tree ensembles.
2590,2590,495.0,University of Cambridge,University of Cambridge,variational implicit processes.
2591,2591,496.0,Ulsan National Institute of Science and Technology,Ulsan National Institute of Science and Technology,discovering latent covariance structures for multiple time series.
2592,2592,497.0,Tsinghua University,Tsinghua University,scalable training of inference networks for gaussian-process models.
2593,2593,498.0,National University of Singapore,MIT,bayesian optimization meets bayesian optimal stopping.
2594,2594,499.0,"Gatsby Unit, UCL","Gatsby Unit, UCL",learning interpretable continuous-time models of latent stochastic dynamical systems.
2595,2595,500.0,Google Research NYC,Google,a tree-based method for fast repeated sampling of determinantal point processes.
2596,2596,501.0,UT Austin,UT Austin,nonlinear stein variational gradient descent for learning diversified mixture models.
2597,2597,502.0,Tsinghua University,Tsinghua University,understanding and accelerating particle-based variational inference.
2598,2598,503.0,Ecole Polytechnique Fédérale de Lausanne,EPFL,efficient learning of smooth probability functions from bernoulli tests with guarantees.
2599,2599,504.0,Columbia University,New York University,the variational predictive natural gradient.
2600,2600,505.0,University of Oxford,University of Oxford,scalable nonparametric sampling from multimodal posteriors with the posterior bootstrap.
2601,2601,506.0,Stanford University,Stanford University,an instability in variational inference for topic models.
2602,2602,507.0,Cornell University,Cornell University / Uber,bayesian optimization of composite functions.
2603,2603,508.0,MIT,MIT,the kernel interaction trick: fast bayesian discovery of pairwise interactions in high dimensions.
2604,2604,509.0,university of texas at austin,UT Austin,quantile stein variational gradient descent for batch  bayesian optimization.
2605,2605,510.0,University of Melbourne,University of Melbourne,exploiting worker correlation for label aggregation in crowdsourcing.
2606,2606,511.0,Microsoft Research,Microsoft Research,efficient amortised bayesian inference for hierarchical and nonlinear dynamical systems.
2607,2607,512.0,Koç University,Koç University,a multitask multiple kernel learning algorithm for survival analysis with application to cancer biology.
2608,2608,513.0,MIT,Massachusetts Institute of Technology,fast and flexible inference of joint distributions from their marginals.
2609,2609,514.0,Princeton University,UC Berkeley,cognitive model priors for predicting human decisions.
2610,2610,515.0,"University of California, Berkeley","University of California, Berkeley",conditioning by adaptive sampling for robust design.
2611,2611,516.0,Cornell University / Google Brain,Cornell University,direct uncertainty prediction for medical second opinions.
2612,2612,517.0,University of Toronto,University of Toronto,dynamic measurement scheduling for event forecasting using deep rl.
2613,2613,518.0,Intel Corporation,Cerebras Systems,parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization.
2614,2614,519.0,Cold Spring Harbor Laboratory,Cold Spring Harbor Laboratory,deepnose: using artificial neural networks to represent the space of odorants.
2615,2615,520.0,Boston University,Boston University,domain agnostic learning with disentangled representations.
2616,2616,521.0,University of the Witwatersrand,Council for Scientific and Industrial Research,composing value functions in reinforcement learning.
2617,2617,522.0,University of Oxford,University of Oxford,fast context adaptation via meta-learning.
2618,2618,523.0,Carnegie Mellon University,Carnegie Mellon University,provable guarantees for gradient-based meta-learning.
2619,2619,524.0,IST Austria,IST Austria,towards understanding knowledge distillation.
2620,2620,525.0,Tsinghua University,UC Berkeley,transferable adversarial training: a general approach to adapting deep classifiers.
2621,2621,526.0,Tsinghua University,Tsinghua University,transferability vs. discriminability: batch spectral penalization for adversarial domain adaptation.
2622,2622,527.0,IIT,University College London,learning-to-learn stochastic gradient descent with biased regularization.
2623,2623,528.0,University of Edinburgh,University of Edinburgh,bert and pals: projected attention layers for efficient adaptation in multi-task learning.
2624,2624,529.0,Tsinghua University,UC Berkeley,towards accurate model selection in deep unsupervised domain adaptation.
2625,2625,530.0,Georgia Institute of Technology,Georgia Institute of Technology,active embedding search via noisy paired comparisons.
2626,2626,531.0,Rochester Institute of Technology,Rochester Institute of Technology,fast direct search in an optimally compressed continuous target space for efficient multi-label active learning.
2627,2627,532.0,Carnegie Mellon University,CMU,myopic posterior sampling for adaptive goal oriented design of experiments.
2628,2628,533.0,University of Adelaide,University of Adelaide,bayesian generative active deep learning.
2629,2629,534.0,University of Pennsylvania,University of Illinois at Chicago,active learning for probabilistic structured prediction of cuts and matchings.
2630,2630,535.0,Google Research,INRIA and Google,active learning with disagreement graphs.
2631,2631,536.0,University of Illinois at Urbana-Champaign,University of Illinois at Urbana Champaign,multi-frequency vector diffusion maps.
2632,2632,537.0,Yale,Yale University,co-manifold learning with missing data.
2633,2633,538.0,University of Cambridge & DeepMind,Google DeepMind,hybrid models with deep and invertible features.
2634,2634,539.0,Universite de Montreal,Google Research &            U. Colorado Boulder,state-reification networks: improving generalization by modeling the distribution of hidden representations.
2635,2635,540.0,Seoul National University,Seoul National University,variational laplace autoencoders.
2636,2636,541.0,Harvard University,Harvard University,latent normalizing flows for discrete sequences.
2637,2637,542.0,Institut National de la Recherche Scientifique,"MILA, UdeM",multi-objective training of generative adversarial networks with multiple discriminators.
2638,2638,543.0,Seoul National University,Seoul National University,learning discrete and continuous factors of data via alternating disentanglement.
2639,2639,544.0,UC Berkeley,UC Berkeley,bit-swap: recursive bits-back coding for lossless compression with hierarchical latent variables.
2640,2640,545.0,Stanford University,Stanford University,graphite: iterative generative modeling of graphs.
2641,2641,546.0,IT University Copenhagen,IT University of Copenhagen,miwae: deep generative modelling and imputation of incomplete data sets.
2642,2642,547.0,Georgia Institute of Technology,Georgia Institute of Technology,on scalable and efficient computation of large scale optimal transport.
2643,2643,548.0,Google Brain,Google Brain,understanding and correcting pathologies in the training of learned optimizers.
2644,2644,549.0,University of Pittsburgh,University of Pittsburgh,demystifying dropout.
2645,2645,550.0,KAIST,KAIST,ladder capsule network.
2646,2646,551.0,Mila - Université de Montréal,U Montreal,unreproducible research is reproducible.
2647,2647,552.0,Michigan State University,Michigan State University,geometric scattering for graph data analysis.
2648,2648,553.0,KAIST,"KAIST, AITRICS",robust inference via generative classifiers for handling noisy labels.
2649,2649,554.0,Stanford University,Stanford and Databricks,lit: learned intermediate representation training for model compression.
2650,2650,555.0,Google Brain,Google,analyzing and improving representations with the soft nearest neighbor loss.
2651,2651,556.0,Carnegie Mellon University,Carnegie Mellon University,what is the effect of importance weighting in deep learning?.
2652,2652,557.0,Google Brain,Google,similarity of neural network representations revisited.
2653,2653,558.0,Stanford,Stanford,learning fast algorithms for linear transforms using butterfly factorizations.
2654,2654,559.0,Microsoft Inc.,National Tsing Hua University,"distributed, egocentric representations of graphs for detecting critical structures."
2655,2655,560.0,ETH Zurich,Google,breaking the softmax bottleneck via learnable monotonic pointwise non-linearities.
2656,2656,561.0,IDSIA,DeepMind,multi-object representation learning with iterative variational inference.
2657,2657,562.0,University of Pennsylvania,Google Research,cross-domain 3d equivariant image embeddings.
2658,2658,563.0,Stanford University,Broad Institute of MIT and Harvard,loss landscapes of regularized linear autoencoders.
2659,2659,564.0,LAPRAS Inc.,scouty Inc.,hyperbolic disk embeddings for directed acyclic graphs.
2660,2660,565.0,ShanghaiTech University,ShanghaiTech University,latentgnn: learning efficient non-local relations for visual recognition.
2661,2661,566.0,ETH Zurich,MPI for Intelligent Systems,robustly disentangled causal mechanisms: validating deep representations for interventional robustness.
2662,2662,567.0,University of Toronto,Vector Institute,lorentzian distance learning for hyperbolic representations.
2663,2663,568.0,Caltech,Caltech,batch policy learning under constraints.
2664,2664,569.0,OpenAI,OpenAI,quantifying generalization in reinforcement learning.
2665,2665,570.0,Google Brain & University of Toronto,Google Brain,learning latent dynamics for planning from pixels.
2666,2666,571.0,TU Darmstadt,University of Lincoln,projections for approximate policy iteration algorithms.
2667,2667,572.0,University of Edinburgh,University of Edinburgh,learning structured decision problems with unawareness.
2668,2668,573.0,Stanford Universtiy,Stanford University,calibrated model-based deep reinforcement learning.
2669,2669,574.0,Politecnico di Milano,Politecnico di Milano,reinforcement learning in configurable continuous environments.
2670,2670,575.0,"University of Illinois, Urbana-Champaign",UIUC,target-based temporal-difference learning.
2671,2671,576.0,University of Washington,University of Washington,iterative linearized control: stable algorithms and complexity guarantees.
2672,2672,577.0,Brown University,Brown,finding options that minimize planning time.
2673,2673,578.0,University of Amsterdam,University of Amsterdam,stochastic beams and where to find them: the gumbel-top-k trick for sampling sequences without replacement.
2674,2674,579.0,Nanjing University,Nanjing University,learning to exploit long-term relational dependencies in knowledge graphs.
2675,2675,580.0,DeepMind,Google DeepMind,meta-learning neural bloom filters.
2676,2676,581.0,Shanghai Jiao Tong University,"Apex Data & Knowledge Management Lab, Shanghai Jiao Tong University",cot: cooperative training for generative modeling of discrete data.
2677,2677,582.0,New York University,New York University,non-monotonic sequential text generation.
2678,2678,583.0,UC Berkeley,"Google, Inc.",insertion transformer: flexible sequence generation via insertion operations.
2679,2679,584.0,University of Toronto,University of Toronto,empirical analysis of beam search performance degradation in neural sequence models.
2680,2680,585.0,Georgia Tech,Georgia Institute of Technology / Facebook AI Research,trainable decoding of sets of sequences for neural sequence models.
2681,2681,586.0,"Google Research, Brain Team",Google Brain,learning to generalize from sparse and underspecified rewards.
2682,2682,587.0,Peking University,Microsoft Research Asia,efficient training of bert by progressively stacking.
2683,2683,588.0,Orange Labs,Microsoft Research,decentralized exploration in multi-armed bandits.
2684,2684,589.0,Microsoft Research,YALE,warm-starting contextual bandits: robustly combining supervised and bandit feedback.
2685,2685,590.0,Inria Lille - Nord Europe,DeepMind,exploiting structure of uncertainty for efficient matroid semi-bandits.
2686,2686,591.0,Indian Institute of Technology Bombay,IIT Bombay,pac identification of many good arms in stochastic multi-armed bandits.
2687,2687,592.0,Seoul National University,Seoul National University,contextual multi-armed bandit algorithm for semiparametric reward model.
2688,2688,593.0,Facebook AI Research,DeepMind,bayesian action decoder for deep multi-agent reinforcement learning.
2689,2689,594.0,Georgia Tech,Facebook,tarmac: targeted multi-agent communication.
2690,2690,595.0,KAIST,KAIST,qtran: learning to factorize with transformation for cooperative multi-agent reinforcement learning.
2691,2691,596.0,University of Southern California,Google Research,actor-attention-critic for multi-agent reinforcement learning.
2692,2692,597.0,Georgia Institute of Technology,Georgia Tech,finite-time analysis of distributed td(0) with linear function approximation on multi-agent reinforcement learning.
2693,2693,598.0,Johns Hopkins University,"Indian Institute of Technology, Hyderabad",neural network attributions: a causal perspective.
2694,2694,599.0,Shanghai Jiao Tong University,Microsoft Research Asia,towards a deep and unified understanding of deep neural models in nlp.
2695,2695,600.0,ETH Zurich,ETH Zurich,explaining deep neural networks with a polynomial time algorithm for shapley value approximation.
2696,2696,601.0,MIT CSAIL,MIT,functional transparency for structured data: a game-theoretic approach.
2697,2697,602.0,ETH Zurich,ETHZ,exploring interpretable lstm neural networks over multi-variable data.
2698,2698,603.0,Google Brain,Google Brain,tensorfuzz: debugging neural networks with coverage-guided fuzzing.
2699,2699,604.0,University of Iowa,University of Iowa,gaining free or low-cost interpretability with interpretable partial substitute.
2700,2700,605.0,NEC Laboratories Europe,NEC Laboratories Europe,state-regularized recurrent neural networks.
2701,2701,606.0,University of Maryland,University of Maryland,understanding impacts of high-order loss approximations and features in deep learning interpretation.
2702,2702,607.0,University of Bremen,University of Cambridge,on the connection between adversarial robustness and saliency map interpretability.
2703,2703,608.0,Tel Aviv University,"Tel Aviv University, Google",why do larger models generalize better? a theoretical perspective via the xor problem.
2704,2704,609.0,University of Heidelberg,University of Montreal,on the spectral bias of neural networks.
2705,2705,610.0,Google,Google,recursive sketches for modular deep learning.
2706,2706,611.0,Indian Institute of Science,Indian Institute of Science,zero-shot knowledge distillation in deep networks.
2707,2707,612.0,Microsoft Research AI,UT-Austin,a convergence theory for deep learning via over-parameterization.
2708,2708,613.0,Telecom ParisTech,Rutgers University,a tail-index analysis of stochastic gradient noise in deep neural networks.
2709,2709,614.0,University of Tokyo / Preferred Networks,The University of Tokyo / RIKEN,approximation and non-parametric estimation of resnet-type convolutional neural networks.
2710,2710,615.0,Hongkong University of Science and Technology,HongKong University of Science and Technology,global convergence of block coordinate descent in deep learning.
2711,2711,616.0,Stanford University,Stanford University,measurements of three-level hierarchical structure in the outliers in the spectrum of deepnet hessians.
2712,2712,617.0,University of Oxford,U Oxford,on the limitations of representing functions on sets.
2713,2713,618.0,Facebook AI Research,Georgia Tech & Facebook AI Research,probabilistic neural symbolic models for interpretable visual question answering.
2714,2714,619.0,National and Kapodistrian University of Athens,National and Kapodistrian University of Athens,nonparametric bayesian deep networks with local competition.
2715,2715,620.0,EURECOM,Eurecom,good initializations of variational bayes for deep models.
2716,2716,621.0,University of Cambridge & DeepMind,UC Irvine,dropout as a structured shrinkage prior.
2717,2717,622.0,University of Texas at Austin,University of Texas at Austin,arsm: augment-reinforce-swap-merge estimator for gradient backpropagation through categorical variables.
2718,2718,623.0,Google Brain,Google Brain,on variational bounds of mutual information.
2719,2719,624.0,Lund University,IT University of Copenhagen,partially exchangeable networks and architectures for learning summary statistics in approximate bayesian computation.
2720,2720,625.0,MILA,Université de Montréal,hierarchical importance weighted autoencoders.
2721,2721,626.0,TU Darmstadt,TU Darmstadt,faster attend-infer-repeat with tractable probabilistic models.
2722,2722,627.0,Inria,Inria Grenoble Rhone-Alpes,understanding priors in bayesian neural networks at the unit level.
2723,2723,628.0,UC Berkeley,UC Berkeley,defending against saddle point attack in byzantine-robust distributed learning.
2724,2724,629.0,"University at Albany, SUNY",SUNY Albany,stochastic iterative hard thresholding for graph-structured sparsity optimization.
2725,2725,630.0,New York University,New York University,neuron birth-death dynamics accelerates gradient descent and converges asymptotically.
2726,2726,631.0,Carnegie Mellon University,Princeton University,width provably matters in optimization for deep linear neural networks.
2727,2727,632.0,"University of California, Riverside",University of Southern California,overparameterized nonlinear learning: gradient descent takes the shortest path?.
2728,2728,633.0,Duke University,UCLA,power k-means clustering.
2729,2729,634.0,University of Rochester,"Kwai Seattle AI lab, University of Rochester",distributed learning over unreliable networks.
2730,2730,635.0,MIT,MIT,escaping saddle points with adaptive gradient methods.
2731,2731,636.0,University of Rochester,"Kwai Seattle AI lab, University of Rochester",$\texttt{doublesqueeze}$: parallel stochastic gradient descent with double-pass error-compensated compression.
2732,2732,637.0,Saarland University,University of Göttingen,model function based conditional gradient method with armijo-like line search.
2733,2733,638.0,The University of Edinburgh,Samsung AI Centre / University of Edinburgh,analogies explained: towards understanding word embeddings.
2734,2734,639.0,Google,Google Brain,parameter-efficient transfer learning for nlp.
2735,2735,640.0,Google Research,Google Research,efficient on-device models using neural projections.
2736,2736,641.0,Idiap Research Institute,IDIAP,deep residual output layers for neural language generation.
2737,2737,642.0,UT Austin,UT Austin,improving neural language modeling via adversarial training.
2738,2738,643.0,MIT,Facebook,mixture models for diverse machine translation: tricks of the trade.
2739,2739,644.0,Nanjing University of Science and Technology,Microsoft,mass: masked sequence to sequence pre-training for language generation.
2740,2740,645.0,University of Oxford,Microsoft Research,humor in word embeddings: cockamamie gobbledegook for nincompoops.
2741,2741,646.0,Massachusetts Institute of Technology,Google Brain,meansum: a neural model for unsupervised multi-document abstractive summarization.
2742,2742,647.0,Google UK,University of West Bohemia,chive: varying prosody in speech synthesis with a linguistically driven dynamic hierarchical conditional variational network.
2743,2743,648.0,Sichuan University,A*STAR,comic: multi-view clustering without parameter selection.
2744,2744,649.0,Ohio State University,The Ohio State University,the wasserstein transform.
2745,2745,650.0,Northeastern University,Northeastern University,sequential facility location: approximate submodularity and greedy algorithm.
2746,2746,651.0,The Australian National University,"Australian National University, Australia",neural collaborative subspace clustering.
2747,2747,652.0,Queen Mary University of London,Vision Semantics Limited,unsupervised deep learning by neighbourhood discovery.
2748,2748,653.0,University of Edinburgh,The University of Edinburgh,autoregressive energy machines.
2749,2749,654.0,East China Normal University,Fudan University,greedy orthogonal pivoting algorithm for non-negative matrix factorization.
2750,2750,655.0,Chan Zuckerberg Biohub,Chan Zuckerberg Biohub,noise2self: blind denoising by self-supervision.
2751,2751,656.0,Stanford University,Stanford,learning dependency structures for weak supervision models.
2752,2752,657.0,Columbia University,"Columbia University, USA",geometry and symmetry in short-and-sparse deconvolution.
2753,2753,658.0,State University of New York at Buffalo,SUNY Buffalo,on sparse linear regression in the local differential privacy model.
2754,2754,659.0,State University of New York at Buffalo,SUNY Buffalo,differentially private empirical risk minimization with non-convex loss functions.
2755,2755,660.0,Google Research,Google,bounding user contributions: a bias-variance trade-off in differential privacy.
2756,2756,661.0,Tel Aviv University and Google,Ben-Gurion University,differentially private learning of geometric concepts.
2757,2757,662.0,Yale University,Yale University,toward controlling discrimination in online ad auctions.
2758,2758,663.0,Johns Hopkins University,Johns Hopkins University,learning optimal fair policies.
2759,2759,664.0,CRITEO,"Criteo AI Lab and UC, Berkeley",fairness-aware learning for continuous attributes and treatments.
2760,2760,665.0,ANU,Google,fairness risk measures.
2761,2761,666.0,Duke University,Duke University,proportionally fair clustering.
2762,2762,667.0,EPFL,Yale University,stable and fair classification.
2763,2763,668.0,University of Toronto,Vector Institute,flexibly fair representation learning by disentanglement.
2764,2764,669.0,Microsoft Research,University of Minnesota, fair regression: quantitative definitions and reduction-based algorithms.
2765,2765,670.0,Harvard University,Harvard University,fairness without harm: decoupled classifiers with preference guarantees.
2766,2766,671.0,Northeastern University,Northeastern University,differentially private fair learning.
2767,2767,672.0,Institut de Mathématiques de Toulouse and IMUVA,Université Toulouse Paul Sabatier Institut de Mathématiques de Toulouse,obtaining fairness using optimal transport theory.
2768,2768,673.0,Harvard University,Harvard University,repairing without retraining: avoiding disparate impact with counterfactual distributions.
2769,2769,674.0,ETHZ,MPI-SWS,on the long-term impact of algorithmic decision policies: effort unfairness and feature segregation through social learning.
2770,2770,675.0,The Alan Turing Institute,University College London,making decisions that reduce discriminatory impacts.
2771,2771,676.0,Yale University,Yale,"submodular maximization beyond non-negativity: guarantees, fast algorithms, and applications."
2772,2772,677.0,Google Research,Duke University,online algorithms for rent-or-buy with expert advice.
2773,2773,678.0,Georgia Institute of Technology,Google,non-monotone submodular maximization with nearly optimal adaptivity and query complexity.
2774,2774,679.0,Google Research,Google,categorical feature compression via submodular optimization.
2775,2775,680.0,University of Chicago,University of Illinois at Urbana Champaign,multi-frequency phase synchronization.
2776,2776,681.0,Google,Carnegie Mellon University,faster algorithms for binary matrix factorization.
2777,2777,682.0,Google Brain,Google Brain,guided evolutionary strategies: augmenting random search with surrogate gradients.
2778,2778,683.0,ETH Zurich,ETH Zurich,adaptive and safe bayesian optimization in high dimensions via one-dimensional subspaces.
2779,2779,684.0,Google,Google,semi-cyclic stochastic gradient descent.
2780,2780,685.0,Google,Google,matrix-free preconditioning in online learning.
2781,2781,686.0,Tel Aviv University,Google and Tel Aviv University,online convex optimization in adversarial markov decision processes.
2782,2782,687.0,Georgia Institute of Technology,Georgia Tech,competing against nash equilibria in adversarially changing zero-sum games.
2783,2783,688.0,Google Research,D. E. Shaw & Co.,online learning with sleeping experts and feedback graphs.
2784,2784,689.0,Tianjin University,Tianjin University,incremental randomized sketching for online kernel learning.
2785,2785,690.0,Poznan University of Technology,UC Santa Cruz & Google Inc.,adaptive scale-invariant online algorithms for learning linear models.
2786,2786,691.0,Google AI Princeton,Princeton University,online control with adversarial disturbances.
2787,2787,692.0,Tel Aviv University,Google and Tel Aviv University,adversarial online learning with noise.
2788,2788,693.0,ETH Zurich,ETH Zurich,online variance reduction with mixtures.
2789,2789,694.0,Yahoo Research,Microsoft Research,bandit multiclass linear classification: efficient algorithms for the separable case.
2790,2790,695.0,Technion and Google,Google and Tel Aviv University,learning linear-quadratic regulators efficiently with only $\sqrt{t}$ regret.
2791,2791,696.0,DeepMind,DeepMind,learning from delayed outcomes via proxies with applications to recommender systems.
2792,2792,697.0,Nanjing University,Nanjing University,adaptive regret of convex and smooth functions.
2793,2793,698.0,University of Minnesota,University of Minnesota,online adaptive principal component analysis and its extensions.
2794,2794,699.0,Adobe Research,DeepMind,politex: regret bounds for policy iteration using expert prediction.
2795,2795,700.0,Google,Google,"anytime online-to-batch, optimism and acceleration."
2796,2796,701.0,Huawei Paris Research Center,CNRS,cautious regret minimization: online optimization with long-term budget constraints.
2797,2797,702.0,ETH Zurich,ETH Zurich,optimal kronecker-sum approximation of real time recurrent learning.
2798,2798,703.0,Lancaster University,PROWLER.io,adaptive sensor placement for continuous spaces.
2799,2799,704.0,UC Berkeley,DeepMind,scale-free adaptive planning for deterministic dynamics & discounted rewards.
2800,2800,705.0,Cornell University,IISC,communication-constrained inference and the role of shared randomness.
2801,2801,706.0,KTH Royal Institute of Technology,KTH Royal Institute of Technology,learning and data selection in big datasets.
2802,2802,707.0,University of Maryland,University of Maryland,sublinear quantum algorithms for training linear and kernel-based classifiers.
2803,2803,708.0,Courant Institute and Google Research,Google,agnostic federated learning.
2804,2804,709.0,Stanford University,Stanford University,discovering conditionally salient features with statistical guarantees.
2805,2805,710.0,Princeton University,Princeton University,a theoretical analysis of contrastive unsupervised representation learning.
2806,2806,711.0,Harvard,Yahoo Research,the information-theoretic value of unlabeled data in semi-supervised learning.
2807,2807,712.0,Insight Centre for Data Analytics (DCU),Insight Centre for Data Analytics,unsupervised label noise modeling and loss correction.
2808,2808,713.0,Carnegie Mellon University,Carnegie Mellon University,domain adaptation with asymmetrically-relaxed distribution alignment.
2809,2809,714.0,University of Texas at Austin,University of Texas at Austin,pareto optimal streaming unsupervised classification.
2810,2810,715.0,ENS,CNRS and ENS,geometric losses for distributional learning.
2811,2811,716.0,École normale supérieure,RIKEN / The University of Tokyo,"classification from positive, unlabeled and biased negative data."
2812,2812,717.0,The University of Tokyo / RIKEN,RIKEN / The University of Tokyo,complementary-label learning for arbitrary losses and models.
2813,2813,718.0,MIT,MIT,learning to infer program sketches.
2814,2814,719.0,Pennsylvania State University,Penn State University,hierarchically structured meta-learning.
2815,2815,720.0,Tsinghua University,UC Berkeley,bridging theory and algorithm for domain adaptation.
2816,2816,721.0,Bar Ilan University,,transfer learning for related reinforcement learning tasks via image-to-image translation.
2817,2817,722.0,OMNIOUS,"KAIST, AITRICS",learning what and where to transfer.
2818,2818,723.0,Uber,Google,dbscan++: towards fast and scalable density clustering.
2819,2819,724.0,Bogazici ,Stanford University,concrete autoencoders: differentiable feature selection and reconstruction.
2820,2820,725.0,"InfiniaML, Inc.",Duke,gromov-wasserstein learning for graph matching and node embedding.
2821,2821,726.0,Saarland University / University of Tübingen,University of Tübingen,spectral clustering of signed graphs via matrix power means.
2822,2822,727.0,Johns Hopkins University,Johns Hopkins University,coresets for ordered weighted clustering.
2823,2823,728.0,Rutgers University,Georgia Institute of Technology,fair k-center clustering for data summarization.
2824,2824,729.0,Google Zurich,Google,a better k-means++ algorithm via local search.
2825,2825,730.0,Osaka University / RIKEN,Okayama University / RIKEN,kernel normalized cut: a theoretical revisit.
2826,2826,731.0,Rutgers University,Georgia Institute of Technology,guarantees for spectral clustering with fairness constraints.
2827,2827,732.0,University of Massachusetts Amherst,UMass Amherst,supervised hierarchical clustering with exponential linkage.
2828,2828,733.0,Inria,Inria,sliced-wasserstein flows: nonparametric generative modeling via optimal transport and diffusions.
2829,2829,734.0,Telecom ParisTech,Télécom ParisTech,non-asymptotic analysis of fractional langevin monte carlo for non-convex optimization.
2830,2830,735.0,Google Brain Robotics,"University of Cambridge, Alan Turing Institute",unifying orthogonal monte carlo methods.
2831,2831,736.0,Stanford University,Stanford University,adaptive monte carlo multiple testing via multi-armed bandits.
2832,2832,737.0,Uber AI Labs,Uber Labs,metropolis-hastings generative adversarial networks.
2833,2833,738.0,Oxford,Oxford University,scalable metropolis-hastings for exact bayesian inference with large datasets.
2834,2834,739.0,The Alan Turing Institute / University of Edinburgh,Oxford University,replica conditional sequential monte carlo.
2835,2835,740.0,University of Washington,University of Washington,a polynomial time mcmc method for  sampling from continuous determinantal point processes.
2836,2836,741.0,Stanford University,Stanford University,adaptive antithetic sampling for variance reduction.
2837,2837,742.0,University of Illinois at Urbana-Champaign,University of Illinois at Urbana-CHampaign,accelerated flow for probability distributions.
2838,2838,743.0,Carnegie Mellon University,Carnegie Mellon University,tight kernel query complexity of kernel ridge regression and kernel $k$-means clustering.
2839,2839,744.0,IBM Research,Carnegie Mellon University,dimensionality reduction for tukey regression.
2840,2840,745.0,Google AI Princeton,Princeton University,efficient full-matrix adaptive regularization.
2841,2841,746.0,UIUC,University of Washington,breaking the gridlock in mixture-of-experts: consistent and efficient algorithms.
2842,2842,747.0,4Paradigm,RIKEN-AIP,efficient nonconvex regularized tensor completion with structure-aware proximal iterations.
2843,2843,748.0,The University of Texas at Austin,University of Texas,robust estimation of tree structured gaussian graphical models.
2844,2844,749.0,KAIST,"KAIST, AITRICS",spectral approximate inference.
2845,2845,750.0,Princeton University,Illinois / Google,partially linear additive gaussian graphical models.
2846,2846,751.0,Lehigh University,IBM T. J. Watson,dag-gnn: dag structure learning with graph neural networks.
2847,2847,752.0,Princeton University,Princeton University,random walks on hypergraphs with edge-dependent vertex weights.
2848,2848,753.0,University of Melbourne,The University of Melbourne,doubly robust joint learning for recommendation on data missing not at random.
2849,2849,754.0,IBM Research - Zurich,"HSR Univ. Applied Sciences, Rapperswil, Switzerland",linear-complexity data-parallel earth mover's distance approximations.
2850,2850,755.0,Babylon Health,Babylon Health,model comparison for semantic grouping.
2851,2851,756.0,Tsinghua Univerisity,University of Texas at Arlington / Tencent AI Lab,rafm: rank-aware factorization machines.
2852,2852,757.0,Cornell University,Cornell,cab: continuous adaptive blending for policy evaluation and learning.
2853,2853,758.0,National Taiwan University,National Taiwan University,metricgan: generative adversarial networks based black-box metric scores optimization for speech enhancement.
2854,2854,759.0,Hebrew University of Jerusalem,Hebrew University of Jerusalem and Facebook AI Research,neural separation of observed and unobserved distributions.
2855,2855,760.0,Zhejiang University,Microsoft,almost unsupervised text to speech and automatic speech recognition.
2856,2856,761.0,UIUC,University of Illinois,autovc:  zero-shot voice style transfer with only autoencoder loss.
2857,2857,762.0,Facebook AI Research,Facebook AI Research,a fully differentiable beam search decoder.
2858,2858,763.0,Northeastern University,Northeastern University,scaling up ordinal embedding: a landmark approach.
2859,2859,764.0,Yandex,Yandex,learning to select for a predefined ranking.
2860,2860,765.0,UCLA,UCLA,mallows ranking models: maximum likelihood estimate and regeneration.
2861,2861,766.0,University of Hong Kong,University of Hong Kong,fast and stable maximum likelihood estimation for incomplete multinomial models.
2862,2862,767.0,The University of Hong Kong,University of Hong Kong,fast algorithm for generalized multinomial models with ranking data.
2863,2863,768.0,University of Catholique de Louvain,Boston University,graph resistance and learning from pairwise comparisons.
2864,2864,769.0,Amazon,TU Darmstadt,learning context-dependent label permutations for multi-label classification.
2865,2865,770.0,Stanford University,Stanford University,discovering context effects from raw choice data.
2866,2866,771.0,UC Berkeley,"EECS Department, University of California, Berkeley","on the feasibility of learning, rather than assuming, human biases for reward inference."
2867,2867,772.0,"Institute of Software, Chinese Academy of Sciences",Northwestern University,learning distance for sequences by learning a ground metric.
2868,2868,0.0,Microsoft Research,Unlearn.ai,ngboost: natural gradient boosting for probabilistic prediction.
2869,2869,1.0,University of Utah,Haverford College,problems with shapley-value-based explanations as feature importance measures.
2870,2870,2.0,"Preferred Networks, Inc",RIKEN / The University of Tokyo,normalized flat minima: exploring scale invariant definition of flat minima for neural networks using pac-bayesian analysis.
2871,2871,3.0,The University of Chicago,University of Chicago Booth School of Business,semiparametric nonlinear bipartite graph representation learning with provable guarantees.
2872,2872,4.0,University of Pennsylvania,University of Pennsylvania,a free-energy principle for representation learning.
2873,2873,5.0,University of Massachusetts Amherst,University of Massachusetts Amherst,asynchronous coagent networks.
2874,2874,6.0,"University of California, Irivine","University of California, Irivine",variational bayesian quantization.
2875,2875,7.0,Northwestern University,Northwestern U,on the global optimality of model-agnostic meta-learning.
2876,2876,8.0,Johns Hopkins University,Johns Hopkins University,full law identification in graphical models of missing data: completeness results.
2877,2877,9.0,JD AI Research,AI Research of JD.com,loss function search for face recognition.
2878,2878,10.0,UIUC,UIUC,zeno++: robust fully asynchronous sgd.
2879,2879,11.0,University of Toronto,Vector Institute,learning the stein discrepancy for training and evaluating energy-based models without sampling.
2880,2880,12.0,University of Illinois at Urbana-Champaign,University of Illinois at Urbana-Champaign,controlvae: controllable variational autoencoder.
2881,2881,13.0,University of Iowa,The University of Iowa,quadratically regularized subgradient methods for weakly convex optimization with weakly convex constraints.
2882,2882,14.0,Google Brain,Google,a simple framework for contrastive learning of visual representations.
2883,2883,15.0,ETS Montreal,ETS Montreal,laplacian regularized few-shot learning.
2884,2884,16.0,"University of California, San Diego",UCSD,data amplification: instance-optimal property estimation .
2885,2885,17.0,University of Minnesota,University of Minnesota,private reinforcement learning with pac and regret guarantees.
2886,2886,18.0,Georgia Institute of Technology,Microsoft Research,faster graph embeddings via coarsening.
2887,2887,19.0,Renmin University of China,Alibaba Group,simple and deep graph convolutional networks.
2888,2888,20.0,Harvard,University of Pennsylvania,towards understanding the dynamics of the first-order adversaries.
2889,2889,21.0,University of Maryland,University of Maryland College Park,an end-to-end differentially private latent dirichlet allocation using a spectral algorithm.
2890,2890,22.0,Rutgers University,Google Research and Courant Institute of Mathematical Sciences,adversarial learning guarantees for linear hypotheses and neural networks.
2891,2891,23.0,Microsoft,Tsinghua University,combinatorial pure exploration for dueling bandit.
2892,2892,24.0,UC Berkeley,Johns Hopkins University,fetchsgd: communication-efficient federated learning with sketching.
2893,2893,25.0,University of Toronto,University of Toronto and Vector Institute,evaluating lossy compression rates of deep generative models.
2894,2894,26.0,Duke University,Duke University,customizing ml predictions for online algorithms.
2895,2895,27.0,Princeton University,UC Berkeley,what is local optimality in nonconvex-nonconcave minimax optimization?.
2896,2896,28.0,University of Florida,University of Florida,streaming k-submodular maximization under noise subject to size constraint.
2897,2897,29.0,IIT Madras,ABInBev,concentration bounds for cvar estimation: the cases of light-tailed and heavy-tailed distributions.
2898,2898,30.0,Tsinghua University,Tsinghua University,interpolation between residual and non-residual networks.
2899,2899,31.0,Chongqing University,Chongqing University,monet3d: towards accurate monocular 3d object localization in real time.
2900,2900,32.0,Duke University,Duke University,penni: pruned kernel sharing for efficient cnn inference.
2901,2901,33.0,IIT Bombay,IIT Bombay,efficient domain generalization via common-specific low-rank decomposition.
2902,2902,34.0,Nanyang Technological University,RIKEN / The University of Tokyo,learning with multiple complementary labels.
2903,2903,35.0,Toyota Technological Institute at Chicago,University of Wisconsin-Madison,individual fairness for k-clustering.
2904,2904,36.0,University of Massachusetts Amherst,University of Massachusetts Amherst,learning from irregularly-sampled time series: a missing data perspective.
2905,2905,37.0,Google Brain,Google Brain,on implicit regularization in $\beta$-vaes.
2906,2906,38.0,UIUC,Carnegie Mellon University,characterizing distribution equivalence and structure learning for cyclic and acyclic directed graphs.
2907,2907,39.0,Northeastern University,Northeastern University,amortized population gibbs samplers with neural sufficient statistics.
2908,2908,40.0,University of Science and Technology of China,University of Science and Technology of China,generative flows with matrix exponential.
2909,2909,41.0,Google Research,Google Research,fedboost: a communication-efficient algorithm for federated learning.
2910,2910,42.0,Facebook AI Research,Facebook AI Research,student specialization in deep rectified networks with finite width and input dimension.
2911,2911,43.0,Stanford University,Stanford University,two routes to scalable credit assignment without weight symmetry.
2912,2912,44.0,Johns Hopkins University,Peking University,on the noisy gradient descent that generalizes as sgd.
2913,2913,45.0,Princeton University,Princeton University,"uncertainty quantification for nonconvex tensor completion: confidence intervals, heteroscedasticity and optimality."
2914,2914,46.0,Tianjin University,Fudan University,q-value path decomposition for deep multiagent reinforcement learning.
2915,2915,47.0,Tsinghua University,Army Academy of Artillery and Air Defense,"semismooth newton algorithm for efficient projections onto $\ell_{1, \infty}$-norm ball."
2916,2916,48.0,Northwestern University,Northwestern U,provably efficient exploration in policy optimization.
2917,2917,49.0,The University of Sydney,The University of Sydney,ltf: a label transformation framework for correcting label shift.
2918,2918,50.0,University of Pittsburgh,University of Pittsburgh,"expert learning through generalized inverse multiobjective optimization: models, insights, and algorithms."
2919,2919,51.0,Seoul National University of Science and Technology,Seoul National University of Science and Technology,confidence-aware learning for deep neural networks.
2920,2920,52.0,University of Michigan,DeepMind,what can learned intrinsic rewards capture?.
2921,2921,53.0,National Institute of Informatics,National Institute of Informatics,approximation guarantees of local search algorithms via localizability of set functions.
2922,2922,54.0,"National Laboratory of Radar Signal Processing, Xidian University",University of Texas at Austin,recurrent hierarchical topic-guided rnn for language generation.
2923,2923,55.0,Stanford University,Stanford,on the generalization effects of linear transformations in data augmentation.
2924,2924,56.0,Massachusetts Institute of Technology,Toyota Technological Institute at Chicago,fair learning with private demographic data.
2925,2925,57.0,Google Brain,"Google, Inc.",random hypervolume scalarizations for provable multi-objective black box optimization.
2926,2926,58.0,4Paradigm,Hong Kong University of Science and Technology,searching to exploit memorization effect in learning with noisy labels.
2927,2927,59.0,University of Catholique de Louvain,Boston University,minimax rate for learning from pairwise comparisons in the btl model.
2928,2928,60.0,Microsoft Research,Google Research,online learning for active cache synchronization.
2929,2929,61.0,university of pennsylvania,University of Pennsylvania,deltagrad: rapid retraining of machine learning models.
2930,2930,62.0,Cornell University,Cornell University,deep reasoning networks for unsupervised pattern de-mixing with constraint reasoning.
2931,2931,63.0,Peking University,Peking University,maximum-and-concatenation networks.
2932,2932,64.0,Harvard University,Stanford,causal strategic linear regression.
2933,2933,65.0,Nanjing University of Aeronautics and Astronautics,Nanjing University of Aeronautics and Astronautics,accelerated stochastic gradient-free and projection-free methods.
2934,2934,66.0,Rensselaer Polytechnic Institute,IBM Thomas J. Watson Research Center,fast learning of graph neural networks with guaranteed generalizability: one-hidden-layer case.
2935,2935,67.0,Microsoft Research,Microsoft,randomized smoothing of all shapes and sizes.
2936,2936,68.0,Google,Google,optimizing long-term social welfare in recommender systems: a constrained matching approach.
2937,2937,69.0,"Noah’s Ark Lab, Huawei Technologies",University of Sydney,training binary neural networks through learning with noisy supervision.
2938,2938,70.0,University of Pennsylvania,Upenn,reverse-engineering deep relu networks.
2939,2939,71.0,Carnegie Mellon University,Carnegie Mellon University,confidence sets and hypothesis testing in a likelihood-free inference setting.
2940,2940,72.0,Carnegie Mellon University,Carnegie Mellon University,familywise error rate control by interactive unmasking.
2941,2941,73.0,University of Southern California,USC Information Sciences Institute,all in the exponential family: bregman duality in thermodynamic variational inference.
2942,2942,74.0,University of Washington,University of Washington,"implicit learning dynamics in stackelberg games: equilibria characterization, convergence analysis, and empirical study."
2943,2943,75.0,"College of Intelligence and Computing, Tianjin University",Alibaba group,dynamic knapsack optimization towards efficient multi-channel sequential advertising.
2944,2944,76.0,TTIC,MIT,scalable nearest neighbor search for optimal transport.
2945,2945,77.0,Purdue University,Purdue University,mutual transfer learning for massive data.
2946,2946,78.0,University of Oxford,University of Oxford,bayesian optimisation over multiple continuous and categorical inputs.
2947,2947,79.0,UC Berkeley,UCLA,the buckley-osthus model and the block preferential attachment model: statistical analysis and application.
2948,2948,80.0,University of Illinois at Urbana-Champaign,University of Illinois at Urbana-Champaign,from importance sampling to doubly robust policy gradient.
2949,2949,81.0,Cornell University,Cornell,differentiating through the fréchet mean.
2950,2950,82.0,National University of Singapore,National University of Singapore,collaborative machine learning with incentive-aware model rewards.
2951,2951,83.0,University of Massachusetts Amherst,University of Massachusetts Amherst,optimizing for the future in non-stationary mdps.
2952,2952,84.0,Zhejiang University,Rutgers University,improving generative imagination in object-centric world models.
2953,2953,85.0,Stanford University,Stanford University,fair generative modeling via weak supervision.
2954,2954,86.0,Peking University,Peking University,distance metric learning with joint representation diversification.
2955,2955,87.0,Stanford University,Stanford University,distributionally robust policy evaluation and learning in offline contextual bandits.
2956,2956,88.0,Columbia University,DeepMind,taylor expansion policy optimization.
2957,2957,89.0,University of Science and Technology of China,University of Science and Technology of China,layered sampling for robust optimization problems.
2958,2958,90.0,the University of Iowa,The University of Iowa,stochastic optimization for non-convex inf-projection problems.
2959,2959,91.0,University of Wisconsin - Madison,University of Wisconsin - Madison,tensor denoising and completion based on ordinal observations.
2960,2960,92.0,National Taiwan University,National University of Singapore,manifold identification for ultimately communication-efficient distributed optimization.
2961,2961,93.0,Weierstrass Institute,Maastricht University,self-concordant analysis of frank-wolfe algorithms.
2962,2962,94.0,Open University of Israel,Yale,streaming submodular maximization under a k-set system constraint.
2963,2963,95.0,Rice University,University of Texas at Austin,autogan-distiller: searching to compress generative adversarial networks.
2964,2964,96.0,Amazon Web Services,Amazon Web Services,leep: a new measure to evaluate transferability of learned representations.
2965,2965,97.0,Carnegie Mellon University,Carnegie Mellon University,stochastic regret minimization in extensive-form games.
2966,2966,98.0,Carnegie Mellon University,Carnegie Mellon University,explaining groups of points in low-dimensional representations.
2967,2967,99.0,Boston University,Boston University,deep divergence learning.
2968,2968,100.0,Kyushu University,Kyushu University,nested subspace arrangement for representation of relational data.
2969,2969,101.0,University of Pennsylvania,University of Pennsylvania,generating programmatic referring expressions via program synthesis.
2970,2970,102.0,Autodesk,University of Toronto,contrastive multi-view representation learning on graphs.
2971,2971,103.0,Fred Hutchinson Cancer Research Center,University of Washington,efficient nonparametric statistical inference on population feature importance using shapley values.
2972,2972,104.0,The University of Chicago,Toyota Technological Institute at Chicago,multigrid neural memory.
2973,2973,105.0,Borealis AI,Borealis AI,on variational learning of controllable representations for text without supervision.
2974,2974,106.0,Nanjing University,Nanjing University,safe deep semi-supervised learning for unseen-class unlabeled data.
2975,2975,107.0,University of Massachusetts,University of Massachusetts Amherst,evaluating the performance of reinforcement learning algorithms.
2976,2976,108.0,Simon Fraser University,National Institute of Informatics,fast and private submodular and $k$-submodular functions maximization with matroid constraints.
2977,2977,109.0,Stanford University,DeepMind,improving the gating mechanism of recurrent neural networks.
2978,2978,110.0,"University of California, Berkeley","University of California, Berkeley",the effect of natural distribution shift on question answering models.
2979,2979,111.0,MIT-IBM Watson AI Lab,MIT,min-max optimization without gradients: convergence and applications to black-box evasion and poisoning attacks.
2980,2980,112.0,UMD,University of Maryland,on second-order group influence functions for black-box predictions.
2981,2981,113.0,University of Pennsylvania,University of Minnesota,oracle efficient private non-convex optimization.
2982,2982,114.0,Carnegie Mellon University,Carnegie Mellon University / Bosch Center for AI,overfitting in adversarially robust deep learning.
2983,2983,115.0,Columbia University,"Department of Statistics, Columbia University",neural clustering processes.
2984,2984,116.0,Massachusetts Institute of Technology,Massachusetts Institute of Technology,the tree ensemble layer: differentiability meets conditional computation.
2985,2985,117.0,MIT,MIT,online pricing with offline data: phase transition and inverse square law.
2986,2986,118.0,University of Wisconsin - Madison,University of Wisconsin-Madison,closing the convergence gap of sgd without replacement.
2987,2987,119.0,Carnegie Mellon University,Harvard University,strategyproof mean estimation from multiple-choice questions.
2988,2988,120.0,Purdue University,Columbia,efficient identification in linear structural causal models with auxiliary cutsets.
2989,2989,121.0,Shanghai Jiao Tong University,UM-SJTU JI,learning fair policies in multi-objective (deep) reinforcement learning with average and discounted rewards.
2990,2990,122.0,Microsoft research,Microsoft Research,drocc: deep robust one-class classification.
2991,2991,123.0,Indian Institute of Science,Microsoft Research India,near-optimal sample complexity bounds for learning latent $k-$polytopes and applications to ad-mixtures.
2992,2992,124.0,Institut National de la Recherche Scientifique (INRS),INRS-EMT,an end-to-end approach for the verification problem: learning the right distance.
2993,2993,125.0,Euclidean Technologies,Carnegie Mellon University,uncertainty-aware lookahead factor models for quantitative investing.
2994,2994,126.0,IBM Research,IBM Research,invariant risk minimization games.
2995,2995,127.0,University of Washington,University of Washington,estimating the number and effect sizes of non-null hypotheses.
2996,2996,128.0,Microsoft Research,Microsoft Research,working memory graphs.
2997,2997,129.0,Baidu Research,Baidu,rifle: backpropagation in depth for deep transfer learning through re-initializing the fully-connected layer.
2998,2998,130.0,Monash University,"Monash University, Australia",parameterized rate-distortion stochastic encoder.
2999,2999,131.0,Carnegie Mellon University,Carnegie Mellon University,an em approach to non-autoregressive conditional sequence generation.
3000,3000,132.0,KAIST,"KAIST, AITRICS",adversarial neural pruning with latent vulnerability suppression.
3001,3001,133.0,Dalhousie University/Vector Institute,Dalhousie University and Vector Institute,detecting out-of-distribution examples with gram matrices.
3002,3002,134.0,Harvard University,Harvard University,associative memory in iterated overparameterized sigmoid autoencoders.
3003,3003,135.0,Google Research,Google Brain,automl-zero: evolving machine learning algorithms from scratch.
3004,3004,136.0,Tsinghua University,Tsinghua University,nonparametric score estimators.
3005,3005,137.0,Stanford University,Stanford University,feature noise induces loss discrepancy across groups.
3006,3006,138.0,Rensselaer Polytechnic Institute,MERL,finite-time convergence in continuous-time optimization.
3007,3007,139.0,Princeton University,MIT,learning adversarial markov decision processes with bandit feedback and unknown transition.
3008,3008,140.0,Texas A&M University,Texas A&M University,nads: neural architecture distribution search for uncertainty awareness.
3009,3009,141.0,Google,Google Brain,representations for stable off-policy reinforcement learning.
3010,3010,142.0,Stanford University,Stanford,scalable identification of partially observed systems with certainty-equivalent em.
3011,3011,143.0,Google Research,Princeton University,boosting for control of dynamical systems.
3012,3012,144.0,Northwestern University,Northwestern U,generative adversarial imitation learning with neural network parameterization: global optimality and convergence rate.
3013,3013,145.0,KAIST,KAIST,batch reinforcement learning with hyperparameter  gradients.
3014,3014,146.0,RJ Research Consulting,HKUST,guided learning of nonconvex models through successive functional gradient optimization.
3015,3015,147.0,Technion – Israel Institute of Technology,Microsoft,discount factor as a regularizer in reinforcement learning .
3016,3016,148.0,Uber AI Labs,Uber AI Labs,parametric gaussian process regressors.
3017,3017,149.0,National Tsing Hua University,National Tsing Hua University,transfer learning without knowing: reprogramming black-box machine learning models with scarce data and limited resources.
3018,3018,150.0,University of Toronto,University of Toronto,distributed online optimization over a heterogeneous network.
3019,3019,151.0,Toyota Technological Institute at Chicago,Toyota Technological Institute at Chicago,is local sgd better than minibatch sgd?.
3020,3020,152.0,Microsoft,Microsoft,differentially private set union.
3021,3021,153.0,ZIB,"CERC Data Science, Polytechnique Montreal",on the unreasonable effectiveness of the greedy algorithm: greedy adapts to sharpness.
3022,3022,154.0,Peking University,Microsoft,informative dropout for robust representation learning: a shape-bias perspective.
3023,3023,155.0,University of Waterloo,University of Waterloo,stronger and faster wasserstein adversarial attacks.
3024,3024,156.0,University of Washington,University of Washington,meta-learning for mixed linear regression.
3025,3025,157.0,Rice University,Amazon AI & Caltech,angular visual hardness.
3026,3026,158.0,Stanford University,MIT,formulazero: distributionally robust online adaptation via offline population synthesis.
3027,3027,159.0,University of Oxford,University of Oxford,gradientdice: rethinking generalized offline estimation of stationary values.
3028,3028,160.0,IBM Research - India,IBM Research,power-bert: accelerating bert inference via progressive word-vector elimination.
3029,3029,161.0,Umass Amherst,University of Massachusetts Amherst,recovery of sparse signals from a mixture of linear samples.
3030,3030,162.0,University of Texas at Austin,University of Texas at Austin,safe imitation learning via fast bayesian reward inference from preferences.
3031,3031,163.0,Google Brain,Google / University of Alberta,scalable deep generative modeling for sparse graphs.
3032,3032,164.0,Google Research,Google Brain,disentangling trainability and generalization in deep neural networks.
3033,3033,165.0,University of Chicago,University of Chicago,on semi-parametric inference for bart.
3034,3034,166.0,Technion – Israel Institute of Technology,Technion – Israel Institute of Technology,fiduciary bandits.
3035,3035,167.0,Skolkovo Institute of Science and Technology,Skolkovo Institute of Science and Technology,low-loss connection of weight vectors: distribution-based approaches.
3036,3036,168.0,Northeastern University,"University of California, San Diego",multiresolution tensor learning for efficient and interpretable spatial analysis.
3037,3037,169.0,RIKEN AIP,RIKEN / The University of Tokyo,variational imitation learning with diverse-quality demonstrations.
3038,3038,170.0,Cornell University,Cornell University,context aware local differential privacy.
3039,3039,171.0,Stanford University,Stanford University,provable guarantees for decision tree induction: the agnostic setting .
3040,3040,172.0,University of Michigan,University of Michigan,two simple ways to learn individual fairness metrics from data.
3041,3041,173.0,University of Cambridge,University of Cambridge and UCLA,inverse active sensing: modeling and understanding timely decision-making.
3042,3042,174.0,UCLA,UCLA,stabilizing differentiable architecture search via perturbation-based regularization.
3043,3043,175.0,Columbia University,Columbia University,designing optimal dynamic treatment regimes: a causal reinforcement learning approach.
3044,3044,176.0,Tsinghua University,UIUC,a chance-constrained generative framework for sequence optimization.
3045,3045,177.0,Baidu Research,Baidu,non-autoregressive neural text-to-speech.
3046,3046,178.0,Google Research,Google,deep k-nn for noisy labels.
3047,3047,179.0,Stanford University,Adobe Research,structured policy iteration for linear quadratic regulator.
3048,3048,180.0,Texas A&M University,Texas A&M University,bayesian graph neural networks with adaptive connection sampling.
3049,3049,181.0,Bytedance,ByteDance AI Lab,dispersed exponential family mixture vaes for interpretable text generation.
3050,3050,182.0,"University of California, Berkeley",COVARIANT.AI,variable skipping for autoregressive range density estimation.
3051,3051,183.0,Facebook Inc.,Duke,cause: learning granger causality from event sequences using attribution methods.
3052,3052,184.0,National University of Singapore,"University of Nebraska, Lincoln",learning and sampling of atomic interventions from observations.
3053,3053,185.0,University of Pittsburgh,University of Pittsburgh,lookahead-bounded q-learning.
3054,3054,186.0,University of Pennsylvania,University of Pennsylvania,rank aggregation from pairwise comparisons in the presence of adversarial corruptions.
3055,3055,187.0,Stanford University,Stanford University,robustness to spurious correlations via human annotations.
3056,3056,188.0,Johns Hopkins University,UCLA,obtaining adjustable regularization for free via iterate averaging.
3057,3057,189.0,Duke University,SUNY Buffalo,variance reduction in stochastic particle-optimization sampling.
3058,3058,190.0,Carnegie Mellon University,Carnegie Mellon University / Bosch Center for AI,certified robustness to label-flipping attacks via randomized smoothing.
3059,3059,191.0,University of Washington,University of Washington,source separation with deep generative priors.
3060,3060,192.0,MIT,MIT,beyond ucb: optimal and efficient contextual bandits with regression oracles.
3061,3061,193.0,Stanford University,Stanford University,an investigation of why overparameterization exacerbates spurious correlations.
3062,3062,194.0,Shannon.AI,Shannon.AI,description based text classification with reinforcement learning.
3063,3063,195.0,ESTsoft,ESTsoft,being bayesian about categorical probability.
3064,3064,196.0,ENS Rennes,University of Copenhagen,tightening exploration in upper confidence reinforcement learning.
3065,3065,197.0,Uber AI,OpenAI,enhanced poet: open-ended reinforcement learning through unbounded invention of learning challenges and their solutions.
3066,3066,198.0,Intel Labs,Oregon State University US,evolutionary reinforcement learning for sample-efficient multiagent coordination.
3067,3067,199.0,UCLA,"University of California, Los Angeles",neural contextual bandits with ucb-based exploration.
3068,3068,200.0,University of Virginia,University of Virginia,learning adversarially robust representations via worst-case mutual information maximization.
3069,3069,201.0,Google,Google,retrieval augmented language model pre-training.
3070,3070,202.0,ETH Zürich,ETH Zurich,adversarial attacks on probabilistic autoregressive forecasting models.
3071,3071,203.0,University of Pittsburgh,University of Pittsburgh & JD Finance America Corporation,fast oscar and owl regression via safe screening rules.
3072,3072,204.0,The University of Texas at Austin,University of Texas at Austin,task-oriented active perception and planning in environments with partially known semantics.
3073,3073,205.0,Yale University,Emory University,boxhed: boosted exact hazard estimator with dynamic covariates.
3074,3074,206.0,University of South Florida,University of South Florida,a markov decision process model for socio-economic systems impacted by climate change.
3075,3075,207.0,Nanyang Technological University,Duke University,nearly linear row sampling algorithm for quantile regression.
3076,3076,208.0,Google Research,Microsoft Research,how good is the bayes posterior in deep neural networks really?.
3077,3077,209.0,University at Buffalo,SUNY Buffalo,feature quantization improves gan training.
3078,3078,210.0,Weizmann Institute of Science,Technion,learning algebraic multigrid using graph neural networks.
3079,3079,211.0,UCLA,UCLA,"closed loop neural-symbolic learning via integrating neural perception, grammar parsing, and symbolic reasoning."
3080,3080,212.0,Google Inc.,Google,the many shapley values for model explanation.
3081,3081,213.0,Seoul National University,Seoul National University,learning compound tasks without task-specific knowledge via imitation and self-supervised learning.
3082,3082,214.0,IIT Gandhinagar,IIT Gandhinagar,streaming coresets for symmetric tensor factorization.
3083,3083,215.0,UC Berkeley,UC Berkeley,hierarchically decoupled imitation for morphological transfer.
3084,3084,216.0,Sharif University of Technology,École Polytechnique Fédérale de Lausanne,lazyiter: a fast algorithm for counting markov equivalent dags and designing experiments.
3085,3085,217.0,Texas A&M University,Texas A&M University,generalization guarantees for sparse kernel approximation with entropic optimal features.
3086,3086,218.0,UC Berkeley,Google,softsort: a continuous relaxation for the argsort operator.
3087,3087,219.0,EPFL,Google Research,scaffold: stochastic controlled averaging for federated learning.
3088,3088,220.0,Princeton University,Princeton University and Institute for Advanced Study,a sample complexity separation between non-convex and convex meta-learning.
3089,3089,221.0,University of Michigan,Princeton University,robust one-bit recovery via relu generative networks: near-optimal statistical rate and global landscape analysis.
3090,3090,222.0,Uber AI Labs,Open AI,generative teaching networks: accelerating neural architecture search by learning to generate synthetic training data.
3091,3091,223.0,Technion,Technion,sub-goal trees -- a framework for goal-based reinforcement learning.
3092,3092,224.0,Google,Google,incremental sampling without replacement for sequence models.
3093,3093,225.0,DeepMind,Deepmind,bootstrap latent-predictive representations for multitask reinforcement learning.
3094,3094,226.0,UC Berkeley,UC Berkeley,"train big, then compress: rethinking model size for efficient training and inference of transformers."
3095,3095,227.0,UCSD,University of California at San Diego,when are non-parametric methods robust?.
3096,3096,228.0,DeepMind,DeepMind/University of Alberta,a simpler approach to accelerated optimization: iterative averaging meets optimism.
3097,3097,229.0,MIT,UC Berkeley,logarithmic regret for adversarial online control.
3098,3098,230.0,University of California San Diego,Tel-Aviv University,explainable k-means and k-medians clustering.
3099,3099,231.0,ETH Zurich,ETH Zurich,topological autoencoders.
3100,3100,232.0,UC Berkeley,University of California at Berkeley,deep isometric learning for visual recognition.
3101,3101,233.0,Google Research,Google Brain,automatic shortcut removal for self-supervised representation learning.
3102,3102,234.0,"University of California, Davis",UC Berkeley,error estimation for sketched svd via the bootstrap.
3103,3103,235.0,Carnegie Mellon University,Google,xtreme: a massively multilingual multi-task benchmark for evaluating cross-lingual generalisation.
3104,3104,236.0,OpenAI,OpenAI,generative pretraining from pixels.
3105,3105,237.0,New York University,New York University,generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data.
3106,3106,238.0,"Université Paris-Est, LIGM (UMR 8049), CNRS, ESIEE Paris",Facebook AI Research,fully parallel hyperparameter search: reshaped space-filling.
3107,3107,239.0,Georgia Institution of Technology,Georgia Institute of Technology,learning to stop while learning to predict.
3108,3108,240.0,Google,"Google Research, NY",federated learning with only positive labels.
3109,3109,241.0,Google Brain,"Google Brain, Google Inc.",how recurrent networks implement contextual processing in sentiment analysis.
3110,3110,242.0,The Hebrew University of Jerusalem,Carnegie Mellon University,online control of the false coverage rate and false sign rate.
3111,3111,243.0,"Google Research, Brain Team",Google Brain,revisiting spatial invariance with low-rank local connectivity.
3112,3112,244.0,INRIA,INRIA - Ecole Normale Supérieure,structured prediction with partial labelling through the infimum loss.
3113,3113,245.0,Carnegie Mellon University,Carnegie Mellon University,influence diagram bandits: variational thompson sampling for structured bandit problems.
3114,3114,246.0,University of Tuebingen,University of Tuebingen,differentiable likelihoods for fast inversion of 'likelihood-free' dynamical systems.
3115,3115,247.0,"CREST, ENSAE",University of Washington,harmonic decompositions of convolutional networks.
3116,3116,248.0,INSA de Lyon,INRIA - LORIA,optimally solving two-agent decentralized pomdps under one-sided information sharing .
3117,3117,249.0,Northwestern University,,global concavity and optimization in a class of dynamic discrete choice models.
3118,3118,250.0,University of Alberta,University of Alberta,selective dyna-style planning under limited model capacity.
3119,3119,251.0,University of Texas at Austin,UT Austin,on the theoretical properties of the network jackknife.
3120,3120,252.0,UC Berkeley,UC Berkeley & Covariant,responsive safety in reinforcement learning by pid lagrangian methods.
3121,3121,253.0,Stanford University,Stanford University,training deep energy-based models with f-divergence minimization.
3122,3122,254.0,UC San Diego,UCSD,optimal robust learning of discrete distributions from batches.
3123,3123,255.0,NVIDIA Research,Bar-Ilan University,on learning sets of symmetric elements.
3124,3124,256.0,Max Planck Institute for Software Systems (MPI-SWS),Max Planck Institute (MPI-SWS),policy teaching via environment poisoning: training-time adversarial attacks against reinforcement learning.
3125,3125,257.0,Stanford University,Stanford University,maximum likelihood with bias-corrected calibration is hard-to-beat at label shift adaptation.
3126,3126,258.0,Massachusetts Institute of Technology,MIT,kernel methods for cooperative multi-agent contextual bandits.
3127,3127,259.0,IIT/DeepMind,"unige, mit, iit",near-linear time gaussian process optimization with adaptive batching and resparsification.
3128,3128,260.0,ETH Zurich,ETH Zurich,adversarial robustness for code.
3129,3129,261.0,MPII,University of Bremen,online metric algorithms with untrusted predictions.
3130,3130,262.0,CREATIS Laboratory INSA Lyon,Jean Monnet University,a swiss army knife for minimax optimal transport.
3131,3131,263.0,Stanford University,Stanford University,domain adaptive imitation learning.
3132,3132,264.0,Stanford,Stanford University,understanding and mitigating the tradeoff between robustness and accuracy.
3133,3133,265.0,Stevens Institute of Technology,Stevens Institute of Technology,stochastically dominant distributional reinforcement learning.
3134,3134,266.0,University of Edinburgh,University of Edinburgh,bayesian experimental design for implicit models by mutual information neural estimation.
3135,3135,267.0,UTS/UCL,TTI-Chicago,learning deep kernels for non-parametric two-sample tests.
3136,3136,268.0,UIUC,Microsoft Research,optimization and analysis of the pap@k metric for recommender systems.
3137,3137,269.0,"University of California, Berkeley",UC Berkeley,rethinking bias-variance trade-off for generalization of neural networks.
3138,3138,270.0,Freie Universität Berlin,Freie Universität Berlin,when explanations lie: why many modified bp attributions fail.
3139,3139,271.0,Université Paris,Université Paris Diderot,quantum expectation-maximization for gaussian mixture models.
3140,3140,272.0,Stanford University,Stanford University,which tasks should be learned together in multi-task learning?.
3141,3141,273.0,Yandex,Yandex,optimal non-parametric learning in repeated contextual auctions with  strategic buyer.
3142,3142,274.0,Barcelona Supercomputing Center,Barcelona Supercomputing Center,"explore, discover and learn: unsupervised discovery of state-covering skills."
3143,3143,275.0,"University of California, San Diego",UCSD,information-theoretic local minima characterization and regularization.
3144,3144,276.0,"University of California, Merced","University of California, Merced","smaller, more accurate regression forests using tree alternating optimization."
3145,3145,277.0,MIT,Massachusetts Institute of Technology,causal structure discovery from distributions arising from mixtures of dags.
3146,3146,278.0,Siemens AG,Siemens AG,explainable and discourse topic-aware neural language understanding.
3147,3147,279.0,UC Santa Cruz,Shanghai Jiao Tong University,peer loss functions: learning from noisy labels without knowing noise rates.
3148,3148,280.0,German Research Center for Aritificial Intelligence (DFKI),German Research Center for Artificial Intelligence (DFKI),lowfer: low-rank bilinear pooling for link prediction.
3149,3149,281.0,Microsoft Research NYC,Google Research,bandits with adversarial scaling.
3150,3150,282.0,INRIA - Ecole Normale Supérieure,"INRIA, École Normale Supérieure",consistent structured prediction with max-min margin markov networks.
3151,3151,283.0,DeepMind,DeepMind,learning to simulate complex physics with graph networks.
3152,3152,284.0,TOTAL,Orange Labs,restarted bayesian online change-point detector achieves optimal detection delay.
3153,3153,285.0,University of Edinburgh,DeepMind,on contrastive learning for likelihood-free inference .
3154,3154,286.0,Skolkovo Institute of Science and Technology,Skoltech,bayesian sparsification of deep c-valued networks.
3155,3155,287.0,ETH Zurich - Max Planck Institute,Google Brain,weakly-supervised disentanglement without compromises.
3156,3156,288.0,DeepMind,DeepMind,a distributional view on multi-objective policy optimization.
3157,3157,289.0,Facebook AI Research,Facebook AI Research,word-level speech recognition with a letter to word encoder.
3158,3158,290.0,TU Darmstadt,ZIB,ipboost – non-convex boosting via integer programming.
3159,3159,291.0,Technion - Israel Institute of Technology,Google Israel,simgans: simulator-based generative adversarial networks for ecg synthesis to improve deep ecg classification.
3160,3160,292.0,Centre Borelli - ENS Paris-Saclay,ENS Cachan,learning the piece-wise constant graph structure of a varying ising model.
3161,3161,293.0,ETH Zürich,ETH Zurich,constructive universal high-dimensional distribution generation through deep relu networks.
3162,3162,294.0,Stanford University,Stanford University,understanding the curse of horizon in off-policy evaluation via conditional importance sampling.
3163,3163,295.0,Inria,Inria,meta-learning with shared amortized variational inference.
3164,3164,296.0,DeepMind,"New York University, CERN",normalizing flows on tori and spheres.
3165,3165,297.0,Facebook AI Research,Google Research,multi-step greedy reinforcement learning algorithms.
3166,3166,298.0,University of Cambridge,University of Cambridge,tasknorm: rethinking batch normalization for meta-learning.
3167,3167,299.0,Samsung,"Higher School of Economics, Samsung AI Center Moscow",controlling overestimation bias with truncated mixture of continuous distributional quantile critics.
3168,3168,300.0,UC Berkeley,Google,stochastic frank-wolfe for constrained finite-sum minimization.
3169,3169,301.0,Aix-Marseille University,Criteo AI Lab,partial trace regression and low-rank kraus decomposition.
3170,3170,302.0,University of Oxford,University of Oxford,ready policy one: world building through active learning.
3171,3171,303.0,Facebook AI,Facebook Artificial Intelligence Research,entropy minimization in emergent languages.
3172,3172,304.0,Criteo,Criteo AI Lab,learning disconnected manifolds: a no gan's land.
3173,3173,305.0,University of the Witwatersrand,Brown,learning portable representations for high-level planning.
3174,3174,306.0,Microsoft Research,Microsoft Research,gnn-film: graph neural networks with feature-wise linear modulation.
3175,3175,307.0,EPFL,EPFL,bayesian differential privacy for machine learning.
3176,3176,308.0,Deepmind,Facebook AI Research,growing action spaces.
3177,3177,309.0,Stanford University,Stanford,optimal randomized first-order methods for least-squares problems.
3178,3178,310.0,Max Planck Institute for Informatics,MPI Informatics,confidence-calibrated adversarial training: generalizing to unseen attacks.
3179,3179,311.0,University of Southern California,Univ. of Southern California,generalization to new actions in reinforcement learning.
3180,3180,312.0,Technion,Technion,online convex optimization in the random order model.
3181,3181,313.0,DeepMind,DeepMind,non-stationary delayed bandits with intermediate observations.
3182,3182,314.0,University of Oxford,University of Oxford,uncertainty estimation using a single deep deterministic neural network.
3183,3183,315.0,"University of Mons, Belgium.",KU Leuven,inertial block proximal methods for non-convex non-smooth optimization.
3184,3184,316.0,ETH Zurich,MIT,constant curvature graph convolutional networks.
3185,3185,317.0,Università della Svizzera Italiana,University of Manitoba,graph random neural features for distance-preserving graph representations.
3186,3186,318.0,INRIA,Université de Montpellier,implicit differentiation of lasso-type models for hyperparameter optimization.
3187,3187,319.0,Politecnico di Milano,Politecnico di Milano,sequential transfer in reinforcement learning with a generative model.
3188,3188,320.0,DeepMind / Imperial College London,DeepMind,an explicitly relational neural network architecture.
3189,3189,321.0,University of Liège,University of Liège,likelihood-free mcmc with amortized approximate ratio estimators.
3190,3190,322.0,University of Southern California,Intel Labs,sample factory: egocentric 3d control from pixels at 100000 fps with asynchronous reinforcement learning.
3191,3191,323.0,Freie Universität Berlin,FU Berlin,equivariant flows: exact likelihood generative learning for symmetric densities.
3192,3192,324.0,Institut Polytechnique de Paris / University of Oxford,Rutgers University,fractional underdamped langevin dynamics: retargeting sgd with momentum under heavy-tailed gradient noise.
3193,3193,325.0,Qualcomm AI Research,University of Amsterdam,predictive sampling with forecasting autoregressive models.
3194,3194,326.0,Technion,Technion,beyond signal propagation: is feature diversity necessary in deep neural network initialization?.
3195,3195,327.0,Aarhus University,"Aarhus University, MADALGO",near-tight margin-based generalization bounds for support vector machines.
3196,3196,328.0,University of Aberdeen,University of Surrey,latent space factorisation and manipulation via matrix subspace projection.
3197,3197,329.0,Télécom Paris,"Télécom ParisTech, Université Paris-Saclay,Paris, France",duality in rkhss with infinite dimensional outputs: application to robust losses.
3198,3198,330.0,"IPhT, CEA Saclay",CNRS,the role of regularization in classification of high-dimensional noisy gaussian mixture.
3199,3199,331.0,University of Milan,Istituto Italiano di Tecnologia and University College London,meta-learning with stochastic linear bandits.
3200,3200,332.0,UCLA,University of Cambridge and UCLA,frequentist uncertainty in recurrent neural networks via blockwise influence functions.
3201,3201,333.0,Université catholique de Louvain,Universite catholique de Louvain,inexact tensor methods with dynamic accuracies.
3202,3202,334.0,Swiss Data Science Center EPFL/ETH,Columbia University,distinguishing cause from effect using quantiles: bivariate quantile causal discovery.
3203,3203,335.0,DeepMind,DeepMind,learning with good feature representations in bandits and in rl with a generative model.
3204,3204,336.0,MIT CSAIL,MIT,linear mode connectivity and the lottery ticket hypothesis.
3205,3205,337.0,"University of California, San Diego",Google Research,adaptive sampling for estimating probability distributions.
3206,3206,338.0,Harvard University,Georgia Institute of Technology,temporal logic point processes.
3207,3207,339.0,Yandex,Yandex,stochasticrank: global optimization of scale-free discrete functions.
3208,3208,340.0,"Data61, The Australian National University and the University of Sydney",Google Research,supervised learning: no loss no cry.
3209,3209,341.0,University of Oxford,"unige, mit, iit",decentralised learning with random features and distributed gradient descent.
3210,3210,342.0,University of Basel,Friedrich Miescher Institute,finding trainable sparse networks through neural tangent transfer .
3211,3211,343.0,Istituto Italiano di Tecnologia - University College London,Istituto Italiano di Tecnologia,on the iteration complexity of hypergradient computation.
3212,3212,344.0,Università di Pisa,Università di Pisa,why are learned indexes so effective?.
3213,3213,345.0,DeepMind,DeepMind,options as responses: grounding behavioural hierarchies in multi-agent reinforcement learning.
3214,3214,346.0,CMU,EPFL,near input sparsity time kernel embeddings via adaptive sampling.
3215,3215,347.0,Google,"Google Research, Zurich",fast differentiable sorting and ranking.
3216,3216,348.0,University of Oxford,University of Oxford,training neural networks for and by interpolation.
3217,3217,349.0,University College London,Facebook AI Research & University College London,learning reasoning strategies in end-to-end differentiable proving.
3218,3218,350.0,Tel Aviv University,Tel Aviv University,logarithmic regret for learning linear quadratic regulators efficiently.
3219,3219,351.0,UC Berkeley,MIT,improving molecular design by stochastic iterative target augmentation.
3220,3220,352.0,"University of Texas, Austin",University of Texas at Austin,thompson sampling via local uncertainty.
3221,3221,353.0,Rice University,University of Southern California,compressive sensing with un-trained neural networks: gradient descent finds a smooth approximation.
3222,3222,354.0,Georgia Tech,Baidu,optimal estimator for unlabeled linear regression.
3223,3223,355.0,Tel-Aviv University & Facebook AI Research,Facebook AI Research and Tel Aviv University,voice separation with an unknown number of multiple speakers.
3224,3224,356.0,University of Bristol,University of Bristol,why bigger is not always better: on finite and infinite neural networks.
3225,3225,357.0,Technical University of Munich,Technical University of Munich,learning similarity metrics for numerical simulations.
3226,3226,358.0,Google,Google,"interpretable, multidimensional, multimodal anomaly detection with negative sampling for detection of device failure."
3227,3227,359.0,ETH,ETH,simple and sharp analysis of k-means||.
3228,3228,360.0,MIT,MIT,continuously indexed domain adaptation.
3229,3229,361.0,University of Oxford,U Oxford,knowing the what but not the where in bayesian optimization.
3230,3230,362.0,CEA,CentraleSupélec,random matrix theory proves that deep learning representations of gan-data behave as gaussian mixtures.
3231,3231,363.0,Inria,Inria,debiased sinkhorn barycenters.
3232,3232,364.0,UT Austin,UT Austin & Amazon,extreme multi-label classification from aggregated labels.
3233,3233,365.0,University of Cambridge,Google Brain,infinite attention: nngp and ntk for deep attention networks.
3234,3234,366.0,Cornell University,Harvard University,double reinforcement learning for efficient and robust off-policy evaluation.
3235,3235,367.0,Princeton University,Princeton University,when deep denoising meets iterative phase retrieval.
3236,3236,368.0,CNRS/LIP6,CNRS/LIP6,interferometric graph transform: a deep unsupervised graph representation.
3237,3237,369.0,National University of Singapore,National University of Singapore,thompson sampling algorithms for mean-variance bandits.
3238,3238,370.0,University of Illinois at Urbana-Champaign,MIT-IBM Watson AI Lab,unsupervised speech decomposition via triple information bottleneck.
3239,3239,371.0,McGill University,McGill University / DeepMind,invariant causal prediction for block mdps.
3240,3240,372.0,MIT,Massachusetts Institute of Technology,estimating generalization under distribution shifts via domain-invariant representations.
3241,3241,373.0,"Information Technology University, Lahore",Northeastern University,invertible generative models for inverse problems: mitigating representation error and dataset bias.
3242,3242,374.0,National University of Singapore,"National University of Singapore,",attacks which do not kill training make adversarial learning stronger.
3243,3243,375.0,Nagoya Institute of Technology,Nagoya Institute of Technology,multi-fidelity bayesian optimization with max-value entropy search and its parallelization.
3244,3244,376.0,Beijing Institute of Technology,Beijing Institute of Technology,tuning-free plug-and-play proximal algorithm for inverse imaging problems.
3245,3245,377.0,University of Amsterdam,University of Amsterdam,learning to learn kernels with variational random features.
3246,3246,378.0,NTT,RIKEN / The University of Tokyo,accelerating the diffusion-based ensemble sampling by non-reversible dynamics.
3247,3247,379.0,TTI-Chicago,Toyota Technological Institute at Chicago,efficiently learning adversarially robust halfspaces with noise.
3248,3248,380.0,New York University,New York University Shanghai,striving for simplicity and performance in off-policy drl: output normalization and non-uniform sampling.
3249,3249,381.0,University of Connecticut,University of Connecticut,logistic regression for massive data with rare events.
3250,3250,382.0,Fujitsu Laboratories Ltd.,Fujitsu Laboratories Ltd.,rate-distortion optimization guided autoencoder for isometric embedding in euclidean latent space.
3251,3251,383.0,University of Technology Sydney,University of Technology Sydney,intrinsic reward driven imitation learning via generative model.
3252,3252,384.0,Mitsubishi Electric Corporation,Mitsubishi Electric Research Labs,can increasing input dimensionality improve deep reinforcement learning?.
3253,3253,385.0,Tokyo Institute of Technology.,Cyberagent,counterfactual cross-validation: stable model selection procedure for causal inference models.
3254,3254,386.0,Nanjing University,Nanjing University,learning with feature and distribution evolvable streams.
3255,3255,387.0,Salesforce,Nanjing University of Information Science & Technology,hybrid stochastic-deterministic minibatch proximal gradient: less-than-single-pass optimization with nearly optimal generalization.
3256,3256,388.0,"Institute of Computing Technology, Chinese Academy of Sciences","Institute of Computing Technology, CAS, China",on the relation between quality-diversity evaluation and distribution-fitting goal in text generation.
3257,3257,389.0,Korea University,"Clova AI Research, NAVER Corp.",learning de-biased representations with biased representations.
3258,3258,390.0,Fudan university,HongKong University of Science and Technology and Peking University,dessilbi: exploring structural sparsity of deep networks via differential inclusion paths.
3259,3259,391.0,National Taiwan University,RIKEN / The University of Tokyo,unbiased risk estimators can mislead: a case study of learning with complementary labels.
3260,3260,392.0,University of Pittsburgh,University of Pittsburgh & JD Finance America Corporation,can stochastic zeroth-order frank-wolfe method converge faster for non-convex problems?.
3261,3261,393.0,Princeton University,Princeton University,efficient non-conjugate gaussian process factor models for spike count data using polynomial approximations.
3262,3262,394.0,Columbia University,Columbia,causal effect identifiability under partial-observability.
3263,3263,395.0,Carnegie Mellon University,Carnegie Mellon University / Bosch Center for AI,combining differentiable pde solvers and graph neural networks for fluid flow prediction.
3264,3264,396.0,Harvard University,Harvard,convolutional dictionary learning based auto-encoders for natural exponential-family distributions.
3265,3265,397.0,Johns Hopkins University,UMass Amherst; DARPA,abstraction mechanisms predict generalization in deep neural networks.
3266,3266,398.0,Cornell University,University of Minnesota,privately learning markov random fields.
3267,3267,399.0,Massachusetts Institute of Technology,Massachusetts Institute of Technology,consistent estimators for learning to defer to an expert.
3268,3268,400.0,Carnegie Mellon University,CMU,on learning language-invariant representations for universal machine translation.
3269,3269,401.0,Princeton University,Princeton University and Institute for Advanced Study,instahide: instance-hiding schemes for private distributed learning.
3270,3270,402.0,Purdue University,"Purdue University, USA",one size fits all: can we train one denoiser for all noise levels?.
3271,3271,403.0,Johns Hopkins University,"Weizmann Institute of Science, Israel","schatten norms in matrix streams: hello sparsity, goodbye dimension."
3272,3272,404.0,University of Toronto,Vector Institute,causal modeling for fairness in dynamical systems.
3273,3273,405.0,"University of California, Berkeley",RealAI,vflow: more expressive generative flows with variational data augmentation.
3274,3274,406.0,The Chinese University of HongKong,The University of Hong Kong,channel equilibrium networks for learning deep representation.
3275,3275,407.0,Yale University,Yale University,data preprocessing to mitigate bias: a maximum entropy based approach.
3276,3276,408.0,Yale University,Yale University,trajectorynet: a dynamic optimal transport network for modeling cellular dynamics.
3277,3277,409.0,Harvard,Harvard,improved communication cost in distributed pagerank computation – a theoretical study.
3278,3278,410.0,Mila/UdeM,"Preferred Networks, Inc.",learning structured latent factors from dependent data:a generative model framework from information-theoretic perspective.
3279,3279,411.0,Columbia University,Columbia University,reinforcement learning for integer programming: learning to cut.
3280,3280,412.0,Oregon State University,Horizon Robotics,implicit generative modeling for efficient exploration.
3281,3281,413.0,ETH Zurich,ETH Zurich,an accelerated dfo algorithm for finite-sum convex functions.
3282,3282,414.0,University of Maryland,University of Maryland,second-order provable defenses against adversarial attacks.
3283,3283,415.0,Harvard,University of Pennsylvania,robust and stable black box explanations.
3284,3284,416.0,Rice University,Rice University,learnable group transform for time-series.
3285,3285,417.0,Google Brain,Google Brain,the neural tangent kernel in high dimensions: triple descent and a multi-scale theory of generalization.
3286,3286,418.0,MIT,MIT,identifying statistical bias in dataset replication.
3287,3287,419.0,Stanford University,Stanford University,robust bayesian classification using an optimistic score ratio.
3288,3288,420.0,The University of Texas at Austin,MIT,learning quadratic games on networks.
3289,3289,421.0,Khoury College of Computer Sciences,Northeastern University,fair k-centers via maximum matching.
3290,3290,422.0,MIT,Massachusetts Institute of Technology,optimal approximation for unconstrained non-submodular minimization.
3291,3291,423.0,MIT,Massachusetts Institute of Technology,complexity of finding stationary points of nonconvex nonsmooth functions.
3292,3292,424.0,Rice University,Rice University,sub-linear memory sketches for near neighbor search on streaming data.
3293,3293,425.0,"Google Research, Brain Team","Google Research, Brain Team",an optimistic perspective on offline deep reinforcement learning.
3294,3294,426.0,Google Research,"Google Research, NY",accelerating large-scale inference with anisotropic vector quantization.
3295,3295,427.0,University of Waterloo,"University of Waterloo, Electrical and Computer Engineering",online bayesian moment matching based sat solver heuristics.
3296,3296,428.0,KAIST,KAIST,learning what to defer for maximum independent sets.
3297,3297,429.0,National University of Singapore,National University of Singapore,best arm identification for cascading bandits in the fixed confidence setting.
3298,3298,430.0,University of Sydney,University of Sydney,neural architecture search in a proxy validation loss landscape.
3299,3299,431.0,McGill University; Mila; Facebook AI Research,Facebook,on the convergence of nesterov's accelerated gradient method in stochastic settings.
3300,3300,432.0,Cornell University,Microsoft Research,adaptive estimator selection for off-policy evaluation.
3301,3301,433.0,Carnegie Mellon University,DeepMind,stabilizing transformers for reinforcement learning.
3302,3302,434.0,Baidu Inc.,The University of Sydney,label-noise robust domain adaptation.
3303,3303,435.0,Seoul National University,Seoul National University,operation-aware soft channel pruning using differentiable masks.
3304,3304,436.0,"McGill University,  Mila Montreal",DeepMind,what can i do here? a theory of affordances in reinforcement learning.
3305,3305,437.0,Peking University,Peking University,don't waste your bits! squeeze activations and gradients for deep neural networks via tinyscript.
3306,3306,438.0,UC Berkeley,UC Berkeley,finite-time last-iterate convergence for multi-agent learning in games.
3307,3307,439.0,Stanford University,Stanford,fast and three-rious: speeding up weak supervision with triplet methods.
3308,3308,440.0,University of Michigan,University of Michigan,preference modeling with context-dependent salient features.
3309,3309,441.0,"VinAI Research, Vietnam",VinAI Research,on unbalanced optimal transport: an analysis of sinkhorn algorithm.
3310,3310,442.0,Massachusetts Institute of Technology,MIT,prediction-guided multi-objective reinforcement learning for continuous robot control.
3311,3311,443.0,IAS,Harvard,dynamics of deep neural networks and neural tangent hierarchy.
3312,3312,444.0,Duke University,Duke University,adaptive droplet routing in digital microfluidic biochips using deep reinforcement learning.
3313,3313,445.0,The University of Queensland,University of Queensland,progressive graph learning for open-set domain adaptation.
3314,3314,446.0,University of Minnesota,University of Minnesota,message passing least squares framework and its application to rotation synchronization.
3315,3315,447.0,Harvard University,MIT,optimal bounds between f-divergences and integral probability metrics.
3316,3316,448.0,Texas A&M University,Texas A&M University,eliminating the invariance on the loss landscape of linear autoencoders.
3317,3317,449.0,Facebook AI Research,New York University,the differentiable cross-entropy method.
3318,3318,450.0,University of Maryland,International Computer Science Institute,measuring non-expert comprehension of machine learning fairness metrics.
3319,3319,451.0,Rutgers,Duke University,the cost-free nature of optimally tuning tikhonov regularizers and other ordered smoothers.
3320,3320,452.0,University of Wisconsin-Madison,University of Wisconsin - Madison,adversarial risk via optimal transport and optimal couplings.
3321,3321,453.0,Google,Google,population-based black-box optimization for biological sequence design.
3322,3322,454.0,North Carolina State University,North Carolina State University,on validation and planning of an optimal decision rule with application in healthcare studies.
3323,3323,455.0,University of Massachusetts Amherst,UMass,efficient intervention design for causal discovery with latents.
3324,3324,456.0,MIT,MIT,hierarchical generation of molecular graphs using structural motifs.
3325,3325,457.0,Shanghai Jiao Tong University,Texas A&M University,median matrix completion: from embarrassment to optimality.
3326,3326,458.0,HKBU / RIKEN,RIKEN / The University of Tokyo,sigua: forgetting may make learning with noisy labels more robust.
3327,3327,459.0,Southeast University,Southeast University,variational label enhancement.
3328,3328,460.0,Rutgers University-Newark,Rutgers University-Newark,sequential cooperative bayesian inference.
3329,3329,461.0,Duke,Duke University,learning opinions in social networks.
3330,3330,462.0,Cornell University,Cornell,moniqua: modulo quantized communication in decentralized sgd.
3331,3331,463.0,The Ohio State University,University of Minnesota,private query release assisted by public data.
3332,3332,464.0,university of Pittsburgh,University of Pittsburgh & JD Finance America Corporation,sparse shrunk additive models.
3333,3333,465.0,MIT,MIT,strength from weakness: fast learning using weak supervision.
3334,3334,466.0,Massachusetts Institute of Technology,MIT, predicting deliberative outcomes.
3335,3335,467.0,University of Wisconsin-Madison,University of Wisconsion-Madison,robust outlier arm identification.
3336,3336,468.0,Virginia Commonwealth University,Virginia Commonwealth University,approximation capabilities of neural odes and invertible residual networks.
3337,3337,469.0,Stanford University,Google,optimizing black-box metrics with adaptive surrogates.
3338,3338,470.0,South China University of Technology,South China University of Technology,breaking the curse of space explosion: towards efficient nas with curriculum search.
3339,3339,471.0,Mila,CNRS/LIP6,decoupled greedy learning of cnns.
3340,3340,472.0,Microsoft Research,CMU,the non-iid data quagmire of decentralized machine learning.
3341,3341,473.0,Peking University,Peking University,(locally) differentially private combinatorial semi-bandits.
3342,3342,474.0,Google,UC Berkeley,circuit-based intrinsic methods to detect overfitting.
3343,3343,475.0,NVIDIA Research,Sanctuary AI,undirected graphical models as approximate posteriors.
3344,3344,476.0,Inria Paris,"Centrum Wiskunde & Informatica, Amsterdam",structure adaptive algorithms for stochastic bandits.
3345,3345,477.0,Microsoft Research,Microsoft Research Cambridge,alleviating privacy attacks via causal learning.
3346,3346,478.0,Intel Labs,Intel Corporation,approximating stacked and bidirectional recurrent architectures with the delayed recurrent neural network.
3347,3347,479.0,Johns Hopkins University,Johns Hopkins University,coresets for clustering in graphs of bounded treewidth.
3348,3348,480.0,Stanford University,Stanford University,individual calibration with randomized forecasting.
3349,3349,481.0,UC Berkeley,UC Berkeley,learning to score behaviors for guided policy optimization.
3350,3350,482.0,Zhejiang University,UIUC,adversarial mutual information for text generation.
3351,3351,483.0,"University of California, San Diego","University of California, San Diego",divide and conquer: leveraging intermediate feature representations for quantized training of neural networks.
3352,3352,484.0,University of Pennsylvania,"CMU, FAIR",planning to explore via self-supervised world models.
3353,3353,485.0,National University of Singapore,National University of Singapore,private outsourced bayesian optimization.
3354,3354,486.0,Indian Institute of Science and Google Brain,Google,learning and evaluating contextual embedding of source code.
3355,3355,487.0,Facebook Reality Labs,Facebook Reality Labs,a sequential self teaching approach for improving generalization in sound event recognition.
3356,3356,488.0,KAIST,KAIST,polynomial tensor sketch for element-wise function of low-rank matrix.
3357,3357,489.0,University of Notre Dame,University of Notre Dame,representing unordered data using complex-weighted multiset automata.
3358,3358,490.0,Princeton University,Princeton,identifying the reward function by anchor actions.
3359,3359,491.0,Haverford College,Harvard University,predictive multiplicity in classification.
3360,3360,492.0,Samsung Research China - Beijing,Microsoft Research,the usual suspects? reassessing blame for vae posterior collapse.
3361,3361,493.0,Walmart Labs,University of Minnesota,structured linear contextual bandits: a sharp and geometric smoothed analysis.
3362,3362,494.0,McMaster University,York University,black-box certification and learning under adversarial perturbations.
3363,3363,495.0,UIUC,Princeton,optimal transport mapping via input convex neural networks.
3364,3364,496.0,Princeton University,Stanford,a general recurrent state space framework for modeling neural dynamics during decision-making.
3365,3365,497.0,Yale Univ,Duke University,spectral graph matching and regularized quadratic relaxations: algorithm and theory.
3366,3366,498.0,IIT Gandhinagar,IIT Gandhinagar,on coresets for regularized regression.
3367,3367,499.0,"NTU, Singapore","NTU, Singapore",communication-efficient distributed pca by riemannian optimization.
3368,3368,500.0,Cornell University,New York University,randomly projected additive gaussian processes for regression.
3369,3369,501.0,University of Kaiserslautern,SUNY Albany,fine-grained analysis of stability and generalization for stochastic gradient descent.
3370,3370,502.0,Lehigh University,Lehigh University,pretrained generalized autoregressive model with adaptive probabilistic label clusters for extreme multi-label text classification.
3371,3371,503.0,University of Texas at Austin,University of Texas at Austin,superpolynomial lower bounds for learning one-layer neural networks using gradient descent.
3372,3372,504.0,Rice University,Rice University,negative sampling in semi-supervised learning.
3373,3373,505.0,Stanford,Stanford University,sample amplification: increasing dataset size even when learning is impossible.
3374,3374,506.0,"Mila, McGill University",McGill University and Mila,inductive relation prediction by subgraph reasoning.
3375,3375,507.0,UC Berkeley,UC Berkeley,frustratingly simple few-shot object detection.
3376,3376,508.0,The University of Haifa,The University of Haifa,sets clustering.
3377,3377,509.0,University of British Columbia,University of British Columbia,online mirror descent and dual averaging: keeping pace in the dynamic case.
3378,3378,510.0,UC Berkeley,KAIST,context-aware dynamics model for generalization in model-based reinforcement learning.
3379,3379,511.0,UC Berkeley,University of Pennsylvania,cautious adaptation for reinforcement learning in safety-critical settings.
3380,3380,512.0,National University of Singapore,MIT,reinforcement learning for non-stationary markov decision processes: the blessing of (more) optimism.
3381,3381,513.0,"ENS Paris-Saclay, Inria",DeepMind,budgeted online influence maximization.
3382,3382,514.0,Stanford University,Stanford University,understanding self-training for gradual domain adaptation.
3383,3383,515.0,Carnegie Mellon University,University of Washington,infogan-cr and modelcentrality: self-supervised model training and selection for disentangling gans.
3384,3384,516.0,"University of California, Los Angeles","University of California, Los Angeles",scaling up hybrid probabilistic inference with logical and arithmetic constraints via message passing.
3385,3385,517.0,Carnegie Mellon University,Carnegie Mellon University,on conditional versus marginal bias in multi-armed bandits.
3386,3386,518.0,UC Berkeley,USC,safe screening rules for l0-regression from perspective relaxations.
3387,3387,519.0,University of Utah,University of Utah,self-modulating nonparametric event-tensor factorization.
3388,3388,520.0,Carnegie Mellon University,Carnegie Mellon University,class-weighted classification: trade-offs and robust approaches.
3389,3389,521.0,Google Brain,D. E. Shaw,imputer: sequence modelling via imputation and dynamic programming.
3390,3390,522.0,Cornell University,Cornell University,choice set optimization under discrete choice models of group decisions.
3391,3391,523.0,Allen Institute for AI,University of Washington,adversarial filters of dataset biases.
3392,3392,524.0,MIT,Massachusetts Institute of Technology,proper network interpretability helps adversarial robustness in classification.
3393,3393,525.0,"University of California, Santa Barbara","University of California, Santa Barbara",boosting deep neural network efficiency with dual-module inference.
3394,3394,526.0,UC Berkeley,UC Berkeley,stochastic gradient and langevin processes.
3395,3395,527.0,Texas A&M University,Texas A&M University,exploration through reward biasing: reward-biased maximum likelihood estimation for stochastic multi-armed bandits.
3396,3396,528.0,Stanford University,Apple Inc.,fundamental tradeoffs between invariance and sensitivity to adversarial perturbations.
3397,3397,529.0,Cornell University,Cornell University,efficient policy learning from surrogate-loss classification reductions.
3398,3398,530.0,Georgia Tech,Georgia Institute of Technology,retro*: learning retrosynthetic planning with neural guided a* search.
3399,3399,531.0,Peking University,Peking University,implicit euler skip connections: enhancing adversarial robustness via numerical stability.
3400,3400,532.0,The University of Texas at Austin,UT Austin,accountable off-policy evaluation with kernel bellman statistics.
3401,3401,533.0,University of Virginia,University of Cambridge and UCLA,learning for dose allocation in adaptive clinical trials with safety constraints.
3402,3402,534.0,UCSD,Apple Inc,optimal sequential maximization: one interview is enough!.
3403,3403,535.0,Technion - Israel Institute of Technology,Technion,structural language models of code.
3404,3404,536.0,Lawrence Livermore National Laboratory,LLNL,mix-n-match : ensemble and compositional methods for uncertainty calibration in deep learning.
3405,3405,537.0,Stanford University,Stanford University,a mean field analysis of deep resnet and beyond: towards  provably optimization via overparameterization from depth.
3406,3406,538.0,ETH Zurich,ETH Zurich,set functions for time series .
3407,3407,539.0,Salesforce Research,Princeton University,provable self-play algorithms for competitive reinforcement learning.
3408,3408,540.0,Georgia Institute of Technoloy,Georgia Institute of Technology,sde-net: equipping deep neural networks with uncertainty estimates.
3409,3409,541.0,OpenAI,OpenAI,leveraging procedural generation to benchmark reinforcement learning.
3410,3410,542.0,University of Alberta,DeepMind,low-variance and zero-variance baselines for extensive-form games.
3411,3411,543.0,Columbia University,Google Research,dual mirror descent for online allocation problems.
3412,3412,544.0,UC Berkeley,"University of California, Berkeley",balancing competing objectives with noisy data: score-based classifiers for welfare-aware machine learning.
3413,3413,545.0,KTH Royal Institute of Technology,KTH Royal Institute of Technology,fast and consistent learning of hidden markov models by incorporating non-consecutive correlations.
3414,3414,546.0,"CNRS, IRIT",CNRS,ordinal non-negative matrix factorization for recommendation.
3415,3415,547.0,Google Brain,Illinois / Google,on the consistency of top-k surrogate losses.
3416,3416,548.0,Massachusetts Institute of Technology,MIT,cooperative multi-agent bandits with heavy tails.
3417,3417,549.0,UC Berkeley,Technion,hallucinative topological memory for zero-shot visual planning.
3418,3418,550.0,Rice University,Stanford University,flexible and efficient long-range planning through curious exploration.
3419,3419,551.0,CREATIS Laboratory INSA Lyon,CREATIS,margin-aware adversarial domain adaptation with optimal transport.
3420,3420,552.0,IIT Delhi,Carnegie Mellon University / Bosch Center for AI,adversarial robustness against the union of multiple perturbation models.
3421,3421,553.0,UCLA,UCLA,optimization theory for relu neural networks trained with normalization layers.
3422,3422,554.0,University of Chicago,Toyota Technological Institute at Chicago,correlation clustering with asymmetric classification errors.
3423,3423,555.0,University of Alberta,University of Alberta,batch stationary distribution estimation.
3424,3424,556.0,University of Tübingen,U Tübingen,netgan without gan: from random walks to low-rank approximations.
3425,3425,557.0,University of Oxford,University of Oxford,"can autonomous vehicles identify, recover from, and adapt to distribution shifts?."
3426,3426,558.0,UC Berkeley,"University of California, Berkeley",test-time training with self-supervision for generalization under distribution shifts.
3427,3427,559.0,RIKEN Center for Advanced Intelligence Project,RIKEN,evolutionary topology search for tensor network decomposition.
3428,3428,560.0,Facebook,University of Maryland,the impact of neural network overparameterization on gradient confusion and stochastic gradient descent.
3429,3429,561.0,Apple,Apple & Univesity of Washington,adascale sgd: a user-friendly algorithm for distributed training.
3430,3430,562.0,Stanford,Stanford University,neural networks are convex regularizers: exact polynomial-time convex optimization formulations for two-layer networks.
3431,3431,563.0,University of Washington,UW,time-consistent self-supervision for semi-supervised learning.
3432,3432,564.0,Jagiellonian University,"Warsaw University of Technology, Tooploox",hypernetwork approach to generating point clouds.
3433,3433,565.0,UCLA Psychology Department,Princeton University,learning representations that support extrapolation.
3434,3434,566.0,UC Berkeley,Microsoft Research,single point transductive prediction.
3435,3435,567.0,UC Berkeley,UC Berkeley,continuous-time lower bounds for gradient-based algorithms.
3436,3436,568.0,California Institute of Technology,Microsoft Research,learning calibratable policies using programmatic style-consistency.
3437,3437,569.0,DeepMind,DeepMind,fast computation of nash equilibria in imperfect information games.
3438,3438,570.0,University of Tübingen,University of Tuebingen,"being bayesian, even just a bit, fixes overconfidence in relu networks."
3439,3439,571.0,Stanford University,Stanford,efficiently solving mdps with stochastic mirror descent.
3440,3440,572.0,UC Santa Barbara,"University of California, Santa Barbara",quantized decentralized stochastic learning over directed graphs.
3441,3441,573.0,University of Washington,Univ. Of Washington,a game theoretic framework for model based reinforcement learning.
3442,3442,574.0,The Ohio State University,The Ohio State University,the sample complexity of best-$k$ items selection from pairwise comparisons.
3443,3443,575.0,Google Brain (AI Residency),Google,efficient and scalable bayesian neural nets with rank-1 factors.
3444,3444,576.0,Otto-von-Guerricke University,DeepMind,stochastic bandits with arm-dependent delays.
3445,3445,577.0,Autodesk Research,Autodesk Research,learning to simulate and design for structural engineering.
3446,3446,578.0,UCLA,University of Cambridge and UCLA,temporal phenotyping using deep predictive clustering of disease progression.
3447,3447,579.0,IIT Delhi,University of Washington,how to solve fair k-center in massive data models.
3448,3448,580.0,Uber ATG,Uber ATG,hierarchical verification for adversarial robustness.
3449,3449,581.0,KAIST,KAIST,self-supervised label augmentation via input transformations.
3450,3450,582.0,Google,Google,data valuation using reinforcement learning.
3451,3451,583.0,University of British Columbia,RIKEN,handling the positive-definite constraint in the bayesian learning rule.
3452,3452,584.0,Princeton University and Institute for Advanced Study,Princeton University,provable representation learning for imitation learning via bi-level optimization.
3453,3453,585.0,North Carolina State University,North Carolina State University,causal effect estimation and optimal dose suggestions in mobile health.
3454,3454,586.0,University of Toronto,Google Brain,small-gan: speeding up gan training using core-sets .
3455,3455,587.0,"University of California, Los Angeles","University of California, Los Angeles",a finite-time analysis of  q-learning with neural network function approximation.
3456,3456,588.0,Moscow Institute of Physics and Technology,KAUST,from local sgd to local fixed-point methods for federated learning.
3457,3457,589.0,Stanford University,Stanford,the implicit and explicit regularization effects of dropout.
3458,3458,590.0,UCLA,UCLA,robust graph representation learning via neural sparsification.
3459,3459,591.0,INRIA,MSR-INRIA Joint Center,statistically preconditioned accelerated gradient method for distributed optimization.
3460,3460,592.0,Google,Google Research,multidimensional shape constraints.
3461,3461,593.0,Stanford University,Google Brain,encoding musical style with transformer autoencoders.
3462,3462,594.0,ENS,ENS,double trouble in double descent:  bias and variance(s) in the lazy regime.
3463,3463,595.0,Mathematical Institute Oxford,University of Oxford,a geometric approach to archetypal analysis via sparse projections.
3464,3464,596.0,Ghent University,Ghent University,debayes: a bayesian method for debiasing network embeddings.
3465,3465,597.0,Hebrew University Jerusalem Israel,Weizmann Institute of Science,proving the lottery ticket hypothesis: pruning is all you need.
3466,3466,598.0,Stanford University,Stanford University,learning near optimal policies with low inherent bellman error.
3467,3467,599.0,EPFL,King Abdullah University of Science & Technology (KAUST),adaptive gradient descent without descent.
3468,3468,600.0,DeepMind,DeepMind,polygen: an autoregressive generative model of 3d meshes.
3469,3469,601.0,Princeton University,Princeton University,packit: a virtual environment for geometric planning.
3470,3470,602.0,Inria Paris,DeepMind,gamification of pure exploration for linear bandits.
3471,3471,603.0,Google Inc.,Google Brain,the shapley taylor interaction index.
3472,3472,604.0,Imperial College London,Imperial College London,multilinear latent conditioning for generating unseen attribute combinations.
3473,3473,605.0,Yale University,Yale School of Medicine,feature selection using stochastic gates.
3474,3474,606.0,Linköping University,Linköping University,deep gaussian markov random fields.
3475,3475,607.0,TU Berlin,TU Berlin,fairwashing explanations with off-manifold detergent.
3476,3476,608.0,Mohamed bin Zayed University of Artificial Intelligence (MBZUAI),Inception Institute of Artificial Intelligence,on the number of linear regions of convolutional neural networks.
3477,3477,609.0,Google Brain/Mila,DeepMind,revisiting fundamentals of experience replay.
3478,3478,610.0,Technion - Israel Institute of Technology,Technion Israeli Institute of Technology,option discovery in the absence of rewards with manifold analysis.
3479,3479,611.0,Facebook AI Research,Facebook AI Research,“other-play” for zero-shot coordination.
3480,3480,612.0,Eindhoven University of Technology,University of Cambridge & Uber,einsum networks: fast and scalable learning of tractable probabilistic circuits.
3481,3481,613.0,"AMLab, University of Amsterdam",University of Amsterdam,doubly stochastic variational inference for neural processes with hierarchical latent variables.
3482,3482,614.0,CREST - ENSAE - Institut Polytechnique de Paris,CREST - ENSAE - Institut Polytechnique de Paris,convergence rates of variational inference in sparse deep learning.
3483,3483,615.0,University of Oxford,University of Oxford,deep coordination graphs.
3484,3484,616.0,Yandex,Yandex,reserve pricing in repeated second-price auctions with strategic bidders.
3485,3485,617.0,DeepMind,DeepMind,comic: complementary task learning & mimicry for reusable skills.
3486,3486,618.0,University of Edinburgh,Google,automatic reparameterisation of probabilistic programs.
3487,3487,619.0,University of Illinois at Urbana-Champaign,University of Illinois at Urbana-Champaign,inductive-bias-driven reinforcement learning for efficient schedules in heterogeneous clusters.
3488,3488,620.0,ETH Zurich,ETH Zurich,t-basis: a compact representation for neural networks.
3489,3489,621.0,University of Oxford,Apple Inc,equivariant neural rendering.
3490,3490,622.0,Harvard University,Harvard University,interpretable off-policy evaluation in reinforcement learning by highlighting influential transitions.
3491,3491,623.0,Criteo AI Lab,Facebook AI Research,efficient optimistic exploration in linear-quadratic regulators via lagrangian relaxation.
3492,3492,624.0,JD,University of Pittsburgh & JD Finance America Corporation,adversarial nonnegative matrix factorization.
3493,3493,625.0,Warwick University & The Alan Turing Institute,Amazon,optimal continual learning has perfect memory and is np-hard.
3494,3494,626.0,MIT-IBM Watson AI Lab,MIT-IBM Watson AI Lab,curvature-corrected learning dynamics in deep neural networks.
3495,3495,627.0,EPFL,EPFL,implicit regularization of random feature models.
3496,3496,628.0,King Abdullah University of Science and Technology (KAUST),KAUST,acceleration for compressed gradient descent in distributed and federated optimization.
3497,3497,629.0,University of California Los Angeles,UCLA,learning to encode position for transformer with continuous dynamical model.
3498,3498,630.0,CIMH/ Heidelberg University,CIMH/ Heidelberg University,transformation of relu-based recurrent neural networks from discrete-time to continuous-time.
3499,3499,631.0,University of Tübingen,University of Tübingen,too relaxed to be fair.
3500,3500,632.0,Umea University,Umea University,training linear neural networks: non-local convergence and complexity results.
3501,3501,633.0,University of Oxford,University of Oxford,"divide, conquer, and combine: a new inference strategy for probabilistic programs with stochastic support."
3502,3502,634.0,Ecole Polytechnique Federale de Lausanne,Ecole Polytechnique Federale de Lausanne,dissecting non-vacuous generalization bounds based on the mean-field approximation.
3503,3503,635.0,Facebook AI,Facebook AI Research,radioactive data: tracing through training.
3504,3504,636.0,German Aerospace Center (DLR),German Aerospace Center (DLR),estimating model uncertainty of neural networks in sparse information form.
3505,3505,637.0,New Jersey Institute of Technology,""" University of Oregon, USA""",scalable differential privacy with certified robustness in adversarial learning.
3506,3506,638.0,Facebook AI Research & Inria,Facebook AI Research,no-regret exploration in goal-oriented reinforcement learning.
3507,3507,639.0,ETH Zurich,ETH,k-means++:  few more steps yield constant approximation.
3508,3508,640.0,Cornell University,Cornell University,deepmatch: balancing deep covariate representations for causal inference using adversarial training.
3509,3509,641.0,University of Oxford,Oxford University,relaxing bijectivity constraints with continuously indexed normalising flows.
3510,3510,642.0,Stanford University,Stanford University,my fair bandit: distributed learning of max-min fairness with multi-player bandits.
3511,3511,643.0,Moscow Institute of Physics and Technology,Moscow Institute of Physics and Technology,towards a general theory of infinite-width limits of neural classifiers.
3512,3512,644.0,Technion - Israel Institute of Technology,Technion,unique properties of flat minima in deep networks.
3513,3513,645.0,Google,IT University of Copenhagen,private counting from anonymous messages: near-optimal accuracy with vanishing communication overhead.
3514,3514,646.0,EPFL,EPFL,a new regret analysis for adam-type algorithms.
3515,3515,647.0,EPFL,EPFL,on convergence-diagnostic based step sizes for stochastic gradient descent.
3516,3516,648.0,Rice University,OpenStax / Rice University,subspace fitting meets regression: the effects of supervision and  orthonormality constraints on double descent of generalization errors.
3517,3517,649.0,Rensselaer Polytechnic Institute,Rensselaer Polytechnic Institute,adaptive sketching for fast and convergent canonical polyadic decomposition.
3518,3518,650.0,University of Cambridge and Invenia Labs,University of Cambridge,scalable exact inference in multi-output gaussian processes.
3519,3519,651.0,Microsoft,Microsoft,"neuro-symbolic visual reasoning: disentangling ""visual"" from ""reasoning""."
3520,3520,652.0,Technical University of Denmark,"University of California, Berkeley",interpretations are useful: penalizing explanations to align neural networks with prior knowledge.
3521,3521,653.0,reciTAL,reciTAL,discriminative adversarial search for abstractive summarization.
3522,3522,654.0,Idiap & EPFL,University of Geneva,transformers are rnns: fast autoregressive transformers with linear attention.
3523,3523,655.0,EPFL,EPFL,a unified theory of decentralized sgd with changing topology and local updates.
3524,3524,656.0,University College London,University College London,self-attentive hawkes process.
3525,3525,657.0,Technische Universitat Darmstadt,TU Darmstadt,continuous time bayesian networks with clocks.
3526,3526,658.0,University of Oxford,University of Oxford,bayesian learning from sequential data using gaussian processes with signature covariances.
3527,3527,659.0,Institut de Physique Théorique,CNRS,generalisation error in learning with random features and the hidden manifold model.
3528,3528,660.0,Uber ATG,Temple University,growing adaptive multi-hyperplane machines.
3529,3529,661.0,DeepMind,DeepMind,on the generalization benefit of noise in stochastic gradient descent.
3530,3530,662.0,"University of California, Davis",UC Davis,estimating the error of randomized newton methods: a bootstrap approach.
3531,3531,663.0,IBM,Oxford University,quantum boosting.
3532,3532,664.0,IST Austria,IST Austria,on the sample complexity of adversarial multi-source pac learning.
3533,3533,665.0,Georgia Institute of Technology,ZIB,boosting frank-wolfe by chasing gradients.
3534,3534,666.0,Samsung,"Higher School of Economics, Samsung AI Center Moscow",involutive mcmc: a unifying framework.
3535,3535,667.0,EPFL,EPFL,scalable and efficient comparison-based search without features.
3536,3536,668.0,CNRS and ENS,Inria,super-efficiency of automatic differentiation for functions defined as a minimum.
3537,3537,669.0,MIT,TU Wien,a natural lottery ticket winner: reinforcement learning with ordinary neural circuits.
3538,3538,670.0,McGill University,McGill University / DeepMind,interference and generalization in temporal difference learning.
3539,3539,671.0,KTH Royal Institute of Technology,KTH Royal Institute of Technology,adding seemingly uninformative labels helps in low data regimes.
3540,3540,672.0,NYU,"Facebook AI Research, NYU",fast adaptation to new environments via policy-dynamics value functions.
3541,3541,673.0,Weizmann Institute of Science,Weizmann Institute of Science,implicit geometric regularization for learning shapes.
3542,3542,674.0,Qualcomm AI Research,Qualcomm,up or down? adaptive rounding for post-training quantization.
3543,3543,675.0,University of Oxford,University of Oxford,student-teacher curriculum learning via reinforcement learning: predicting hospital inpatient admission location.
3544,3544,676.0,KTH Royal Institute of Technology,KTH Royal Institute of Technology,convergence of a stochastic gradient method with momentum for non-smooth non-convex optimization.
3545,3545,677.0,Ruhr University Bochum,Ruhr-Universität Bochum,leveraging frequency analysis for deep fake image recognition.
3546,3546,678.0,Aalto University,Aalto University,state space expectation propagation: efficient inference schemes for temporal gaussian processes.
3547,3547,679.0,Vrije Universiteit Amsterdam,Vrije Universiteit Amsterdam,attentive group equivariant convolutional networks.
3548,3548,680.0,Bar-Ilan University,Bar-Ilan University,explicit gradient learning for black-box optimization.
3549,3549,681.0,ELTE Eötvös Loránd University,Eotvos Lorand University,videoonenet: bidirectional convolutional recurrent onenet with trainable data steps for video processing.
3550,3550,682.0,Politecnico di Milano,Politecnico di Milano,control frequency adaptation via action persistence in batch reinforcement learning.
3551,3551,683.0,"Technion, I.I.T",Technion,"it's not what machines can learn, it's what we cannot teach."
3552,3552,684.0,KAUST,KAUST,variance reduced coordinate descent with acceleration: new method with a surprising application to finite-sum problems.
3553,3553,685.0,University College London,University College London,healing products of gaussian process experts.
3554,3554,686.0,DeepMind,DeepMind,"small data, big decisions: model selection in the small-data regime."
3555,3555,687.0,University of Southern California,USC,model-free reinforcement learning in infinite-horizon average-reward markov decision processes.
3556,3556,688.0,A2I2,Deakin University,deepcoda: personalized interpretability for compositional health data.
3557,3557,689.0,PROWLER.io,PROWLER.io,sparse gaussian processes with spherical harmonic features.
3558,3558,690.0,Hebrew University of Jerusalem,"Hebrew University of Jerusalem, Israel",let's agree to agree: neural networks share classification order on real datasets.
3559,3559,691.0,Imperial College London,Imperial College London,multi-precision policy enforced training (muppet) : a precision-switching strategy for quantised fixed-point training of cnns.
3560,3560,692.0,University of Tuebingen,University of Tübingen,reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.
3561,3561,693.0,Max Planck Institute for Informatics,"MPI fuer Informatik, Saarbruecken",lifted disjoint paths with application in multiple object tracking.
3562,3562,694.0,Ulsan National Institute of Science and Technology (UNIST),KAIST,xtarnet: learning to extract task-adaptive representation for incremental few-shot learning.
3563,3563,695.0,UNSW; MPI MIS,University of New South Wales,haar graph pooling.
3564,3564,696.0,University of Chicago,University of Chicago,orthogonalized sgd and nested architectures for anytime neural networks.
3565,3565,697.0,Instituto de Telecomunicações // NIF 502854200,Instituto de Telecomunicacoes,lp-sparsemap: differentiable relaxed optimization for sparse structured prediction.
3566,3566,698.0,Deepmind,DeepMind,agent57: outperforming the atari human benchmark.
3567,3567,699.0,University of Oxford,Oxford and DeepMind,metafun: meta-learning with iterative functional updates.
3568,3568,700.0,The University of Queensland,University of Queensland,dino: distributed newton-type optimization method.
3569,3569,701.0,Cornell University,Harvard University,statistically efficient off-policy policy gradients.
3570,3570,702.0,University of Oxford,University of Cambridge and UCLA,time series deconfounder: estimating treatment effects over time in the presence of hidden confounders.
3571,3571,703.0,IBM Research AI,Tsinghua University,safe reinforcement learning in constrained markov decision processes.
3572,3572,704.0,The University of Tokyo /RIKEN,RIKEN / The University of Tokyo,online dense subgraph discovery via blurred-graph feedback.
3573,3573,705.0,Stanford University,Stanford University,"graph-based, self-supervised program repair from diagnostic feedback."
3574,3574,706.0,The Alan Turing Institute,University of Warwick,non-separable non-stationary random fields.
3575,3575,707.0,Microsoft,"Institute of Computing Technology, Chinese Academy of Sciences",optimization from structured samples for coverage functions.
3576,3576,708.0,Texas A&M University,Amazon AI & Caltech,automated synthetic-to-real generalization.
3577,3577,709.0,National Tsing Hua University,National Tsing Hua University,adversarial robustness via runtime masking and cleansing.
3578,3578,710.0,Tsinghua University,Tsinghua University,unsupervised transfer learning for spatiotemporal predictive networks.
3579,3579,711.0,Tsinghua University,UCLA,on lp-norm robustness of ensemble decision stumps and trees.
3580,3580,712.0,"AI Lab, Samsung Research China - Beijing",Peking University,boosted histogram transform for regression.
3581,3581,713.0,Seoul National University,Seoul National University,feature-map-level online adversarial knowledge distillation.
3582,3582,714.0,Mila,Mila,on relativistic f-divergences.
3583,3583,715.0,SUTD,Singapore University of Technology and Design,from chaos to order: symmetry and conservation laws in game dynamics.
3584,3584,716.0,UCL,University College London,spread divergence.
3585,3585,717.0,Shanghai Jiao Tong University,Shanghai Jiao Tong University,bidirectional model-based policy optimization.
3586,3586,718.0,Washington University in St. Louis,Washington University in St. Louis,"binoculars for efficient, nonmyopic sequential experimental design."
3587,3587,719.0,South China University of Technology,South China University of Technology,towards understanding the regularization of adversarial robustness on neural networks.
3588,3588,720.0,University of Waterloo,University of Waterloo,p-norm flow diffusion for local graph clustering.
3589,3589,721.0,Georgia Tech,Georgia Institute of Technology,privately detecting changes in unknown distributions.
3590,3590,722.0,Uber ATG,Uber ATG & University of Toronto,multi-agent routing value iteration network.
3591,3591,723.0,University of Toronto,University of Toronto; Vector Institute,improved bounds on minimax regret under logarithmic loss via self-concordance.
3592,3592,724.0,MIT,Massachusetts Institute of Technology,estimation of bounds on potential outcomes for decision making.
3593,3593,725.0,MIT-IBM Watson AI Lab,MIT,invariant rationalization.
3594,3594,726.0,The University of Iowa,BASIS Independent Silicon Valley,transparency promotion with model-agnostic linear competitors.
3595,3595,727.0,Duke University,Duke University,fiedler regularization: learning neural networks with graph sparsity.
3596,3596,728.0,Google Brain Robotics,Google,stochastic flows and geometric optimization on the orthogonal group.
3597,3597,729.0,Stony Brook University,Stony Brook University,error-bounded correction of noisy labels.
3598,3598,730.0,Facebook AI Research,Carnegie Mellon University,learning robot skills with temporal variational inference.
3599,3599,731.0,Carnegie Mellon University,Carnegie Mellon University,fact: a diagnostic for group fairness trade-offs.
3600,3600,732.0,Duke University,Google Research,robust pricing in dynamic mechanism design.
3601,3601,733.0,Uber AI,Deep Collective,"estimating q(s,s') with deep deterministic dynamics gradients."
3602,3602,734.0,University of Washington,University of Washington,a flexible framework for nonparametric graphical modeling that accommodates machine learning.
3603,3603,735.0,Tsinghua University,Stanford,on the expressivity of neural networks for deep reinforcement learning.
3604,3604,736.0,Layer 6,Layer6 AI,improving transformer optimization through better initialization .
3605,3605,737.0,University of Maryland,University of Maryland,unraveling meta-learning: understanding feature representations for few-shot tasks.
3606,3606,738.0,University of Pennsylvania,University of Pennsylvania,convex calibrated surrogates for the multi-label f-measure.
3607,3607,739.0,Stanford,Stanford University,bridging the gap between f-gans and wasserstein gans.
3608,3608,740.0,MIT,MIT,understanding contrastive representation learning through alignment and uniformity on the hypersphere.
3609,3609,741.0,"Mila, Université de Montréal","MILA, UdeM",linear lower bounds and conditioning of differentiable games.
3610,3610,742.0,Google Research,"Google Research, NY",does label smoothing mitigate label noise?.
3611,3611,743.0,UW-Madison,UW-Madison,black-box methods for restoring monotonicity.
3612,3612,744.0,The University of Hong Kong,Huawei Noah’s Ark Lab,do rnn and lstm have long memory?.
3613,3613,745.0,Massachusetts Institute of Technology,MIT,do gans always have nash equilibria?.
3614,3614,746.0,Pontifical Catholic University of Rio de Janeiro,"TUM School of Management, Technical University of Munich",born-again tree ensembles.
3615,3615,747.0,RIKEN AIP & Tokyo Tech,RIKEN AIP,graph homomorphism convolution.
3616,3616,748.0,KAIST,KAIST,fr-train: a mutual information-based approach to fair and robust training.
3617,3617,749.0,University of Pennsylvania,University of Pennsylvania,sharp composition bounds for gaussian differential privacy via edgeworth expansion.
3618,3618,750.0,University of Minnesota,University of Minnesota,almost tune-free variance reduction.
3619,3619,751.0,Carnegie Mellon University,Carnegie Mellon University,refined bounds for algorithm configuration: the knife-edge of dual class approximability.
3620,3620,752.0,Google Research,Hudson River Trading,online learning with dependent stochastic feedback graphs.
3621,3621,753.0,SAP,Rutgers University,robustifying sequential neural processes.
3622,3622,754.0,"Institute of Automation, Chinese Academy of Sciences","""Chinese Academy of Sciences, China""",towards accurate post-training network quantization via bit-split and stitching.
3623,3623,755.0,MIT,Yahoo! Research,sparse convex optimization via adaptively regularized hard thresholding.
3624,3624,756.0,"University of California, Berkeley","University of California, Berkeley",performative prediction.
3625,3625,757.0,McGill/Mila,McGill University and Mila,latent variable modelling with hyperbolic normalizing flows.
3626,3626,758.0,Duke University,Duke,learning the valuations of a $k$-demand agent.
3627,3627,759.0,University College London,Gatsby Unit，UCL,kernelized stein discrepancy tests of goodness-of-fit  for time-to-event data.
3628,3628,760.0,Tsinghua University,Tsinghua University,graph convolutional network for recommendation with low-pass collaborative filters.
3629,3629,761.0,NTT,Kyoto University/RIKEN Center for AIP,fast deterministic cur matrix decomposition with accuracy assurance.
3630,3630,762.0,Nanyang Technological University,Carnegie Mellon University,input-sparsity low rank approximation in schatten norm.
3631,3631,763.0,Northwestern University,Microsoft Research AI,mapping natural-language problems to formal-language solutions using structured neural representations.
3632,3632,764.0,Google,"Samsung - SAIT AI Lab, Montreal",acceleration through spectral density estimation.
3633,3633,765.0,Harvard,Rutgers University,interpreting robust optimization via adversarial influence functions.
3634,3634,766.0,XaiPient,"University of Wisconsin, Madison",concise explanations of neural networks using adversarial training.
3635,3635,767.0,University of Toronto,University of Toronto,maximum entropy gain exploration for long horizon multi-goal reinforcement learning.
3636,3636,768.0,McGill - Mila,McGill - Mila,universal equivariant multilayer perceptrons.
3637,3637,769.0,The Ohio State University,The Ohio State University,history-gradient aided batch size adaptation for variance reduced algorithms.
3638,3638,770.0,"University of Maryland, College Park",UMD-CP & UNC-CH,scalable differentiable physics for learning and control.
3639,3639,771.0,"Samsung - SAIT AI Lab, Montreal",Google,universal asymptotic optimality of polyak momentum.
3640,3640,772.0,NUS,National University of Singapore,deep graph random process for relational-thinking-based  speech recognition.
3641,3641,773.0,University of Texas at Austin,University of Texas at Austin,reducing sampling error in batch temporal difference learning.
3642,3642,774.0,Massachusetts Institute of Technology,Massachusetts Institute of Technology,empirical study of the benefits of overparameterization in learning latent variable models.
3643,3643,775.0,Google Research,Hudson River Trading,adaptive region-based active learning.
3644,3644,776.0,University of Minnesota,University of Minnesota,new oracle-efficient algorithms for private synthetic data release.
3645,3645,777.0,"Indian Institute of Science (IISc), Bangalore",DeepMind,improved sleeping bandits with stochastic action sets and adversarial rewards.
3646,3646,778.0,Princeton University,Princeton University,minimax-optimal off-policy evaluation with linear function approximation.
3647,3647,779.0,"University of Massachusetts, Amherst",Massachusetts Institute of Technology,causal inference using gaussian processes with structured latent confounders.
3648,3648,780.0,"University of California, San Diego","University of California, San Diego",provably efficient model-based policy adaptation.
3649,3649,781.0,UC Berkeley,UC Berkeley,on gradient descent ascent for nonconvex-concave minimax problems.
3650,3650,782.0,University of Utah,University of Utah,understanding the impact of model incoherence on convergence of incremental sgd with random reshuffle.
3651,3651,783.0,Princeton University,Princeton University,amortized finite element analysis for fast pde-constrained optimization.
3652,3652,784.0,Wellesley College,"University of Maryland, College Park",a pairwise fair and community-preserving approach to k-center clustering.
3653,3653,785.0,Peking University,Georgia Tech,deep reinforcement learning with smooth policy.
3654,3654,786.0,Google,Google,black-box variational inference as a parametric approximation to langevin dynamics.
3655,3655,787.0,McGill University,McGill University / Facebook,constrained markov decision processes via backward value functions.
3656,3656,788.0,University of Edinburgh,Peking University,on breaking deep generative model-based defenses and beyond.
3657,3657,789.0,Microsoft Research; Sun Yat-sen University,Microsoft Research Asia,sequence generation with mixed representations.
3658,3658,790.0,IBM Research,IBM Research,enhancing simple models by exploiting what they already know.
3659,3659,791.0,University of Illinois at Urbana-Champaign,UIUC,improving robustness of deep-learning-based image reconstruction.
3660,3660,792.0,Cornell University,Cornell University,learning selection strategies in buchberger’s algorithm.
3661,3661,793.0,Yale University,Yale University,adaptive checkpoint adjoint method for gradient estimation in neural ode.
3662,3662,794.0,MIT,MIT,from imagenet to image classification: contextualizing progress on benchmarks.
3663,3663,795.0,Harvard University,Harvard University,spectrum dependent learning curves in kernel regression and wide neural networks.
3664,3664,796.0,McGill University,McGill University,how to train your neural ode: the world of jacobian and kinetic regularization.
3665,3665,797.0,Boston University,Boston University,piecewise linear regression via a difference of convex functions.
3666,3666,798.0,Georgia Institute of Technology,Georgia Institute of Technology,graphopt: learning optimization models of graph formation.
3667,3667,799.0,Carnegie Mellon University,Carnegie Mellon University,optimizing dynamic structures with bayesian generative search.
3668,3668,800.0,Google Brain,UCLA,differentiable product quantization for end-to-end embedding compression.
3669,3669,801.0,Tsinghua University,Tsinghua University,task understanding from confusing multi-task data.
3670,3670,802.0,Shanghai University of Finance and Economics,Shanghai University of Finance and Economics,on a projective ensemble approach to two sample test for equality of distributions.
3671,3671,803.0,Carnegie Mellon University,Carnegie Mellon University,sharp statistical guaratees for adversarially robust gaussian classification.
3672,3672,804.0,Cornell University,Prowler.io,stochastic coordinate minimization with progressive precision for stochastic convex optimization.
3673,3673,805.0,Samsung Advanced Institute of Technology,"KAIST, AITRICS",meta variance transfer: learning to augment from the others.
3674,3674,806.0,Google,Google,rigging the lottery: making all tickets winners.
3675,3675,807.0,Sungkyunkwan University,SKKU,t-gd: transferable gan-generated images detection framework.
3676,3676,808.0,Dalian University of Technology,Southern University of Science and Technology,a generic first-order algorithmic framework for bi-level programming beyond lower-level singleton.
3677,3677,809.0,Peking University,Peking University,lower complexity bounds for finite-sum convex-concave minimax optimization problems.
3678,3678,810.0,University of Amsterdam,Borealis AI,tails of lipschitz triangular flows.
3679,3679,811.0,Google AI,"Google Research, NY",low-rank bottleneck in multi-head attention models.
3680,3680,812.0,"University of California, San Diego",The University of Sydney,learning with bounded instance- and label-dependent label noise.
3681,3681,813.0,Princeton University,Princeton University,"calibration, entropy rates, and memory in language models."
3682,3682,814.0,"University of California, Berkeley","University of California, Berkeley",strategic classification is causal modeling in disguise.
3683,3683,815.0,Johns Hopkins University,Microsoft Semantic Machines / Johns Hopkins Univ.,neural datalog through time: informed temporal modeling via logical specification.
3684,3684,816.0,UIC,University of Illinois at Chicago (UIC),convex representation learning for generalized invariance in semi-inner-product space.
3685,3685,817.0,Mila / Université de Montréal,HEC Montreal & MILA,continuous graph neural networks.
3686,3686,818.0,McGill University,McGill University,active learning on attributed graphs via graph   cognizant logistic regression and preemptive query generation.
3687,3687,819.0,Shanghai Jiao Tong University,Shanghai Jiao Tong University,linear convergence of randomized primal-dual coordinate method for large-scale linear constrained convex programming.
3688,3688,820.0,Carnegie Mellon University,Carnegie Mellon University,sparsified linear programming for zero-sum equilibrium finding.
3689,3689,821.0,The University of North Carolina at Chapel Hill,"IBM Research, Thomas J. Watson Research Center",stochastic gauss-newton algorithms for nonconvex compositional optimization.
3690,3690,822.0,UC Berkeley,UC Berkeley,skew-fit: state-covering self-supervised reinforcement learning.
3691,3691,823.0,"School of Computer Science and Engineering, University of New South Wales",University of New South Wales,adaptive adversarial multi-task representation learning.
3692,3692,824.0,South China University of Technology,South China University of Technology,analytic marching: an analytic meshing solution from deep implicit surface networks.
3693,3693,825.0,Mila & University of Montreal,Google Brain,countering language drift with seeded iterated learning.
3694,3694,826.0,Duke University,Duke,club: a contrastive log-ratio upper bound of mutual information.
3695,3695,827.0,Princeton University,MIT,reward-free exploration for reinforcement learning.
3696,3696,828.0,Georgia Institute of Technology,Georgia Institute of Technology,upper bounds for model-free row-sparse principal component analysis.
3697,3697,829.0,Alibaba Group,Alibaba Group,learning optimal tree models under beam search.
3698,3698,830.0,National University of Singapore,National University of Singapore,multi-task learning with user preferences: gradient descent with controlled ascent in pareto optimization.
3699,3699,831.0,University of Wisconsin-Madison,University of Wisconsin-Madison,robustness to programmable string transformations via augmented abstract training.
3700,3700,832.0,Duke University,Duke,bandits for bmo functions.
3701,3701,833.0,Peking University,Peking University,pdo-econvs: partial differential operator based equivariant convolutions.
3702,3702,834.0,Stanford University,Tsinghua University,variance reduction and quasi-newton for particle-based variational inference.
3703,3703,835.0,Stanford University,Stanford,goal-aware prediction: learning to model what matters.
3704,3704,836.0,UW-Madison,University of Wisconsin-Madison,adaptive reward-poisoning attacks against reinforcement learning.
3705,3705,837.0,University of Calgary,Université de Montréal,perceptual generative autoencoders.
3706,3706,838.0,University of Pennsylvania,LinkedIn,optimal differential privacy composition for exponential mechanisms.
3707,3707,839.0,National University of Singapore,National University of Singapore,r2-b2: recursive reasoning-based bayesian optimization for no-regret learning in games.
3708,3708,840.0,"University of Maryland, College Park",University of Maryland,drwr: a differentiable renderer without rendering for unsupervised 3d structure learning from silhouette images.
3709,3709,841.0,KAIST,KAIST,variational inference for sequential data with future likelihood estimates.
3710,3710,842.0,University of Chicago,University of Chicago, recht-re noncommutative arithmetic-geometric mean conjecture is false.
3711,3711,843.0,Carnegie Mellon University,IBM Research AI,is there a trade-off between fairness and accuracy? a perspective using mismatched hypothesis testing.
3712,3712,844.0,Google Brain,Google / University of Alberta,"go wide, then narrow: efficient training of deep thin networks."
3713,3713,845.0,Princeton University,Google,conqur: mitigating delusional bias in deep q-learning .
3714,3714,846.0,Harvard University,University of Virginia,the intrinsic robustness of stochastic bandits to strategic manipulation.
3715,3715,847.0,Purdue University,Purdue University,simultaneous inference for massive data: distributed bootstrap.
3716,3716,848.0,Yale University,Yale,more data can expand the generalization gap between adversarially robust and standard models.
3717,3717,849.0,State University of New York at Buffalo,SUNY Buffalo,on differentially private stochastic convex optimization  with heavy-tailed data.
3718,3718,850.0,MIT,MIT,educating text autoencoders: latent representation guidance via denoising.
3719,3719,851.0,University of Michigan,University of Michigan,clinician-in-the-loop decision making: reinforcement learning with near-optimal set-valued policies.
3720,3720,852.0,Duke University,Duke,on leveraging pretrained gans for generation with limited data.
3721,3721,853.0,OpenAI,OpenAI,distribution augmentation for generative modeling.
3722,3722,854.0,Carleton University,Carleton University,time-aware large kernel convolutions.
3723,3723,855.0,University of Toronto,University of Toronto; Vector Institute,generalization via derandomization.
3724,3724,856.0,University of Chicago,The University of Chicago,lorentz group equivariant neural network for particle physics.
3725,3725,857.0,"Imagia, Dalhousie University",Imagia,implicit class-conditioned domain alignment for unsupervised domain adaptation.
3726,3726,858.0,UCLA,Princeton University,"reinforcement learning in feature space: matrix bandit, kernels, and regret bound."
3727,3727,859.0,Deakin University,The University of Melbourne,normalized loss functions for deep learning with noisy labels.
3728,3728,860.0,University of Southern California,USC Information Sciences Institute,improving generalization by controlling label-noise information in neural network weights.
3729,3729,861.0,Carnegie Mellon University,Carnegie Mellon University,uniform convergence of rank-weighted learning .
3730,3730,862.0,UT Austin,University of Sydney,on hyperparameter tuning in general clustering problemsm.
3731,3731,863.0,University of Alberta,UCLA,model-based reinforcement learning with value-targeted regression.
3732,3732,864.0,Stanford University,,computational and statistical tradeoffs in inferring combinatorial structures of ising model.
3733,3733,865.0,University of Utah,Google Research,online learning with imperfect hints.
3734,3734,866.0,Boston University,Google Research,momentum improves normalized sgd.
3735,3735,867.0,The Chinese University of Hong Kong,The Chinese University of Hong Kong,a nearly-linear time algorithm for exact community recovery in stochastic block model.
3736,3736,868.0,"MIT-IBM Watson AI Lab, IBM Research",MIT,learning task-agnostic embedding of multiple black-box experts for multi-task model fusion.
3737,3737,869.0,College of William and Mary,Johns Hopkins University,on efficient constructions of checkpoints.
3738,3738,870.0,MIT,MIT,efficient continuous pareto exploration in multi-task learning.
3739,3739,871.0,University of Wisconsin-Madison,"University of Wisconsin, Madison",data-dependent differentially private parameter learning for directed graphical models.
3740,3740,872.0,Microsoft Research,Microsoft Research,no-regret and incentive-compatible online learning.
3741,3741,873.0,New York University,New York University,semi-supervised learning with normalizing flows.
3742,3742,874.0,University of Minnesota,Carnegie Mellon University,poisson learning: graph based semi-supervised learning at very low label rates.
3743,3743,875.0,"University of Massachusetts, Amherst","University of Massachusetts, Amherst",provable smoothness guarantees for black-box variational inference.
3744,3744,876.0,University of Maryland,University of Maryland,adversarial attacks on copyright detection systems.
3745,3745,877.0,University of North Carolina at Chapel Hill,UNC-Chapel Hill,acflow: flow models for arbitrary conditional likelihoods.
3746,3746,878.0,McGIll,McGill University / Facebook,online learned continual compression with adaptive quantization modules.
3747,3747,879.0,Peking University,"University of California, Berkeley",when demands evolve larger and noisier: learning and earning in a growing environment.
3748,3748,880.0,Nanyang Technological University,Nanyang Technological University,converging to team-maxmin equilibria in zero-sum multiplayer games.
3749,3749,881.0,Duke University,Microsoft,graph optimal transport for cross-domain alignment.
3750,3750,882.0,"Mila, Université de Montréal","MILA, UdeM",stochastic hamiltonian gradient methods for smooth games.
3751,3751,883.0,Tsinghua University,Tsinghua University,understanding and stabilizing gans' training dynamics using control theory.
3752,3752,884.0,Rice University,Amazon AI & Caltech,semi-supervised stylegan for disentanglement learning.
3753,3753,885.0,University of Pennsylvania,University of Pennsylvania,goodness-of-fit tests for inhomogeneous random graphs.
3754,3754,886.0,National University of Singapore,Université du Luxembourg,fractal gaussian networks: a sparse random graph model based on gaussian multiplicative chaos.
3755,3755,887.0,The University of Texas at Austin,The University of Texas at Austin,deep molecular programming: a natural implementation of binary-weight relu neural networks.
3756,3756,888.0,Rutgers University,TTIC,learning discrete structured representations by adversarially maximizing mutual information.
3757,3757,889.0,Stanford University,Singapore University of Technology and Design,better depth-width trade-offs for neural networks through the lens of dynamical systems.
3758,3758,890.0,MIT,MIT,multi-objective molecule generation using interpretable substructures.
3759,3759,891.0,Cornell University,Microsoft Research,doubly robust off-policy evaluation with shrinkage .
3760,3760,892.0,Cornell University,Cornell University,spectral frank-wolfe algorithm: strict complementarity and linear convergence.
3761,3761,893.0,Stanford University,Facebook AI Research,graph structure of neural networks.
3762,3762,894.0,Northwestern University,Northwestern U,breaking the curse of many agents: provable mean embedding q-iteration for mean-field reinforcement learning.
3763,3763,895.0,Microsoft Research,Microsoft Research,kinematic state abstraction and provably efficient rich-observation reinforcement learning.
3764,3764,896.0,Duke University,Duke University,minimax pareto fairness: a multi objective perspective.
3765,3765,897.0,KAIST,"KAIST, AITRICS",cost-effective interactive attention learning with neural attention processes.
3766,3766,898.0,MIT,MIT,visual grounding of learned physical models.
3767,3767,899.0,Cornell University,Facebook,certified data removal from machine learning models.
3768,3768,900.0,University of Alberta,University of Alberta,domain aggregation networks for multi-source domain adaptation.
3769,3769,901.0,Carnegie Mellon University,Carnegie Mellon University,optimizing data usage via differentiable rewards.
3770,3770,902.0,Harbin Institute of Technology,Microsoft Research,unilmv2: pseudo-masked language models for unified language model pre-training.
3771,3771,903.0,University of Alberta,University of Alberta,gradient temporal-difference learning with regularized corrections.
3772,3772,904.0,Stanford University,Stanford University,coresets for data-efficient training of machine learning models.
3773,3773,905.0,The University of North Carolina Computer Science Department,UNC-Chapel Hill,defense through diverse directions.
3774,3774,906.0,Stanford University,Seoul National University,principled learning method for wasserstein distributionally robust optimization with local perturbations.
3775,3775,907.0,California Institute of Technology,Caltech,the performance analysis of generalized margin maximizers on separable data.
3776,3776,908.0,Google,Google,sparse sinkhorn attention.
3777,3777,909.0,MIT,MIT,model fusion with kullback--leibler divergence.
3778,3778,910.0,Boston University,Boston University,"parameter-free, dynamic, and strongly-adaptive online learning."
3779,3779,911.0,Massachusetts Institute of Technology,MIT,generalization and representational limits of graph neural networks.
3780,3780,912.0,UC Berkeley,"CMU, FAIR",one policy to control them all: shared modular policies for agent-agnostic control.
3781,3781,913.0,Google Research,Google Inc. ,beyond synthetic noise: deep learning on controlled noisy labels.
3782,3782,914.0,Google,VinAI Research,collapsed amortized variational inference for switching nonlinear dynamical systems.
3783,3783,915.0,Mila,HEC Montreal & MILA,few-shot relation extraction via bayesian meta-learning on relation graphs.
3784,3784,916.0,Purdue University,Purdue University,non-convex learning via replica exchange stochastic gradient mcmc.
3785,3785,917.0,The University of Iowa,The University of Iowa,communication-efficient distributed stochastic auc maximization with deep neural networks.
3786,3786,918.0,University of Pennsylvania,University of Pennsylvania,one-shot distributed ridge regression in high dimensions.
3787,3787,919.0,"Stanford University, Google Research",Google,an imitation learning approach for cache replacement.
3788,3788,920.0,Intel Labs,Columbia University,emergence of separable manifolds in deep language representations.
3789,3789,921.0,"University of California, Berkeley",U Oxford,learning human objectives by evaluating hypothetical behavior.
3790,3790,922.0,University of Pittsburgh,University of Pittsburgh & JD Finance America Corporation,momentum-based policy gradient methods.
3791,3791,923.0,University of Oxford,University of Oxford,provably convergent two-timescale off-policy actor-critic with function approximation.
3792,3792,924.0,University of British Columbia,University of British Columbia,generalized and scalable optimal sparse decision trees.
3793,3793,925.0,University of Texas at Austin,University of Texas,learning mixtures of graphs from epidemic cascades .
3794,3794,926.0,Southeast University,RIKEN / The University of Tokyo,progressive identification of true labels for partial-label learning.
3795,3795,927.0,University of Texas at Austin,MIT,sgd learns one-layer networks in wgans.
3796,3796,928.0,University of Illinois at Chicago,University of Southern California,high-dimensional robust mean estimation via gradient descent.
3797,3797,929.0,Mila,MILA,ar-dae: towards unbiased neural entropy gradient estimation.
3798,3798,930.0,Shanghai Jiao Tong University,University of California at Berkeley,video prediction via example guidance.
3799,3799,931.0,Stanford University,UC Berkeley,accelerated message passing for entropy-regularized map inference.
3800,3800,932.0,National University of Singapore,"National University of Singapore,",inferring dqn structure for high-dimensional continuous control.
3801,3801,933.0,UC San Diego,IBM Research,bio-inspired hashing for unsupervised similarity search.
3802,3802,934.0,99andBeyond,Montreal Institute for Learning Algorithms,learning to navigate the synthetically accessible chemical space using reinforcement learning.
3803,3803,935.0,National Technical University of Athens,National Technical University of Athens,multiclass neural network minimization via tropical newton polytope approximation.
3804,3804,936.0,Baidu Research,Baidu Research,waveflow: a compact flow-based model for raw audio.
3805,3805,937.0,Stanford,Stanford University,a distributional framework for data valuation.
3806,3806,938.0,Criteo AI Lab,Telecom Paris,improved optimistic algorithms for logistic bandits.
3807,3807,939.0,University of Alberta / Google Brain,University of Alberta,on the global convergence rates of softmax policy gradient methods.
3808,3808,940.0,Indian Institute of Technology Delhi,IIT Delhi,symbolic network: generalized neural policies for relational mdps.
3809,3809,941.0,Facebook AI Research (FAIR),Facebook,aligned cross entropy for non-autoregressive machine translation.
3810,3810,942.0,LinkedIn Corporation,LinkedIn Corporation,eclipse: an extreme-scale linear program solver for web-applications.
3811,3811,943.0,Stanford University,Stanford University,active world model learning in agent-rich environments with progress curiosity.
3812,3812,944.0,Google Brain,Google / University of Alberta,energy-based processes for exchangeable data.
3813,3813,945.0,UT Austin,UT Austin,good subnetworks provably exist: pruning via greedy forward selection.
3814,3814,946.0,Tsinghua University,Tsinghua University,roma: multi-agent reinforcement learning with emergent roles.
3815,3815,947.0,UC Berkeley,UC Berkeley,decentralized reinforcement learning: global decision-making via local economic transactions.
3816,3816,948.0,Stanford University,Stanford University,concept bottleneck models.
3817,3817,949.0,UC Berkeley,"University of California, Berkeley",evaluating machine accuracy on imagenet.
3818,3818,950.0,"Indian Institute of Science (IISc), Bangalore",Indian Institute of Science,from pac to instance-optimal sample complexity in the plackett-luce model.
3819,3819,951.0,Texas A&M University,Texas A&M University,when does self-supervision help graph convolutional networks?.
3820,3820,952.0,University of Minnesota,University of Minnesota,improving the sample and communication complexity for decentralized non-convex optimization: joint gradient estimation and tracking.
3821,3821,953.0,Yandex,Yandex,unsupervised discovery of interpretable directions in the gan latent space.
3822,3822,954.0,Ben-Gurion University of the Negev,Microsoft Research,bounding the fairness and accuracy of classifiers from population statistics.
3823,3823,955.0,UC Berkeley,UC Berkeley & Covariant,curl: contrastive unsupervised representations for reinforcement learning.
3824,3824,956.0,University of California Los Angeles,UCLA,generalization error of generalized linear models in high dimensions.
3825,3825,957.0,Stanford University,Carnegie Mellon University,the implicit regularization of stochastic gradient flow for least squares.
3826,3826,958.0,Caltech,Amazon AI & Caltech,implicit competitive regularization in gans.
3827,3827,959.0,Columbia University,Amazon,decision trees for decision-making under the predict-then-optimize framework.
3828,3828,960.0,NUS,National University of Singapore,do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation.
3829,3829,961.0,University of California Berkeley,UC Berkeley,on thompson sampling with langevin algorithms.
3830,3830,962.0,Google Research,Weizmann Institute of Science,the complexity of finding stationary points with stochastic gradient descent.
3831,3831,963.0,Criteo,Stanford University,gradient-free online learning in continuous games with delayed rewards.
3832,3832,964.0,KU Leuven,KU Leuven,online continual learning from imbalanced data.
3833,3833,965.0,IST Austria,IST Austria,landscape connectivity and dropout stability of sgd solutions for over-parameterized neural networks.
3834,3834,966.0,University of Michigan,University of Michigan,a flexible latent space model for multilayer networks.
3835,3835,967.0,Volkswagen AG,Volkswagen Group,learning flat latent manifolds with vaes.
3836,3836,968.0,University of Birmingham,University of Birmingham,optimistic bounds for multi-output learning.
3837,3837,969.0,Princeton University,New York University,extra-gradient with player sampling for faster convergence in n-player games.
3838,3838,970.0,University of Salzburg,"""University of Salzburg, Austria""",topologically densified distributions.
3839,3839,971.0,University of Oxford,University of Oxford,inter-domain deep gaussian processes.
3840,3840,972.0,Weizmann Institute of Science,Weizmann Institute,frequency bias in neural networks for input of non-uniform density.
3841,3841,973.0,"ENSAE, Institut Polytechnique de Paris",Google,missing data imputation using optimal transport.
3842,3842,974.0,Idiap Research Institute,University of Geneva,optimizer benchmarking needs to account for hyperparameter tuning.
3843,3843,975.0,UC Berkeley,Berkeley,neural kernels without tangents.
3844,3844,976.0,Criteo AI Lab,Criteo AI Lab,real-time optimisation for online learning in auctions.
3845,3845,977.0,Imperial College London,"Google Research, Brain team",pegasus: pre-training with extracted gap-sentences for abstractive summarization.
3846,3846,978.0,Technical University of Munich,Technical University of Munich,"efficient robustness certificates for discrete data: sparsity-aware randomized smoothing for graphs, images and more."
3847,3847,979.0,"Heidelberg University, Mila","Mila, University of Montreal",revisiting training strategies and generalization performance in deep metric learning.
3848,3848,980.0,University of Amsterdam,University of Amsterdam,low bias low variance gradient estimates for hierarchical boolean stochastic networks.
3849,3849,981.0,UC Berkeley,MIT,naive exploration is optimal for online lqr.
3850,3850,982.0,UCLA,University of Cambridge and UCLA,discriminative jackknife: quantifying uncertainty in deep learning via higher-order influence functions.
3851,3851,983.0,"Yandex Research, MSU im. Lomonosova",Yandex,bisection-based pricing for repeated contextual auctions against strategic buyer.
3852,3852,984.0,University of Warsaw,Microsoft Research,the k-tied normal distribution: a compact parameterization of gaussian mean field posteriors in bayesian neural networks.
3853,3853,985.0,"University of California, Berkeley",ETH Zurich,randomized block-diagonal preconditioning for parallel learning.
3854,3854,986.0,EPFL,EPFL,conditional gradient methods for stochastically constrained convex minimization.
3855,3855,987.0,IBM Research,IBM Research,learning to rank learning curves.
3856,3856,988.0,Google Research and Tel Aviv University,IT University of Copenhagen,composable sketches for functions of frequencies: beyond the worst case.
3857,3857,989.0,"University of California, Irvine","University of California, Irvine",online multi-kernel learning with graph-structured feedback.
3858,3858,990.0,Stanford University,VinAI Research,predictive coding for locally-linear control.
3859,3859,991.0,University of Washington,"University of Washington, Allen Institue for AI",soft threshold weight reparameterization for learnable sparsity.
3860,3860,992.0,Tel Aviv University,"TAU, GOOGLE",near-optimal regret bounds for stochastic shortest path.
3861,3861,993.0,DeepMind,DeepMind,data-efficient image recognition with contrastive predictive coding.
3862,3862,994.0,University of Tuebingen,University of Tübingen,minimally distorted adversarial examples with a fast adaptive boundary attack.
3863,3863,995.0,EPFL,EPFL,random extrapolation for primal-dual coordinate descent.
3864,3864,996.0,DeepMind,DeepMind,monte-carlo tree search as regularized policy optimization.
3865,3865,997.0,Yandex,"Yandex, Higher School of Economics",graph-based nearest neighbor search: from practice to theory.
3866,3866,998.0,Ecole Polytechnique Fédérale de Lausanne,EPFL,double-loop unadjusted langevin algorithm.
3867,3867,999.0,Google,Google,supervised quantile normalization for low rank matrix factorization.
3868,3868,1000.0,"University of California, Berkeley",UC Berkeley,powernorm: rethinking batch normalization in transformers.
3869,3869,1001.0,INRIA Saclay Ile-de-France,University Paris Sud,aggregation of multiple knockoffs.
3870,3870,1002.0,Uber ATG,Montreal Institute for Learning Algorithms,learning to combine top-down and bottom-up signals in recurrent neural networks with attention over modules.
3871,3871,1003.0,Karlsruhe Institute of Technology (KIT),FZI Research Center for Information Technology,information particle filter tree: an online algorithm for pomdps with belief-based rewards on continuous domains.
3872,3872,1004.0,Harvard University,Harvard,predicting choice with set-dependent aggregation.
3873,3873,1005.0,NORCE the Norwegian Research Centre,Università della Svizzera Italiana,spectral clustering with graph neural networks for graph pooling.
3874,3874,1006.0,University of Paderborn,Paderborn University,preselection bandits.
3875,3875,1007.0,Technische Universiteit Delft,University of Warwick,the boomerang sampler.
3876,3876,1008.0,Technion,Technion, topic modeling via full dependence mixtures.
3877,3877,1009.0,University of Cambridge,University of Cambridge,a generative model for molecular distance geometry.
3878,3878,1010.0,University of Bristol,University of Cambridge,modulating surrogates for bayesian optimization.
3879,3879,1011.0,University of Verona,PUC-RIO,teaching with limited information on the learner's behaviour.
3880,3880,1012.0,"Gatsby Unit, University College London","Gatsby Unit, UCL",amortised learning by wake-sleep.
3881,3881,1013.0,KAUST,KAUST,stochastic subspace cubic newton method.
3882,3882,1014.0,Technion,Technion,robust learning with the hilbert-schmidt independence criterion.
3883,3883,1015.0,NAVER LABS Europe,Amazon,a quantile-based approach for hyperparameter transfer learning.
3884,3884,1016.0,Siemens AG,University of Munich (LMU),neural topic modeling with continual lifelong learning.
3885,3885,1017.0,Bosch Center for Artificial Intelligence BCAI,"Health Policy and Management, Yale School of Public Health",influenza forecasting framework based on gaussian processes.
3886,3886,1018.0,UCSD,"University of California, San Diego",towards adaptive residual network training: a neural-ode perspective.
3887,3887,1019.0,EPFL,EPFL,efficient proximal mapping of the 1-path-norm of shallow networks.
3888,3888,1020.0,University of Salzburg,"""University of Salzburg, Austria""",graph filtration learning.
3889,3889,1021.0,"CITEC, Bielefeld University","CITEC, Bielefeld University",towards non-parametric drift detection via dynamic adapting window independence drift detection (dawidd).
3890,3890,1022.0,Aalto University,Aalto University and University of Manchester,projective preferential bayesian optimization.
3891,3891,1023.0,Kingston University London,Kingston University,latent bernoulli autoencoder.
3892,3892,1024.0,Inria,Inria,convolutional kernel networks for graph-structured data.
3893,3893,1025.0,CNRS & Sorbonne Université,LaBRI,on efficient low distortion ultrametric embedding.
3894,3894,1026.0,Ecole Centrale de Lille,Centrale Lille / CRIStAL CNRS UMR 9189,kernel interpolation with continuous volume sampling.
3895,3895,1027.0,Sorbonne Université,"Sorbonne Universite, Criteo AI Lab",stochastic latent residual video prediction.
3896,3896,1028.0,Apple,Apple,learning to branch for multi-task learning.
3897,3897,1029.0,Harvard University,Harvard,the fast algorithm for submodular maximization.
3898,3898,1030.0,Technical University of Denmark,Imperial College London,stochastic differential equations with variational wishart diffusions.
3899,3899,1031.0,Huawei UK,Shanghai Jiao Tong University,multi-agent determinantal q-learning.
3900,3900,1032.0,ENSAE Paris,Google,regularized optimal transport is ground cost adversarial.
3901,3901,1033.0,UCLA,UC Berkeley,forecasting sequential data using consistent koopman autoencoders.
3902,3902,1034.0,Technion,Technion,optimistic policy optimization with bandit feedback.
3903,3903,1035.0,University of Cambridge,University of Cambridge and UCLA,unlabelled data improves bayesian uncertainty calibration under covariate shift  .
3904,3904,1036.0,DeepMind,Amazon Research Berlin,linear bandits with stochastic delayed feedback.
3905,3905,1037.0,Columbia University,Columbia,the continuous categorical: a novel simplex-valued exponential family.
3906,3906,1038.0,Riken,RIKEN,training binary neural networks using the bayesian learning rule.
3907,3907,1039.0,Neural Magic,IST Austria & NeuralMagic,inducing and exploiting activation sparsity for fast inference on deep neural networks.
3908,3908,1040.0,Technical University of Denmark,Technical University of Denmark,variational autoencoders with riemannian brownian motion priors.
3909,3909,1041.0,Facebook AI Research,Deepmind,probing emergent semantics in predictive agents via question answering.
3910,3910,1042.0,University of Cambridge,University of Cambridge,reinforcement learning for molecular design guided by quantum mechanics.
3911,3911,1043.0,Universität zu Lübeck,Universität zu Lübeck,scalable gaussian process separation for kernels with a non-stationary phase.
3912,3912,1044.0,Imperial College London,University College London,efficiently sampling functions from gaussian process posteriors.
3913,3913,1045.0,EPFL,EPFL,extrapolation for large-batch training in deep learning.
3914,3914,1046.0,KTH Royal Institute of Technology,KTH Royal Institute of Technology,anderson acceleration of proximal gradient methods.
3915,3915,1047.0,Boston University,Northeastern University,parallel algorithm for non-monotone dr-submodular maximization.
3916,3916,1048.0,ETH Zurich,ETH Zurich,from sets to multisets: provable variational  inference for probabilistic integer submodular models.
3917,3917,1049.0,Carnegie Mellon University,SenseTime Research,learning factorized weight matrix for joint filtering.
3918,3918,1050.0,University of New South Wales,U of Sydney,spectral subsampling mcmc for stationary time series.
3919,3919,1051.0,Technical University of Munich,EPFL,reliable fidelity and diversity metrics for generative models.
3920,3920,1052.0,University of Sydney,The University of Sydney,deep streaming label learning.
3921,3921,1053.0,Dauphine University - CEA LIST,Université Paris-Dauphine,randomization matters how to defend against strong adversarial attacks.
3922,3922,1054.0,"University of Maryland, College Park",University of Maryland,curse of dimensionality on randomized smoothing for certifiable robustness.
3923,3923,1055.0,DeepMind,DeepMind,off-policy actor-critic with shared experience replay.
3924,3924,1056.0,Argo AI,MIT,neural network control policy verification with persistent adversarial perturbation.
3925,3925,1057.0,University of Cambridge,INRIA - Ecole Normale Supérieure,stochastic optimization for regularized wasserstein estimators.
3926,3926,1058.0,University of Texas at Austin,University of Texas at Austin,on the power of compressed sensing with generative models .
3927,3927,1059.0,"Guangzhou Huya Technology Co., Ltd.",University of Oxford,more information supervised probabilistic deep face embedding learning.
3928,3928,1060.0,Nanjing University,Nanjing University,projection-free distributed online convex optimization with $o(\sqrt{t})$ communication complexity.
3929,3929,1061.0,Seoul National University,Seoul National University,puzzle mix: exploiting saliency and local statistics for optimal mixup.
3930,3930,1062.0,London School of Economics and Political Science,Amazon,does the markov decision process fit the data: testing for the markov property in sequential decision making.
3931,3931,1063.0,NUS,National University of Singapore,sample complexity bounds for 1-bit compressive sensing and binary stable embeddings with generative priors.
3932,3932,1064.0,Tsinghua University,UIUC,multinomial logit bandit with low switching cost.
3933,3933,1065.0,National University of Singapore,NUS,dropnet: reducing neural network complexity via iterative pruning.
3934,3934,1066.0,University of Science and Technology of China,USTC,dual-path distillation: a unified framework to improve black-box attacks.
3935,3935,1067.0,NEC Corporation,NEC Corporation,on the (in)tractability of computing normalizing constants for the product of determinantal point processes.
3936,3936,1068.0,The University of Tokyo / RIKEN,RIKEN / The University of Tokyo,do we need zero training loss after achieving zero training error?.
3937,3937,1069.0,University of Science and Technology of China,,a tree-structured decoder for image-to-markup generation.
3938,3938,1070.0,Georgia Institute of Technology,Georgia Institute of Technology,transformer hawkes process.
3939,3939,1071.0,Harvard University,University of Illinois at Urbana-Champaign,minimax weight and q-function learning for off-policy evaluation.
3940,3940,1072.0,Deakin University,Deakin University,self-attentive associative memory.
3941,3941,1073.0,"InfiniaML, Inc.",Duke,learning autoencoders with relational regularization.
3942,3942,1074.0,MERL,Tufts University,representation learning via adversarially-contrastive optimal transport.
3943,3943,1075.0,Peking University,HEC Montreal & MILA,a graph to graphs framework for retrosynthesis prediction.
3944,3944,1076.0,Nanjing University,Nanjing University,cost-effectively identifying causal effects when only response variable is observable.
3945,3945,1077.0,"Shanxi University, China",Shanxi University,sparse subspace clustering with entropy-norm.
3946,3946,1078.0,University of Washington,Facebook AI Research,non-autoregressive machine translation with disentangled context transformer.
3947,3947,1079.0,Nagoya Institute of Technology,Nagoya Institute of Technology,multi-objective bayesian optimization using pareto-frontier entropy.
3948,3948,1080.0,University of Science and Technology of China,University of Texas at Austin,self-pu: self boosted and calibrated positive-unlabeled training.
3949,3949,1081.0,The University of Tokyo / RIKEN,RIKEN / The University of Tokyo,few-shot domain adaptation by causal mechanism transfer.
3950,3950,1082.0,"Institute of Computing Technology, Chinese Academy of Sciences",Microsoft Research Asia,on layer normalization in the transformer architecture.
3951,3951,1083.0,Nanyang Technological University,Nanyang Technological University,learning efficient multi-agent communication: an information bottleneck approach.